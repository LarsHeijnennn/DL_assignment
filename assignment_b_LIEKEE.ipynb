{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         file_path  \\\n",
      "0  /Users/liekevaneijk/Downloads/Train/2m_9039.wav   \n",
      "1  /Users/liekevaneijk/Downloads/Train/4f_1887.wav   \n",
      "2  /Users/liekevaneijk/Downloads/Train/4f_9571.wav   \n",
      "3  /Users/liekevaneijk/Downloads/Train/1m_3736.wav   \n",
      "4  /Users/liekevaneijk/Downloads/Train/1m_3078.wav   \n",
      "\n",
      "                                            waveform  accent gender  \n",
      "0  [[[tensor(8.2519e-05), tensor(2.3516e-07), ten...       2      m  \n",
      "1  [[[tensor(7.0271e-05), tensor(6.2840e-05), ten...       4      f  \n",
      "2  [[[tensor(8.9346e-05), tensor(5.5403e-05), ten...       4      f  \n",
      "3  [[[tensor(0.0017), tensor(0.0002), tensor(4.98...       1      m  \n",
      "4  [[[tensor(0.0008), tensor(0.0003), tensor(0.00...       1      m  \n",
      "torch.Size([1, 201, 208])\n",
      "torch.Size([1, 201, 335])\n",
      "torch.Size([1, 201, 444])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "import torchaudio.transforms as T # Import the transforms module\n",
    "\n",
    "\n",
    "def load_and_preprocess_audios_from_folder(folder_path, target_sr=16000):\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    # Initialize the Spectrogram transform\n",
    "    spectrogram_transform = T.Spectrogram()\n",
    "\n",
    "    for fname in os.listdir(folder_path):\n",
    "        if fname.endswith('.wav'):\n",
    "            file_path = os.path.join(folder_path, fname)\n",
    "            \n",
    "            # Load audio\n",
    "            waveform, sr = torchaudio.load(file_path)\n",
    "            \n",
    "            # Normalize amplitude\n",
    "            waveform = waveform / waveform.abs().max()\n",
    "            \n",
    "            # Apply STFT\n",
    "            spectrogram = spectrogram_transform(waveform)\n",
    "\n",
    "            # Extract accent and gender\n",
    "            accent = int(fname[0])  # 1-5\n",
    "            gender = fname[1]       # 'm' or 'f'\n",
    "            \n",
    "            data.append({\n",
    "                'file_path': file_path,\n",
    "                'waveform': spectrogram, # Store the spectrogram\n",
    "                'accent': accent,\n",
    "                'gender': gender\n",
    "            })\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "    \n",
    "df_train = load_and_preprocess_audios_from_folder(\"/Users/liekevaneijk/Downloads/Train\")\n",
    "print(df_train.head())\n",
    "\n",
    "\n",
    "#Size first waveform\n",
    "print(df_train['waveform'].iloc[0].shape)\n",
    "print(df_train['waveform'].iloc[1].shape)\n",
    "print(df_train['waveform'].iloc[2].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pad_waveform(waveform, target_width=208):\n",
    "    _, h, w = waveform.shape\n",
    "    if w >= target_width:\n",
    "        return waveform[:, :, :target_width]\n",
    "    else:\n",
    "        pad_amt = target_width - w\n",
    "        return F.pad(waveform, (0, pad_amt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class AccentDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        waveform = self.df.loc[idx, 'waveform']\n",
    "        label = self.df.loc[idx, 'accent'] \n",
    "        return waveform, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNNBaseline(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNBaseline, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "       \n",
    "        self.fc1 = nn.Linear(32 * 50 * 52, 128)  # Adjust based on input shape\n",
    "        self.fc2 = nn.Linear(128, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class CNNRegularized(nn.Module):\n",
    "    def __init__(self, num_classes=5):\n",
    "        super(CNNRegularized, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "    \n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(32 * 50 * 52, 128)\n",
    "        self.fc2 = nn.Linear(128, 5)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader=None, num_epochs=10, lr=0.001, weight_decay=0.0):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            if inputs.dim() == 3:  # Add channel dim\n",
    "                inputs = inputs.unsqueeze(1)  # (B,1,H,W)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        train_acc = 100 * correct / total\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | Loss: {running_loss:.4f} | Train Accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "        # Optional validation\n",
    "        if val_loader is not None:\n",
    "            val_acc = evaluate(model, val_loader)\n",
    "            print(f\" Validation Accuracy: {val_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 6. Evaluation function\n",
    "\n",
    "def evaluate(model, data_loader):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            if inputs.dim() == 3:\n",
    "                inputs = inputs.unsqueeze(1)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Baseline CNN\n",
      "Epoch 1/10 | Loss: 685.4233 | Train Accuracy: 31.36%\n",
      " Validation Accuracy: 39.75%\n",
      "Epoch 2/10 | Loss: 200.4573 | Train Accuracy: 50.36%\n",
      " Validation Accuracy: 42.74%\n",
      "Epoch 3/10 | Loss: 131.5519 | Train Accuracy: 68.64%\n",
      " Validation Accuracy: 45.90%\n",
      "Epoch 4/10 | Loss: 67.8269 | Train Accuracy: 85.70%\n",
      " Validation Accuracy: 45.27%\n",
      "Epoch 5/10 | Loss: 37.4206 | Train Accuracy: 94.27%\n",
      " Validation Accuracy: 44.16%\n",
      "Epoch 6/10 | Loss: 16.1838 | Train Accuracy: 97.63%\n",
      " Validation Accuracy: 42.43%\n",
      "Epoch 7/10 | Loss: 15.0132 | Train Accuracy: 97.95%\n",
      " Validation Accuracy: 42.43%\n",
      "Epoch 8/10 | Loss: 13.4658 | Train Accuracy: 98.18%\n",
      " Validation Accuracy: 42.11%\n",
      "Epoch 9/10 | Loss: 9.8606 | Train Accuracy: 98.58%\n",
      " Validation Accuracy: 43.06%\n",
      "Epoch 10/10 | Loss: 4.2771 | Train Accuracy: 99.29%\n",
      " Validation Accuracy: 43.38%\n",
      "Baseline CNN Test Accuracy: 43.38%\n",
      "\n",
      "Training Regularized CNN\n",
      "Epoch 1/10 | Loss: 317.4447 | Train Accuracy: 21.60%\n",
      " Validation Accuracy: 23.97%\n",
      "Epoch 2/10 | Loss: 254.3410 | Train Accuracy: 23.42%\n",
      " Validation Accuracy: 25.24%\n",
      "Epoch 3/10 | Loss: 254.7041 | Train Accuracy: 23.54%\n",
      " Validation Accuracy: 23.34%\n",
      "Epoch 4/10 | Loss: 253.1409 | Train Accuracy: 26.62%\n",
      " Validation Accuracy: 35.02%\n",
      "Epoch 5/10 | Loss: 241.4890 | Train Accuracy: 31.08%\n",
      " Validation Accuracy: 38.80%\n",
      "Epoch 6/10 | Loss: 229.6663 | Train Accuracy: 34.16%\n",
      " Validation Accuracy: 41.48%\n",
      "Epoch 7/10 | Loss: 221.3326 | Train Accuracy: 37.91%\n",
      " Validation Accuracy: 44.16%\n",
      "Epoch 8/10 | Loss: 211.4423 | Train Accuracy: 40.48%\n",
      " Validation Accuracy: 44.16%\n",
      "Epoch 9/10 | Loss: 200.6604 | Train Accuracy: 44.51%\n",
      " Validation Accuracy: 44.95%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    df = load_and_preprocess_audios_from_folder(\"/Users/liekevaneijk/Downloads/Train\")\n",
    "    df['waveform'] = df['waveform'].apply(lambda x: pad_waveform(x, target_width=208))\n",
    "    df['accent'] = df['accent'].apply(lambda x: x - 1)  # zero-based labels!\n",
    "\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['accent'], random_state=42)\n",
    "\n",
    "    train_dataset = AccentDataset(train_df.reset_index(drop=True))\n",
    "    test_dataset = AccentDataset(test_df.reset_index(drop=True))\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "    print(\"Training Baseline CNN\")\n",
    "    baseline_model = CNNBaseline()\n",
    "    train(baseline_model, train_loader, val_loader=test_loader, num_epochs=10, weight_decay=0.0)\n",
    "    baseline_acc = evaluate(baseline_model, test_loader)\n",
    "    print(f\"Baseline CNN Test Accuracy: {baseline_acc:.2f}%\\n\")\n",
    "\n",
    "    print(\"Training Regularized CNN\")\n",
    "    reg_model = CNNRegularized()\n",
    "    train(reg_model, train_loader, val_loader=test_loader, num_epochs=10, weight_decay=1e-4)\n",
    "    reg_acc = evaluate(reg_model, test_loader)\n",
    "    print(f\"Regularized CNN Test Accuracy: {reg_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
