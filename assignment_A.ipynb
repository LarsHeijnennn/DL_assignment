{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data (not augmented)\n",
    "\n",
    "Data augmentation does not happen here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class AccentRawWaveformDataset(Dataset):\n",
    "    def __init__(self, folder_path,\n",
    "                 target_sr: int = 16000,\n",
    "                 standardize: bool = True):\n",
    "        # store file paths only; transform per item\n",
    "        self.file_paths = [\n",
    "            os.path.join(folder_path, f)\n",
    "            for f in os.listdir(folder_path)\n",
    "            if f.endswith('.wav')\n",
    "        ]\n",
    "        self.target_sr = target_sr\n",
    "        self.standardize = standardize\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.file_paths[idx]\n",
    "        waveform, sr = torchaudio.load(path)\n",
    "        if sr != self.target_sr:\n",
    "            waveform = torchaudio.transforms.Resample(sr, self.target_sr)(waveform)\n",
    "        # Convert to mono if not already\n",
    "        if waveform.shape[0] > 1:\n",
    "            waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "        # Standardize (zero mean, unit variance) if requested\n",
    "        if self.standardize:\n",
    "            mean = waveform.mean()\n",
    "            std = waveform.std() if waveform.std() > 0 else 1.0\n",
    "            waveform = (waveform - mean) / std\n",
    "\n",
    "        fname = os.path.basename(path)\n",
    "        accent = int(fname[0]) - 1          # classes 0–4\n",
    "        gender = fname[1]  # 'm' or 'f' \n",
    "        return waveform, accent, gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def pad_1d_collate(batch, target_length=208):\n",
    "    waveforms, accents, genders = zip(*batch)\n",
    "    padded_waveforms = []\n",
    "    for w in waveforms:\n",
    "        pad_amount = target_length - w.shape[-1]\n",
    "        if pad_amount > 0:\n",
    "            # Pad at the end (right side) for 1D waveform\n",
    "            padded = F.pad(w, (0, pad_amount))\n",
    "        else:\n",
    "            padded = w[..., :target_length]\n",
    "        padded_waveforms.append(padded)\n",
    "    return (\n",
    "        torch.stack(padded_waveforms),  # (B, 1, T)\n",
    "        torch.tensor(accents),\n",
    "        list(genders)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in dataset: 3166\n",
      "Sample 0 waveform shape: torch.Size([1, 41400])\n",
      "Sample 0 accent label: 1\n",
      "Sample 0 gender label: m\n"
     ]
    }
   ],
   "source": [
    "# Let's instantiate the dataset and inspect a sample\n",
    "# (Assume the folder path is './data' - change as needed)\n",
    "dataset = AccentRawWaveformDataset(\"/Users/larsheijnen/DL/Train\")\n",
    "\n",
    "print(f\"Number of samples in dataset: {len(dataset)}\")\n",
    "\n",
    "# Get the first sample\n",
    "sample_waveform, sample_accent, sample_gender = dataset[0]\n",
    "\n",
    "print(\"Sample 0 waveform shape:\", sample_waveform.shape)\n",
    "print(\"Sample 0 accent label:\", sample_accent)\n",
    "print(\"Sample 0 gender label:\", sample_gender)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waveforms: torch.Size([4, 1, 208])\n",
      "Accents: tensor([4, 0, 1, 0])\n",
      "Gender: ['m', 'f', 'f', 'f']\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Use batch_size=4 for low RAM, pin_memory is False for macOS/MPS\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=pad_1d_collate, pin_memory=False)\n",
    "\n",
    "# Try again\n",
    "for batch in dataloader:\n",
    "    waveforms, accents, gender = batch\n",
    "    print(f\"Waveforms: {waveforms.shape}\")  # (B, 1, T)\n",
    "    print(f\"Accents: {accents}\")            # (B,)\n",
    "    print(f\"Gender: {gender}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Model 1 (baseline)\n",
    "class CNNBaseline(nn.Module):\n",
    "    def __init__(self, num_classes: int = 5):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 8, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(8, 16, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(16)  # Output: (B, 32, 256)\n",
    "        self.fc = nn.Linear(32 * 16, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, 1, T)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool(x)  # (B, 32, 256)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Model 2 (baseline + batch normalization)\n",
    "class CNNBaseline_BatchNorm(nn.Module):\n",
    "    def __init__(self, num_classes: int = 5):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 8, kernel_size=3, padding=1)\n",
    "        self.bn1   = nn.BatchNorm1d(8)\n",
    "        self.conv2 = nn.Conv1d(8, 16, kernel_size=3, padding=1)\n",
    "        self.bn2   = nn.BatchNorm1d(16)\n",
    "        self.conv3 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn3   = nn.BatchNorm1d(32)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(16)\n",
    "        self.fc = nn.Linear(32 * 16, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Model 3 (baseline + dropout 0.3)\n",
    "class CNNBaseline_Dropout3(nn.Module):\n",
    "    def __init__(self, num_classes: int = 5, dropout_p: float = 0.3):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 8, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(8, 16, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(16)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.fc = nn.Linear(32 * 16, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Model 4 (baseline + dropout 0.5)\n",
    "class CNNBaseline_Dropout5(nn.Module):\n",
    "    def __init__(self, num_classes: int = 5, dropout_p: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 8, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(8, 16, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(16)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.fc = nn.Linear(32 * 16, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Model 5 (baseline + batch normalization + dropout 0.3)\n",
    "class CNNBaseline_Dropout3_BatchNorm(nn.Module):\n",
    "    def __init__(self, num_classes: int = 5, dropout_p: float = 0.3):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 8, kernel_size=3, padding=1)\n",
    "        self.bn1   = nn.BatchNorm1d(8)\n",
    "        self.conv2 = nn.Conv1d(8, 16, kernel_size=3, padding=1)\n",
    "        self.bn2   = nn.BatchNorm1d(16)\n",
    "        self.conv3 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn3   = nn.BatchNorm1d(32)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(16)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.fc = nn.Linear(32 * 16, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Model 6 (baseline + batch normalization + dropout 0.5)\n",
    "class CNNBaseline_Dropout5_BatchNorm(nn.Module):\n",
    "    def __init__(self, num_classes: int = 5, dropout_p: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 8, kernel_size=3, padding=1)\n",
    "        self.bn1   = nn.BatchNorm1d(8)\n",
    "        self.conv2 = nn.Conv1d(8, 16, kernel_size=3, padding=1)\n",
    "        self.bn2   = nn.BatchNorm1d(16)\n",
    "        self.conv3 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn3   = nn.BatchNorm1d(32)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(16)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.fc = nn.Linear(32 * 16, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {\n",
    "    \"Model1\": CNNBaseline,\n",
    "    \"Model2\": CNNBaseline_BatchNorm, \n",
    "    \"Model3\": CNNBaseline_Dropout3,\n",
    "    \"Model4\": CNNBaseline_Dropout5,\n",
    "    \"Model5\": CNNBaseline_Dropout3_BatchNorm,\n",
    "    \"Model6\": CNNBaseline_Dropout5_BatchNorm,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training model: CNNBaseline (Early Stopping) ===\n",
      "Epoch   1/150 | Train Loss: 1012.309 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 0/20\n",
      "    → New best test accuracy: 23.659% (saved to /Users/larsheijnen/DL/saved_models/A/not_augmented_earlystop/CNNBaseline_not_augmented_best_1d_earlystop.pth)\n",
      "Epoch   2/150 | Train Loss: 1011.110 | Train Acc: 23.82% | Train Prec:  4.76% | Train Recall: 19.97% | Train F1:  7.69% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 0/20\n",
      "Epoch   3/150 | Train Loss: 1010.694 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 1/20\n",
      "Epoch   4/150 | Train Loss: 1009.884 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 2/20\n",
      "Epoch   5/150 | Train Loss: 1010.169 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 3/20\n",
      "Epoch   6/150 | Train Loss: 1009.849 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 4/20\n",
      "Epoch   7/150 | Train Loss: 1009.750 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 5/20\n",
      "Epoch   8/150 | Train Loss: 1009.720 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 6/20\n",
      "Epoch   9/150 | Train Loss: 1009.463 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 7/20\n",
      "Epoch  10/150 | Train Loss: 1009.850 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 8/20\n",
      "Epoch  11/150 | Train Loss: 1009.775 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 9/20\n",
      "Epoch  12/150 | Train Loss: 1009.505 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 10/20\n",
      "Epoch  13/150 | Train Loss: 1009.650 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 11/20\n",
      "Epoch  14/150 | Train Loss: 1009.556 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 12/20\n",
      "Epoch  15/150 | Train Loss: 1009.509 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 13/20\n",
      "Epoch  16/150 | Train Loss: 1009.045 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 14/20\n",
      "Epoch  17/150 | Train Loss: 1009.444 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 15/20\n",
      "Epoch  18/150 | Train Loss: 1009.780 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 16/20\n",
      "Epoch  19/150 | Train Loss: 1009.458 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 17/20\n",
      "Epoch  20/150 | Train Loss: 1009.455 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 18/20\n",
      "Epoch  21/150 | Train Loss: 1009.442 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 19/20\n",
      "\n",
      "Early stopping triggered for CNNBaseline after 21 epochs.\n",
      "Final training state for CNNBaseline saved to /Users/larsheijnen/DL/saved_models/A/not_augmented_earlystop/CNNBaseline_not_augmented_latest_1d_earlystop.pth\n",
      "\n",
      "Training completed for CNNBaseline after 21 epochs.\n",
      "Best test accuracy achieved during training: 23.659%\n",
      "\n",
      "Loading best saved model for CNNBaseline from /Users/larsheijnen/DL/saved_models/A/not_augmented_earlystop/CNNBaseline_not_augmented_best_1d_earlystop.pth for final evaluation...\n",
      "\n",
      "Classification Report for CNNBaseline (using best saved model):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       138\n",
      "           1      0.000     0.000     0.000       118\n",
      "           2      0.000     0.000     0.000       120\n",
      "           3      0.237     1.000     0.383       150\n",
      "           4      0.000     0.000     0.000       108\n",
      "\n",
      "    accuracy                          0.237       634\n",
      "   macro avg      0.047     0.200     0.077       634\n",
      "weighted avg      0.056     0.237     0.091       634\n",
      "\n",
      "\n",
      "Gender breakdown for CNNBaseline (using best saved model):\n",
      "Male: {'accuracy': 0.2515923566878981, 'precision': 0.05031847133757962, 'recall': 0.2, 'f1': 0.08040712468193384}\n",
      "Female: {'accuracy': 0.221875, 'precision': 0.044375, 'recall': 0.2, 'f1': 0.07263427109974424}\n",
      "\n",
      "--- Summary for CNNBaseline ---\n",
      "- Total epochs trained: 21\n",
      "- Best validation accuracy during training: 23.659%\n",
      "- Training accuracy of loaded (best saved) model: 23.85%\n",
      "- Best model saved to: /Users/larsheijnen/DL/saved_models/A/not_augmented_earlystop/CNNBaseline_not_augmented_best_1d_earlystop.pth\n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "=== Training model: CNNBaseline_BatchNorm (Early Stopping) ===\n",
      "Epoch   1/150 | Train Loss: 997.851 | Train Acc: 22.43% | Train Prec: 22.88% | Train Recall: 19.92% | Train F1: 11.68% || Test Acc: 24.29% | Test Prec: 16.28% | Test Recall: 21.74% | Test F1: 13.02% | Patience: 0/20\n",
      "    → New best test accuracy: 24.290% (saved to /Users/larsheijnen/DL/saved_models/A/not_augmented_earlystop/CNNBaseline_BatchNorm_not_augmented_best_1d_earlystop.pth)\n",
      "Epoch   2/150 | Train Loss: 975.915 | Train Acc: 27.65% | Train Prec: 21.58% | Train Recall: 23.29% | Train F1: 14.81% || Test Acc: 26.66% | Test Prec: 19.91% | Test Recall: 22.87% | Test F1: 13.98% | Patience: 0/20\n",
      "    → New best test accuracy: 26.656% (saved to /Users/larsheijnen/DL/saved_models/A/not_augmented_earlystop/CNNBaseline_BatchNorm_not_augmented_best_1d_earlystop.pth)\n",
      "Epoch   3/150 | Train Loss: 950.827 | Train Acc: 25.00% | Train Prec: 21.31% | Train Recall: 24.19% | Train F1: 16.42% || Test Acc: 24.45% | Test Prec: 22.51% | Test Recall: 25.33% | Test F1: 17.03% | Patience: 0/20\n",
      "Epoch   4/150 | Train Loss: 951.633 | Train Acc: 24.96% | Train Prec: 25.03% | Train Recall: 20.94% | Train F1: 10.39% || Test Acc: 25.24% | Test Prec: 40.20% | Test Recall: 21.48% | Test F1: 10.73% | Patience: 1/20\n",
      "Epoch   5/150 | Train Loss: 935.260 | Train Acc: 23.97% | Train Prec: 12.29% | Train Recall: 20.33% | Train F1: 10.02% || Test Acc: 23.34% | Test Prec:  7.27% | Test Recall: 19.95% | Test F1:  9.23% | Patience: 2/20\n",
      "Epoch   6/150 | Train Loss: 926.164 | Train Acc: 23.78% | Train Prec: 45.18% | Train Recall: 23.51% | Train F1: 14.28% || Test Acc: 20.82% | Test Prec: 33.23% | Test Recall: 21.97% | Test F1: 12.58% | Patience: 3/20\n",
      "Epoch   7/150 | Train Loss: 912.580 | Train Acc: 21.72% | Train Prec: 18.48% | Train Recall: 19.98% | Train F1: 12.63% || Test Acc: 20.82% | Test Prec: 22.89% | Test Recall: 18.83% | Test F1: 11.76% | Patience: 4/20\n",
      "Epoch   8/150 | Train Loss: 904.626 | Train Acc: 22.08% | Train Prec: 43.29% | Train Recall: 21.60% | Train F1: 10.73% || Test Acc: 19.87% | Test Prec: 37.07% | Test Recall: 21.11% | Test F1:  9.21% | Patience: 5/20\n",
      "Epoch   9/150 | Train Loss: 887.139 | Train Acc: 32.35% | Train Prec: 38.50% | Train Recall: 27.48% | Train F1: 20.01% || Test Acc: 30.76% | Test Prec: 17.92% | Test Recall: 27.69% | Test F1: 19.73% | Patience: 6/20\n",
      "    → New best test accuracy: 30.757% (saved to /Users/larsheijnen/DL/saved_models/A/not_augmented_earlystop/CNNBaseline_BatchNorm_not_augmented_best_1d_earlystop.pth)\n",
      "Epoch  10/150 | Train Loss: 883.243 | Train Acc: 17.06% | Train Prec: 23.71% | Train Recall: 21.64% | Train F1: 11.02% || Test Acc: 19.56% | Test Prec: 35.21% | Test Recall: 22.13% | Test F1: 12.96% | Patience: 0/20\n",
      "Epoch  11/150 | Train Loss: 859.932 | Train Acc: 26.07% | Train Prec: 31.81% | Train Recall: 22.06% | Train F1: 13.21% || Test Acc: 25.39% | Test Prec: 31.38% | Test Recall: 21.78% | Test F1: 12.60% | Patience: 1/20\n",
      "Epoch  12/150 | Train Loss: 863.730 | Train Acc: 21.45% | Train Prec: 36.20% | Train Recall: 21.01% | Train F1: 17.35% || Test Acc: 19.56% | Test Prec: 22.33% | Test Recall: 20.25% | Test F1: 14.91% | Patience: 2/20\n",
      "Epoch  13/150 | Train Loss: 861.728 | Train Acc: 14.85% | Train Prec: 27.96% | Train Recall: 20.07% | Train F1:  5.30% || Test Acc: 17.03% | Test Prec:  3.41% | Test Recall: 20.00% | Test F1:  5.82% | Patience: 3/20\n",
      "Epoch  14/150 | Train Loss: 843.267 | Train Acc: 25.79% | Train Prec: 44.77% | Train Recall: 22.23% | Train F1: 12.31% || Test Acc: 22.56% | Test Prec: 22.83% | Test Recall: 20.88% | Test F1:  9.67% | Patience: 4/20\n",
      "Epoch  15/150 | Train Loss: 839.983 | Train Acc: 30.73% | Train Prec: 29.54% | Train Recall: 30.35% | Train F1: 27.23% || Test Acc: 26.50% | Test Prec: 25.92% | Test Recall: 26.93% | Test F1: 24.27% | Patience: 5/20\n",
      "Epoch  16/150 | Train Loss: 825.995 | Train Acc: 16.47% | Train Prec: 20.59% | Train Recall: 21.29% | Train F1:  9.13% || Test Acc: 18.14% | Test Prec: 33.61% | Test Recall: 20.98% | Test F1:  8.80% | Patience: 6/20\n",
      "Epoch  17/150 | Train Loss: 817.529 | Train Acc: 27.49% | Train Prec: 47.91% | Train Recall: 23.60% | Train F1: 16.56% || Test Acc: 25.71% | Test Prec: 47.65% | Test Recall: 22.42% | Test F1: 15.41% | Patience: 7/20\n",
      "Epoch  18/150 | Train Loss: 812.713 | Train Acc: 19.87% | Train Prec: 34.39% | Train Recall: 20.04% | Train F1:  8.35% || Test Acc: 19.24% | Test Prec:  9.50% | Test Recall: 20.77% | Test F1:  8.21% | Patience: 8/20\n",
      "Epoch  19/150 | Train Loss: 805.357 | Train Acc: 26.54% | Train Prec: 55.50% | Train Recall: 25.19% | Train F1: 15.71% || Test Acc: 22.71% | Test Prec: 14.66% | Test Recall: 23.50% | Test F1: 13.44% | Patience: 9/20\n",
      "Epoch  20/150 | Train Loss: 794.216 | Train Acc: 17.34% | Train Prec: 19.50% | Train Recall: 21.81% | Train F1: 11.07% || Test Acc: 19.24% | Test Prec: 24.46% | Test Recall: 21.87% | Test F1: 12.20% | Patience: 10/20\n",
      "Epoch  21/150 | Train Loss: 798.628 | Train Acc: 20.22% | Train Prec: 43.02% | Train Recall: 20.20% | Train F1:  7.17% || Test Acc: 18.61% | Test Prec:  3.72% | Test Recall: 20.00% | Test F1:  6.28% | Patience: 11/20\n",
      "Epoch  22/150 | Train Loss: 779.311 | Train Acc: 27.37% | Train Prec: 23.33% | Train Recall: 23.51% | Train F1: 18.46% || Test Acc: 25.24% | Test Prec: 21.00% | Test Recall: 22.64% | Test F1: 17.56% | Patience: 12/20\n",
      "Epoch  23/150 | Train Loss: 787.663 | Train Acc: 23.89% | Train Prec: 18.69% | Train Recall: 20.88% | Train F1: 12.68% || Test Acc: 22.87% | Test Prec: 11.68% | Test Recall: 19.85% | Test F1: 11.06% | Patience: 13/20\n",
      "Epoch  24/150 | Train Loss: 771.801 | Train Acc: 22.00% | Train Prec: 27.79% | Train Recall: 26.26% | Train F1: 18.51% || Test Acc: 21.61% | Test Prec: 28.44% | Test Recall: 23.98% | Test F1: 17.56% | Patience: 14/20\n",
      "Epoch  25/150 | Train Loss: 762.079 | Train Acc: 24.76% | Train Prec: 21.24% | Train Recall: 21.25% | Train F1: 12.27% || Test Acc: 23.50% | Test Prec: 11.96% | Test Recall: 20.29% | Test F1: 10.78% | Patience: 15/20\n",
      "Epoch  26/150 | Train Loss: 763.191 | Train Acc: 21.56% | Train Prec: 29.29% | Train Recall: 23.26% | Train F1: 17.04% || Test Acc: 21.14% | Test Prec: 25.75% | Test Recall: 21.82% | Test F1: 15.33% | Patience: 16/20\n",
      "Epoch  27/150 | Train Loss: 757.978 | Train Acc: 25.20% | Train Prec: 28.70% | Train Recall: 25.50% | Train F1: 21.22% || Test Acc: 26.03% | Test Prec: 28.79% | Test Recall: 25.69% | Test F1: 21.88% | Patience: 17/20\n",
      "Epoch  28/150 | Train Loss: 759.984 | Train Acc: 33.21% | Train Prec: 49.24% | Train Recall: 30.72% | Train F1: 21.40% || Test Acc: 27.76% | Test Prec: 33.65% | Test Recall: 27.74% | Test F1: 17.46% | Patience: 18/20\n",
      "Epoch  29/150 | Train Loss: 747.285 | Train Acc: 18.33% | Train Prec: 30.86% | Train Recall: 23.01% | Train F1: 11.76% || Test Acc: 18.93% | Test Prec: 21.65% | Test Recall: 21.65% | Test F1: 10.45% | Patience: 19/20\n",
      "\n",
      "Early stopping triggered for CNNBaseline_BatchNorm after 29 epochs.\n",
      "Final training state for CNNBaseline_BatchNorm saved to /Users/larsheijnen/DL/saved_models/A/not_augmented_earlystop/CNNBaseline_BatchNorm_not_augmented_latest_1d_earlystop.pth\n",
      "\n",
      "Training completed for CNNBaseline_BatchNorm after 29 epochs.\n",
      "Best test accuracy achieved during training: 30.757%\n",
      "\n",
      "Loading best saved model for CNNBaseline_BatchNorm from /Users/larsheijnen/DL/saved_models/A/not_augmented_earlystop/CNNBaseline_BatchNorm_not_augmented_best_1d_earlystop.pth for final evaluation...\n",
      "\n",
      "Classification Report for CNNBaseline_BatchNorm (using best saved model):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.323     0.761     0.454       138\n",
      "           1      0.277     0.110     0.158       118\n",
      "           2      0.000     0.000     0.000       120\n",
      "           3      0.296     0.513     0.376       150\n",
      "           4      0.000     0.000     0.000       108\n",
      "\n",
      "    accuracy                          0.308       634\n",
      "   macro avg      0.179     0.277     0.197       634\n",
      "weighted avg      0.192     0.308     0.217       634\n",
      "\n",
      "\n",
      "Gender breakdown for CNNBaseline_BatchNorm (using best saved model):\n",
      "Male: {'accuracy': 0.24203821656050956, 'precision': 0.14423664306017248, 'recall': 0.2593164383204608, 'f1': 0.16530681542566095}\n",
      "Female: {'accuracy': 0.371875, 'precision': 0.23380694646336558, 'recall': 0.29702058504875406, 'f1': 0.22648083623693385}\n",
      "\n",
      "--- Summary for CNNBaseline_BatchNorm ---\n",
      "- Total epochs trained: 29\n",
      "- Best validation accuracy during training: 30.757%\n",
      "- Training accuracy of loaded (best saved) model: 32.35%\n",
      "- Best model saved to: /Users/larsheijnen/DL/saved_models/A/not_augmented_earlystop/CNNBaseline_BatchNorm_not_augmented_best_1d_earlystop.pth\n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "=== Training model: CNNBaseline_Dropout3 (Early Stopping) ===\n",
      "Epoch   1/150 | Train Loss: 1012.034 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 0/20\n",
      "    → New best test accuracy: 21.767% (saved to /Users/larsheijnen/DL/saved_models/A/not_augmented_earlystop/CNNBaseline_Dropout3_not_augmented_best_1d_earlystop.pth)\n",
      "Epoch   2/150 | Train Loss: 1010.506 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 0/20\n",
      "Epoch   3/150 | Train Loss: 1010.147 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 1/20\n",
      "    → New best test accuracy: 23.659% (saved to /Users/larsheijnen/DL/saved_models/A/not_augmented_earlystop/CNNBaseline_Dropout3_not_augmented_best_1d_earlystop.pth)\n",
      "Epoch   4/150 | Train Loss: 1009.963 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 0/20\n",
      "Epoch   5/150 | Train Loss: 1009.942 | Train Acc: 23.82% | Train Prec:  4.76% | Train Recall: 19.97% | Train F1:  7.69% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 1/20\n",
      "Epoch   6/150 | Train Loss: 1009.782 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 2/20\n",
      "Epoch   7/150 | Train Loss: 1009.806 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 3/20\n",
      "Epoch   8/150 | Train Loss: 1009.722 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 4/20\n",
      "Epoch   9/150 | Train Loss: 1009.566 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 5/20\n",
      "Epoch  10/150 | Train Loss: 1009.450 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 6/20\n",
      "Epoch  11/150 | Train Loss: 1009.557 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 7/20\n",
      "Epoch  12/150 | Train Loss: 1009.692 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 8/20\n",
      "Epoch  13/150 | Train Loss: 1009.419 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 9/20\n",
      "Epoch  14/150 | Train Loss: 1009.261 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 10/20\n",
      "Epoch  15/150 | Train Loss: 1009.266 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 11/20\n",
      "Epoch  16/150 | Train Loss: 1009.441 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 12/20\n",
      "Epoch  17/150 | Train Loss: 1009.303 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 13/20\n",
      "Epoch  18/150 | Train Loss: 1009.323 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 14/20\n",
      "Epoch  19/150 | Train Loss: 1009.245 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 15/20\n",
      "Epoch  20/150 | Train Loss: 1009.544 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 16/20\n",
      "Epoch  21/150 | Train Loss: 1009.125 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 17/20\n",
      "Epoch  22/150 | Train Loss: 1009.391 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 18/20\n",
      "Epoch  23/150 | Train Loss: 1009.413 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 19/20\n",
      "\n",
      "Early stopping triggered for CNNBaseline_Dropout3 after 23 epochs.\n",
      "Final training state for CNNBaseline_Dropout3 saved to /Users/larsheijnen/DL/saved_models/A/not_augmented_earlystop/CNNBaseline_Dropout3_not_augmented_latest_1d_earlystop.pth\n",
      "\n",
      "Training completed for CNNBaseline_Dropout3 after 23 epochs.\n",
      "Best test accuracy achieved during training: 23.659%\n",
      "\n",
      "Loading best saved model for CNNBaseline_Dropout3 from /Users/larsheijnen/DL/saved_models/A/not_augmented_earlystop/CNNBaseline_Dropout3_not_augmented_best_1d_earlystop.pth for final evaluation...\n",
      "\n",
      "Classification Report for CNNBaseline_Dropout3 (using best saved model):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       138\n",
      "           1      0.000     0.000     0.000       118\n",
      "           2      0.000     0.000     0.000       120\n",
      "           3      0.237     1.000     0.383       150\n",
      "           4      0.000     0.000     0.000       108\n",
      "\n",
      "    accuracy                          0.237       634\n",
      "   macro avg      0.047     0.200     0.077       634\n",
      "weighted avg      0.056     0.237     0.091       634\n",
      "\n",
      "\n",
      "Gender breakdown for CNNBaseline_Dropout3 (using best saved model):\n",
      "Male: {'accuracy': 0.2515923566878981, 'precision': 0.05031847133757962, 'recall': 0.2, 'f1': 0.08040712468193384}\n",
      "Female: {'accuracy': 0.221875, 'precision': 0.044375, 'recall': 0.2, 'f1': 0.07263427109974424}\n",
      "\n",
      "--- Summary for CNNBaseline_Dropout3 ---\n",
      "- Total epochs trained: 23\n",
      "- Best validation accuracy during training: 23.659%\n",
      "- Training accuracy of loaded (best saved) model: 23.85%\n",
      "- Best model saved to: /Users/larsheijnen/DL/saved_models/A/not_augmented_earlystop/CNNBaseline_Dropout3_not_augmented_best_1d_earlystop.pth\n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "=== Training model: CNNBaseline_Dropout5 (Early Stopping) ===\n",
      "Epoch   1/150 | Train Loss: 1012.290 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 0/20\n",
      "    → New best test accuracy: 23.659% (saved to /Users/larsheijnen/DL/saved_models/A/not_augmented_earlystop/CNNBaseline_Dropout5_not_augmented_best_1d_earlystop.pth)\n",
      "Epoch   2/150 | Train Loss: 1010.279 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 0/20\n",
      "Epoch   3/150 | Train Loss: 1010.945 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 1/20\n",
      "Epoch   4/150 | Train Loss: 1010.501 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 2/20\n",
      "Epoch   5/150 | Train Loss: 1010.652 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 3/20\n",
      "Epoch   6/150 | Train Loss: 1010.253 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 4/20\n",
      "Epoch   7/150 | Train Loss: 1009.843 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 5/20\n",
      "Epoch   8/150 | Train Loss: 1009.744 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 6/20\n",
      "Epoch   9/150 | Train Loss: 1009.223 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 7/20\n",
      "Epoch  10/150 | Train Loss: 1009.716 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 8/20\n",
      "Epoch  11/150 | Train Loss: 1009.908 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 9/20\n",
      "Epoch  12/150 | Train Loss: 1009.909 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 10/20\n",
      "Epoch  13/150 | Train Loss: 1009.555 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 11/20\n",
      "Epoch  14/150 | Train Loss: 1009.679 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 12/20\n",
      "Epoch  15/150 | Train Loss: 1009.373 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.71% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 13/20\n",
      "Epoch  16/150 | Train Loss: 1009.539 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 14/20\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "import os\n",
    "\n",
    "# Prepare dataset & split\n",
    "dataset = AccentRawWaveformDataset(\n",
    "    '/Users/larsheijnen/DL/Train',\n",
    "    target_sr=16000,\n",
    "    standardize=True\n",
    ")\n",
    "\n",
    "train_len = int(0.8 * len(dataset))\n",
    "test_len  = len(dataset) - train_len\n",
    "train_ds, test_ds = random_split(dataset, [train_len, test_len], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True,  collate_fn=pad_1d_collate)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=4, shuffle=False, collate_fn=pad_1d_collate)\n",
    "\n",
    "device    = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def evaluate(loader, model, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for specs, labels, _ in loader:\n",
    "            specs, labels = specs.to(device), labels.to(device)\n",
    "            outputs = model(specs)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_labels.extend(labels.cpu().tolist())\n",
    "    acc    = accuracy_score(all_labels, all_preds)\n",
    "    prec   = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='macro')\n",
    "    f1     = f1_score(all_labels, all_preds, average='macro')\n",
    "    return acc, prec, recall, f1\n",
    "\n",
    "def evaluate_by_gender(loader, model, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels, all_genders = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for specs, labels, genders in loader:\n",
    "            specs, labels = specs.to(device), labels.to(device)\n",
    "            outputs = model(specs)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_labels.extend(labels.cpu().tolist())\n",
    "            all_genders.extend(genders)\n",
    "    results = {}\n",
    "    for gender in ['m', 'f']:\n",
    "        idxs = [i for i, g in enumerate(all_genders) if g == gender]\n",
    "        gender_preds = [all_preds[i] for i in idxs]\n",
    "        gender_labels = [all_labels[i] for i in idxs]\n",
    "        acc = accuracy_score(gender_labels, gender_preds)\n",
    "        prec = precision_score(gender_labels, gender_preds, average='macro', zero_division=0)\n",
    "        recall = recall_score(gender_labels, gender_preds, average='macro')\n",
    "        f1 = f1_score(gender_labels, gender_preds, average='macro')\n",
    "        results[gender] = {'accuracy': acc, 'precision': prec, 'recall': recall, 'f1': f1}\n",
    "    return results\n",
    "\n",
    "def classification_report_for_model(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for specs, labels, _ in loader:\n",
    "            specs, labels = specs.to(device), labels.to(device)\n",
    "            outputs = model(specs)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_labels.extend(labels.cpu().tolist())\n",
    "    print(classification_report(all_labels, all_preds, digits=3))\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 20\n",
    "max_epochs = 150\n",
    "min_improvement = 0.005\n",
    "\n",
    "save_dir_base = \"/Users/larsheijnen/DL/saved_models/A/not_augmented_earlystop\"\n",
    "os.makedirs(save_dir_base, exist_ok=True)\n",
    "\n",
    "for model_name, model_class in models_dict.items():\n",
    "    model = model_class().to(device)\n",
    "    print(f\"\\n=== Training model: {type(model).__name__} (Early Stopping) ===\")\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "    best_test_acc = 0.0\n",
    "    patience_counter = 0\n",
    "\n",
    "    best_model_path = os.path.join(save_dir_base, f\"{type(model).__name__}_not_augmented_best_1d_earlystop.pth\")\n",
    "    final_model_path = os.path.join(save_dir_base, f\"{type(model).__name__}_not_augmented_latest_1d_earlystop.pth\")\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for specs, labels, genders in train_loader:\n",
    "            specs, labels = specs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(specs), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Compute and print general metrics for this epoch (not by gender)\n",
    "        train_acc, train_prec, train_recall, train_f1 = evaluate(train_loader, model, device)\n",
    "        test_acc, test_prec, test_recall, test_f1 = evaluate(test_loader, model, device)\n",
    "        print(\n",
    "            f\"Epoch {epoch+1:3d}/{max_epochs} | \"\n",
    "            f\"Train Loss: {running_loss:.3f} | \"\n",
    "            f\"Train Acc: {train_acc*100:5.2f}% | \"\n",
    "            f\"Train Prec: {train_prec*100:5.2f}% | \"\n",
    "            f\"Train Recall: {train_recall*100:5.2f}% | \"\n",
    "            f\"Train F1: {train_f1*100:5.2f}% || \"\n",
    "            f\"Test Acc: {test_acc*100:5.2f}% | \"\n",
    "            f\"Test Prec: {test_prec*100:5.2f}% | \"\n",
    "            f\"Test Recall: {test_recall*100:5.2f}% | \"\n",
    "            f\"Test F1: {test_f1*100:5.2f}% | \"\n",
    "            f\"Patience: {patience_counter}/{patience}\"\n",
    "        )\n",
    "\n",
    "        if test_acc > best_test_acc + min_improvement:\n",
    "            best_test_acc = test_acc\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"    → New best test accuracy: {best_test_acc*100:.3f}% (saved to {best_model_path})\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\nEarly stopping triggered for {type(model).__name__} after {epoch+1} epochs.\")\n",
    "            break\n",
    "\n",
    "    torch.save(model.state_dict(), final_model_path)\n",
    "    print(f\"Final training state for {type(model).__name__} saved to {final_model_path}\")\n",
    "    print(f\"\\nTraining completed for {type(model).__name__} after {epoch+1} epochs.\")\n",
    "    print(f\"Best test accuracy achieved during training: {best_test_acc*100:.3f}%\")\n",
    "\n",
    "    # Load the best model for final evaluation\n",
    "    if os.path.exists(best_model_path):\n",
    "        print(f\"\\nLoading best saved model for {type(model).__name__} from {best_model_path} for final evaluation...\")\n",
    "        model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "        eval_model_description = \"best saved\"\n",
    "    else:\n",
    "        print(f\"\\nNo best model was saved for {type(model).__name__}. Using final model state for evaluation.\")\n",
    "        eval_model_description = \"final\"\n",
    "\n",
    "    print(f\"\\nClassification Report for {type(model).__name__} (using {eval_model_description} model):\")\n",
    "    classification_report_for_model(model, test_loader, device)\n",
    "\n",
    "    print(f\"\\nGender breakdown for {type(model).__name__} (using {eval_model_description} model):\")\n",
    "    gender_results = evaluate_by_gender(test_loader, model, device)\n",
    "    for gender in gender_results:\n",
    "        label = \"Male\" if gender == \"m\" else \"Female\"\n",
    "        print(f\"{label}: {gender_results[gender]}\")\n",
    "\n",
    "    final_train_acc, _, _, _ = evaluate(train_loader, model, device)\n",
    "    print(f\"\\n--- Summary for {type(model).__name__} ---\")\n",
    "    print(f\"- Total epochs trained: {epoch+1}\")\n",
    "    print(f\"- Best validation accuracy during training: {best_test_acc*100:.3f}%\")\n",
    "    print(f\"- Training accuracy of loaded ({eval_model_description}) model: {final_train_acc*100:.2f}%\")\n",
    "    if os.path.exists(best_model_path):\n",
    "        print(f\"- Best model saved to: {best_model_path}\")\n",
    "    else:\n",
    "        print(f\"- Best model not saved (or final model is the best achieved). Final model at: {final_model_path}\")\n",
    "    print(f\"---------------------------------------\\n\")\n",
    "\n",
    "print(\"\\nAll model configurations have been trained and evaluated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting acccent on Test data\n",
    "\n",
    "To hand in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = AccentRawWaveformDataset(\n",
    "    '/Users/larsheijnen/DL/Test set',\n",
    "    target_sr=16000,\n",
    "    standardize=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, collate_fn=pad_1d_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# Dynamically determine the saved models directory relative to this script or notebook\n",
    "base_dir = os.path.dirname(os.path.abspath('assignment_A.ipynb'))  # or __file__ if in .py\n",
    "saved_models_dir = os.path.join(base_dir, \"saved_models\", \"A\", \"not_augmented\")\n",
    "\n",
    "# List all .pth files in the directory\n",
    "model_files = [f for f in os.listdir(saved_models_dir) if f.endswith(\".pth\")]\n",
    "\n",
    "# Map model file names to their classes (assumes naming convention: class name is prefix before first underscore or before '_latest')\n",
    "model_classes = {}\n",
    "for fname in model_files:\n",
    "    if fname.startswith(\"CNNBaseline_Dropout3_BatchNorm\"):\n",
    "        model_classes[fname] = CNNBaseline_Dropout3_BatchNorm\n",
    "    elif fname.startswith(\"CNNBaseline_Dropout5_BatchNorm\"):\n",
    "        model_classes[fname] = CNNBaseline_Dropout5_BatchNorm\n",
    "    elif fname.startswith(\"CNNBaseline_Dropout3\"):\n",
    "        model_classes[fname] = CNNBaseline_Dropout3\n",
    "    elif fname.startswith(\"CNNBaseline_Dropout5\"):\n",
    "        model_classes[fname] = CNNBaseline_Dropout5\n",
    "    elif fname.startswith(\"CNNBaseline_BatchNorm\"):\n",
    "        model_classes[fname] = CNNBaseline_BatchNorm\n",
    "    elif fname.startswith(\"CNNBaseline\"):\n",
    "        model_classes[fname] = CNNBaseline\n",
    "    # Add more elifs if you have more model types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_accent_on_testset(model, test_loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_fnames = []\n",
    "    with torch.no_grad():\n",
    "        for i, (specs, _, _) in enumerate(test_loader):  # gender is ignored\n",
    "            specs = specs.to(device)\n",
    "            outputs = model(specs)\n",
    "            preds = outputs.argmax(dim=1).cpu().tolist()\n",
    "            all_preds.extend(preds)\n",
    "            # Get filenames for this batch\n",
    "            batch_indices = range(i * test_loader.batch_size, i * test_loader.batch_size + len(preds))\n",
    "            fnames = [os.path.basename(test_dataset.file_paths[idx]) for idx in batch_indices]\n",
    "            all_fnames.extend(fnames)\n",
    "    return list(zip(all_fnames, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "for model_file, model_class in model_classes.items():\n",
    "    model = model_class().to(device)\n",
    "    model_path = os.path.join(saved_models_dir, model_file)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "    print(f\"\\nPredictions for model: {model_file}\")\n",
    "    results = predict_accent_on_testset(model, test_loader, device)\n",
    "    for fname, pred in results:\n",
    "        print(f\"File: {fname} | Predicted Accent: {pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check models on train data\n",
    "\n",
    "Checking predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_dataset = AccentRawWaveformDataset(\n",
    "    '/Users/larsheijnen/DL/Train',\n",
    "    target_sr=16000,\n",
    "    standardize=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, collate_fn=pad_1d_collate)\n",
    "\n",
    "np.random.seed(42)\n",
    "subset_indices = np.random.choice(len(full_train_dataset), size=100, replace=False)\n",
    "subset_dataset = Subset(full_train_dataset, subset_indices)\n",
    "subset_loader = DataLoader(subset_dataset, batch_size=4, shuffle=False, collate_fn=pad_1d_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_subset(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_fnames = []\n",
    "    with torch.no_grad():\n",
    "        for i, (specs, labels, _) in enumerate(loader):  # ignore gender\n",
    "            specs = specs.to(device)\n",
    "            outputs = model(specs)\n",
    "            preds = outputs.argmax(dim=1).cpu().tolist()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.tolist())\n",
    "            # Get filenames for this batch\n",
    "            batch_indices = range(i * loader.batch_size, i * loader.batch_size + len(preds))\n",
    "            fnames = [os.path.basename(full_train_dataset.file_paths[idx]) for idx in subset_indices[batch_indices.start:batch_indices.stop]]\n",
    "            all_fnames.extend(fnames)\n",
    "    return list(zip(all_fnames, all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_file in model_files:\n",
    "    model_class = model_classes[model_file]\n",
    "    model = model_class().to(device)\n",
    "    model_path = os.path.join(saved_models_dir, model_file)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "    print(f\"\\nEvaluation on subset for model: {model_file}\")\n",
    "    results = evaluate_on_subset(model, subset_loader, device)\n",
    "    correct = 0\n",
    "    for fname, true_label, pred_label in results:\n",
    "        is_correct = true_label == pred_label\n",
    "        correct += is_correct\n",
    "        print(f\"File: {fname} | True Accent: {true_label + 1} | Predicted Accent: {pred_label + 1} | {'✔️' if is_correct else '❌'}\")\n",
    "    print(f\"Accuracy on subset: {correct/len(results)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation\n",
    "\n",
    "Hier voegen we onder andere noise toe, en trainen we de modellen opnieuw. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import os\n",
    "\n",
    "class AccentRawWaveformDatasetAug(AccentRawWaveformDataset):\n",
    "    def __init__(self, *args, noise_level=0.005, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.noise_level = noise_level\n",
    "\n",
    "    def add_noise(self, waveform, noise_level=None):\n",
    "        if noise_level is None:\n",
    "            noise_level = self.noise_level\n",
    "        noise = torch.randn_like(waveform) * noise_level\n",
    "        return waveform + noise\n",
    "\n",
    "    def time_shift(self, waveform, shift_max=0.2):\n",
    "        shift = int(waveform.size(1) * shift_max * (2 * torch.rand(1) - 1))\n",
    "        return torch.roll(waveform, shifts=shift, dims=1)\n",
    "\n",
    "    def random_volume(self, waveform, min_gain=0.8, max_gain=1.2):\n",
    "        gain = torch.empty(1).uniform_(min_gain, max_gain)\n",
    "        return waveform * gain\n",
    "\n",
    "    def augment(self, waveform, sr):\n",
    "        if torch.rand(1).item() < 0.5:\n",
    "            waveform = self.add_noise(waveform)\n",
    "        if torch.rand(1).item() < 0.5:\n",
    "            waveform = self.time_shift(waveform)\n",
    "        if torch.rand(1).item() < 0.5:\n",
    "            waveform = self.random_volume(waveform)\n",
    "        return waveform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        waveform, accent, gender = super().__getitem__(idx)\n",
    "        waveform = self.augment(waveform, self.target_sr)\n",
    "        return waveform, accent, gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def pad_1d_collate(batch, target_length=208):\n",
    "    waveforms, accents, genders = zip(*batch)\n",
    "    padded_waveforms = []\n",
    "    for w in waveforms:\n",
    "        pad_amount = target_length - w.shape[-1]\n",
    "        if pad_amount > 0:\n",
    "            # Pad at the end (right side) for 1D waveform\n",
    "            padded = F.pad(w, (0, pad_amount))\n",
    "        else:\n",
    "            padded = w[..., :target_length]\n",
    "        padded_waveforms.append(padded)\n",
    "    return (\n",
    "        torch.stack(padded_waveforms),  # (B, 1, T)\n",
    "        torch.tensor(accents),\n",
    "        list(genders)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in dataset: 3166\n",
      "Sample 0 waveform shape: torch.Size([1, 41400])\n",
      "Sample 0 accent label: 1\n",
      "Sample 0 gender label: m\n"
     ]
    }
   ],
   "source": [
    "# Let's instantiate the dataset and inspect a sample\n",
    "# (Assume the folder path is './data' - change as needed)\n",
    "dataset = AccentRawWaveformDatasetAug(\"/Users/larsheijnen/DL/Train\")\n",
    "\n",
    "print(f\"Number of samples in dataset: {len(dataset)}\")\n",
    "\n",
    "# Get the first sample\n",
    "sample_waveform, sample_accent, sample_gender = dataset[0]\n",
    "\n",
    "print(\"Sample 0 waveform shape:\", sample_waveform.shape)\n",
    "print(\"Sample 0 accent label:\", sample_accent)\n",
    "print(\"Sample 0 gender label:\", sample_gender)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waveforms: torch.Size([4, 1, 208])\n",
      "Accents: tensor([3, 3, 0, 0])\n",
      "Gender: ['m', 'm', 'f', 'f']\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Use batch_size=4 for low RAM, pin_memory is False for macOS/MPS\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=pad_1d_collate, pin_memory=False)\n",
    "\n",
    "# Try again\n",
    "for batch in dataloader:\n",
    "    waveforms, accents, gender = batch\n",
    "    print(f\"Waveforms: {waveforms.shape}\")  # (B, 1, T)\n",
    "    print(f\"Accents: {accents}\")            # (B,)\n",
    "    print(f\"Gender: {gender}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Model 1 (baseline)\n",
    "class CNNBaseline(nn.Module):\n",
    "    def __init__(self, num_classes: int = 5):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 8, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(8, 16, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(16)  # Output: (B, 32, 256)\n",
    "        self.fc = nn.Linear(32 * 16, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, 1, T)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool(x)  # (B, 32, 256)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Model 2 (baseline + batch normalization)\n",
    "class CNNBaseline_BatchNorm(nn.Module):\n",
    "    def __init__(self, num_classes: int = 5):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 8, kernel_size=3, padding=1)\n",
    "        self.bn1   = nn.BatchNorm1d(8)\n",
    "        self.conv2 = nn.Conv1d(8, 16, kernel_size=3, padding=1)\n",
    "        self.bn2   = nn.BatchNorm1d(16)\n",
    "        self.conv3 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn3   = nn.BatchNorm1d(32)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(16)\n",
    "        self.fc = nn.Linear(32 * 16, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Model 3 (baseline + dropout 0.3)\n",
    "class CNNBaseline_Dropout3(nn.Module):\n",
    "    def __init__(self, num_classes: int = 5, dropout_p: float = 0.3):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 8, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(8, 16, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(16)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.fc = nn.Linear(32 * 16, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Model 4 (baseline + dropout 0.5)\n",
    "class CNNBaseline_Dropout5(nn.Module):\n",
    "    def __init__(self, num_classes: int = 5, dropout_p: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 8, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(8, 16, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(16)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.fc = nn.Linear(32 * 16, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Model 5 (baseline + batch normalization + dropout 0.3)\n",
    "class CNNBaseline_Dropout3_BatchNorm(nn.Module):\n",
    "    def __init__(self, num_classes: int = 5, dropout_p: float = 0.3):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 8, kernel_size=3, padding=1)\n",
    "        self.bn1   = nn.BatchNorm1d(8)\n",
    "        self.conv2 = nn.Conv1d(8, 16, kernel_size=3, padding=1)\n",
    "        self.bn2   = nn.BatchNorm1d(16)\n",
    "        self.conv3 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn3   = nn.BatchNorm1d(32)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(16)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.fc = nn.Linear(32 * 16, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Model 6 (baseline + batch normalization + dropout 0.5)\n",
    "class CNNBaseline_Dropout5_BatchNorm(nn.Module):\n",
    "    def __init__(self, num_classes: int = 5, dropout_p: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 8, kernel_size=3, padding=1)\n",
    "        self.bn1   = nn.BatchNorm1d(8)\n",
    "        self.conv2 = nn.Conv1d(8, 16, kernel_size=3, padding=1)\n",
    "        self.bn2   = nn.BatchNorm1d(16)\n",
    "        self.conv3 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn3   = nn.BatchNorm1d(32)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(16)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.fc = nn.Linear(32 * 16, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {\n",
    "    \"Model1\": CNNBaseline,\n",
    "    \"Model2\": CNNBaseline_BatchNorm, \n",
    "    \"Model3\": CNNBaseline_Dropout3,\n",
    "    \"Model4\": CNNBaseline_Dropout5,\n",
    "    \"Model5\": CNNBaseline_Dropout3_BatchNorm,\n",
    "    \"Model6\": CNNBaseline_Dropout5_BatchNorm,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training model: CNNBaseline ===\n",
      "Epoch  1 | Train Loss: 1011.558 | Train Acc: 23.70% | Train Prec: 14.36% | Train Recall: 20.33% | Train F1: 10.29% || Test Acc: 22.40% | Test Prec: 18.00% | Test Recall: 20.79% | Test F1: 10.11%\n",
      "Epoch  2 | Train Loss: 1011.026 | Train Acc: 23.38% | Train Prec:  7.40% | Train Recall: 19.60% | Train F1:  8.25% || Test Acc: 23.66% | Test Prec: 10.86% | Test Recall: 20.05% | Test F1:  8.63%\n",
      "Epoch  3 | Train Loss: 1010.271 | Train Acc: 24.01% | Train Prec: 29.26% | Train Recall: 20.21% | Train F1:  9.15% || Test Acc: 22.24% | Test Prec:  9.28% | Test Recall: 20.34% | Test F1:  8.96%\n",
      "Epoch  4 | Train Loss: 1010.286 | Train Acc: 23.70% | Train Prec:  7.48% | Train Recall: 19.90% | Train F1:  7.93% || Test Acc: 23.82% | Test Prec:  8.78% | Test Recall: 20.17% | Test F1:  8.03%\n",
      "Epoch  5 | Train Loss: 1009.960 | Train Acc: 24.01% | Train Prec: 14.05% | Train Recall: 20.47% | Train F1: 10.83% || Test Acc: 23.19% | Test Prec: 17.53% | Test Recall: 21.26% | Test F1: 10.93%\n",
      "Epoch  6 | Train Loss: 1010.110 | Train Acc: 24.13% | Train Prec:  9.69% | Train Recall: 20.30% | Train F1:  8.77% || Test Acc: 22.08% | Test Prec: 10.26% | Test Recall: 20.23% | Test F1:  8.35%\n",
      "Epoch  7 | Train Loss: 1009.771 | Train Acc: 23.85% | Train Prec:  4.78% | Train Recall: 20.00% | Train F1:  7.71% || Test Acc: 23.50% | Test Prec:  4.72% | Test Recall: 19.87% | Test F1:  7.62%\n",
      "Epoch  8 | Train Loss: 1009.434 | Train Acc: 24.37% | Train Prec: 10.06% | Train Recall: 20.49% | Train F1: 10.01% || Test Acc: 21.45% | Test Prec:  7.96% | Test Recall: 19.64% | Test F1:  8.35%\n",
      "Epoch  9 | Train Loss: 1009.841 | Train Acc: 24.17% | Train Prec:  9.90% | Train Recall: 20.33% | Train F1:  9.42% || Test Acc: 22.08% | Test Prec:  7.61% | Test Recall: 20.23% | Test F1:  8.40%\n",
      "Epoch 10 | Train Loss: 1009.140 | Train Acc: 24.21% | Train Prec: 10.19% | Train Recall: 20.36% | Train F1:  9.03% || Test Acc: 22.08% | Test Prec: 10.26% | Test Recall: 20.23% | Test F1:  8.35%\n",
      "\n",
      "Classification Report for CNNBaseline:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.221     0.978     0.360       138\n",
      "           1      0.000     0.000     0.000       118\n",
      "           2      0.000     0.000     0.000       120\n",
      "           3      0.273     0.040     0.070       150\n",
      "           4      0.000     0.000     0.000       108\n",
      "\n",
      "    accuracy                          0.222       634\n",
      "   macro avg      0.099     0.204     0.086       634\n",
      "weighted avg      0.113     0.222     0.095       634\n",
      "\n",
      "\n",
      "Gender breakdown for CNNBaseline:\n",
      "Male: {'accuracy': 0.1592356687898089, 'precision': 0.11026315789473684, 'recall': 0.20587126312954482, 'f1': 0.07039918051154007}\n",
      "Female: {'accuracy': 0.3, 'precision': 0.16437158469945357, 'recall': 0.21594180467419904, 'f1': 0.12609819121447027}\n",
      "\n",
      "=== Training model: CNNBaseline_BatchNorm ===\n",
      "Epoch  1 | Train Loss: 1023.051 | Train Acc: 17.61% | Train Prec: 15.28% | Train Recall: 19.61% | Train F1:  8.42% || Test Acc: 20.50% | Test Prec: 17.87% | Test Recall: 21.29% | Test F1: 10.46%\n",
      "Epoch  2 | Train Loss: 1007.700 | Train Acc: 15.09% | Train Prec: 15.26% | Train Recall: 19.88% | Train F1:  6.85% || Test Acc: 17.19% | Test Prec: 20.57% | Test Recall: 19.82% | Test F1:  7.96%\n",
      "Epoch  3 | Train Loss: 996.717 | Train Acc: 23.38% | Train Prec: 11.08% | Train Recall: 19.89% | Train F1:  9.17% || Test Acc: 24.13% | Test Prec: 18.29% | Test Recall: 20.84% | Test F1: 10.92%\n",
      "Epoch  4 | Train Loss: 1000.629 | Train Acc: 21.01% | Train Prec: 19.04% | Train Recall: 21.10% | Train F1: 11.52% || Test Acc: 19.40% | Test Prec: 37.46% | Test Recall: 20.69% | Test F1: 10.57%\n",
      "Epoch  5 | Train Loss: 996.010 | Train Acc: 19.83% | Train Prec: 10.96% | Train Recall: 19.94% | Train F1:  8.44% || Test Acc: 18.45% | Test Prec: 11.96% | Test Recall: 19.89% | Test F1:  8.11%\n",
      "Epoch  6 | Train Loss: 994.810 | Train Acc: 23.66% | Train Prec: 25.85% | Train Recall: 19.91% | Train F1:  8.16% || Test Acc: 23.34% | Test Prec:  4.73% | Test Recall: 19.73% | Test F1:  7.63%\n",
      "Epoch  7 | Train Loss: 984.216 | Train Acc: 21.21% | Train Prec: 16.11% | Train Recall: 19.43% | Train F1: 13.45% || Test Acc: 20.50% | Test Prec: 11.84% | Test Recall: 19.64% | Test F1: 13.32%\n",
      "Epoch  8 | Train Loss: 987.661 | Train Acc: 19.15% | Train Prec: 21.75% | Train Recall: 20.66% | Train F1: 13.92% || Test Acc: 18.45% | Test Prec: 38.31% | Test Recall: 19.55% | Test F1: 14.38%\n",
      "Epoch  9 | Train Loss: 986.180 | Train Acc: 22.55% | Train Prec: 17.98% | Train Recall: 19.31% | Train F1: 11.61% || Test Acc: 21.29% | Test Prec: 15.95% | Test Recall: 18.67% | Test F1: 11.93%\n",
      "Epoch 10 | Train Loss: 982.297 | Train Acc: 22.95% | Train Prec: 13.39% | Train Recall: 19.30% | Train F1:  9.46% || Test Acc: 23.19% | Test Prec: 20.99% | Test Recall: 19.75% | Test F1:  9.38%\n",
      "\n",
      "Classification Report for CNNBaseline_BatchNorm:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.159     0.051     0.077       138\n",
      "           1      0.000     0.000     0.000       118\n",
      "           2      0.000     0.000     0.000       120\n",
      "           3      0.233     0.913     0.371       150\n",
      "           4      0.000     0.000     0.000       108\n",
      "\n",
      "    accuracy                          0.227       634\n",
      "   macro avg      0.078     0.193     0.090       634\n",
      "weighted avg      0.090     0.227     0.105       634\n",
      "\n",
      "\n",
      "Gender breakdown for CNNBaseline_BatchNorm:\n",
      "Male: {'accuracy': 0.2197452229299363, 'precision': 0.25997644287396937, 'recall': 0.1793728307984694, 'f1': 0.09072519459259791}\n",
      "Female: {'accuracy': 0.228125, 'precision': 0.10782456140350875, 'recall': 0.20191920755301038, 'f1': 0.09405537858368047}\n",
      "\n",
      "=== Training model: CNNBaseline_Dropout3 ===\n",
      "Epoch  1 | Train Loss: 1011.900 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15%\n",
      "Epoch  2 | Train Loss: 1010.774 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15%\n",
      "Epoch  3 | Train Loss: 1010.672 | Train Acc: 23.89% | Train Prec: 11.44% | Train Recall: 20.03% | Train F1:  7.78% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65%\n",
      "Epoch  4 | Train Loss: 1010.174 | Train Acc: 23.66% | Train Prec:  7.76% | Train Recall: 19.91% | Train F1:  8.16% || Test Acc: 23.50% | Test Prec:  6.96% | Test Recall: 19.90% | Test F1:  7.95%\n",
      "Epoch  5 | Train Loss: 1010.660 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65%\n",
      "Epoch  6 | Train Loss: 1009.787 | Train Acc: 24.21% | Train Prec: 12.02% | Train Recall: 20.37% | Train F1:  9.82% || Test Acc: 22.24% | Test Prec:  9.19% | Test Recall: 20.32% | Test F1:  9.26%\n",
      "Epoch  7 | Train Loss: 1010.199 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65%\n",
      "Epoch  8 | Train Loss: 1009.761 | Train Acc: 24.01% | Train Prec:  9.87% | Train Recall: 20.20% | Train F1:  8.72% || Test Acc: 21.77% | Test Prec:  9.33% | Test Recall: 19.94% | Test F1:  8.25%\n",
      "Epoch  9 | Train Loss: 1009.907 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65%\n",
      "Epoch 10 | Train Loss: 1008.992 | Train Acc: 23.93% | Train Prec: 18.11% | Train Recall: 20.08% | Train F1:  7.87% || Test Acc: 23.66% | Test Prec:  4.74% | Test Recall: 20.00% | Test F1:  7.66%\n",
      "\n",
      "Classification Report for CNNBaseline_Dropout3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       138\n",
      "           1      0.000     0.000     0.000       118\n",
      "           2      0.000     0.000     0.000       120\n",
      "           3      0.237     1.000     0.383       150\n",
      "           4      0.000     0.000     0.000       108\n",
      "\n",
      "    accuracy                          0.237       634\n",
      "   macro avg      0.047     0.200     0.077       634\n",
      "weighted avg      0.056     0.237     0.091       634\n",
      "\n",
      "\n",
      "Gender breakdown for CNNBaseline_Dropout3:\n",
      "Male: {'accuracy': 0.2515923566878981, 'precision': 0.05047923322683706, 'recall': 0.2, 'f1': 0.08061224489795918}\n",
      "Female: {'accuracy': 0.221875, 'precision': 0.044375, 'recall': 0.2, 'f1': 0.07263427109974424}\n",
      "\n",
      "=== Training model: CNNBaseline_Dropout5 ===\n",
      "Epoch  1 | Train Loss: 1012.424 | Train Acc: 23.89% | Train Prec: 23.28% | Train Recall: 20.22% | Train F1:  9.03% || Test Acc: 22.56% | Test Prec:  9.07% | Test Recall: 20.85% | Test F1:  8.81%\n",
      "Epoch  2 | Train Loss: 1010.783 | Train Acc: 23.82% | Train Prec: 20.09% | Train Recall: 20.00% | Train F1:  8.06% || Test Acc: 23.66% | Test Prec:  4.76% | Test Recall: 20.00% | Test F1:  7.69%\n",
      "Epoch  3 | Train Loss: 1010.631 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.36% | Test Recall: 20.00% | Test F1:  7.16%\n",
      "Epoch  4 | Train Loss: 1010.495 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15%\n",
      "Epoch  5 | Train Loss: 1010.241 | Train Acc: 23.85% | Train Prec:  8.77% | Train Recall: 20.07% | Train F1:  7.84% || Test Acc: 21.92% | Test Prec: 11.04% | Test Recall: 20.13% | Test F1:  7.44%\n",
      "Epoch  6 | Train Loss: 1009.917 | Train Acc: 23.74% | Train Prec: 11.43% | Train Recall: 19.90% | Train F1:  7.75% || Test Acc: 23.66% | Test Prec:  4.75% | Test Recall: 20.00% | Test F1:  7.67%\n",
      "Epoch  7 | Train Loss: 1009.965 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15%\n",
      "Epoch  8 | Train Loss: 1009.654 | Train Acc: 23.82% | Train Prec: 24.76% | Train Recall: 20.03% | Train F1:  7.75% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15%\n",
      "Epoch  9 | Train Loss: 1009.111 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.69% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15%\n",
      "Epoch 10 | Train Loss: 1008.762 | Train Acc: 23.97% | Train Prec:  9.17% | Train Recall: 20.16% | Train F1:  8.46% || Test Acc: 22.71% | Test Prec: 13.18% | Test Recall: 20.79% | Test F1:  8.94%\n",
      "\n",
      "Classification Report for CNNBaseline_Dropout5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.223     0.993     0.364       138\n",
      "           1      0.000     0.000     0.000       118\n",
      "           2      0.000     0.000     0.000       120\n",
      "           3      0.368     0.047     0.083       150\n",
      "           4      0.000     0.000     0.000       108\n",
      "\n",
      "    accuracy                          0.227       634\n",
      "   macro avg      0.118     0.208     0.089       634\n",
      "weighted avg      0.136     0.227     0.099       634\n",
      "\n",
      "\n",
      "Gender breakdown for CNNBaseline_Dropout5:\n",
      "Male: {'accuracy': 0.15286624203821655, 'precision': 0.08032258064516129, 'recall': 0.20253164556962028, 'f1': 0.057480341534204046}\n",
      "Female: {'accuracy': 0.275, 'precision': 0.08076923076923077, 'recall': 0.19402569261724192, 'f1': 0.09141564845933978}\n",
      "\n",
      "=== Training model: CNNBaseline_Dropout3_BatchNorm ===\n",
      "Epoch  1 | Train Loss: 1031.285 | Train Acc: 24.05% | Train Prec: 20.62% | Train Recall: 20.80% | Train F1: 11.13% || Test Acc: 20.82% | Test Prec: 16.64% | Test Recall: 19.25% | Test F1:  8.72%\n",
      "Epoch  2 | Train Loss: 1010.940 | Train Acc: 14.77% | Train Prec: 12.85% | Train Recall: 18.67% | Train F1:  8.42% || Test Acc: 17.82% | Test Prec: 20.26% | Test Recall: 20.26% | Test F1:  9.45%\n",
      "Epoch  3 | Train Loss: 994.502 | Train Acc: 17.42% | Train Prec: 14.10% | Train Recall: 19.61% | Train F1:  8.02% || Test Acc: 18.14% | Test Prec: 11.97% | Test Recall: 19.12% | Test F1:  7.77%\n",
      "Epoch  4 | Train Loss: 999.552 | Train Acc: 20.97% | Train Prec: 20.25% | Train Recall: 18.00% | Train F1: 13.49% || Test Acc: 21.61% | Test Prec: 19.89% | Test Recall: 19.17% | Test F1: 14.22%\n",
      "Epoch  5 | Train Loss: 995.292 | Train Acc: 24.37% | Train Prec: 22.16% | Train Recall: 20.64% | Train F1: 11.71% || Test Acc: 22.87% | Test Prec: 10.88% | Test Recall: 20.78% | Test F1: 10.89%\n",
      "Epoch  6 | Train Loss: 994.330 | Train Acc: 20.22% | Train Prec: 25.92% | Train Recall: 20.07% | Train F1:  8.90% || Test Acc: 18.30% | Test Prec: 11.28% | Test Recall: 19.59% | Test F1:  7.39%\n",
      "Epoch  7 | Train Loss: 992.411 | Train Acc: 20.58% | Train Prec: 14.83% | Train Recall: 20.16% | Train F1:  9.70% || Test Acc: 18.61% | Test Prec: 10.79% | Test Recall: 19.73% | Test F1:  8.45%\n",
      "Epoch  8 | Train Loss: 992.859 | Train Acc: 23.70% | Train Prec: 22.48% | Train Recall: 20.10% | Train F1:  9.15% || Test Acc: 23.66% | Test Prec: 11.86% | Test Recall: 20.13% | Test F1:  8.88%\n",
      "Epoch  9 | Train Loss: 991.376 | Train Acc: 20.06% | Train Prec: 32.55% | Train Recall: 19.75% | Train F1:  9.26% || Test Acc: 19.24% | Test Prec: 13.84% | Test Recall: 20.30% | Test F1:  9.27%\n",
      "Epoch 10 | Train Loss: 990.936 | Train Acc: 23.50% | Train Prec: 19.54% | Train Recall: 19.85% | Train F1: 10.81% || Test Acc: 23.34% | Test Prec: 32.89% | Test Recall: 20.10% | Test F1: 11.26%\n",
      "\n",
      "Classification Report for CNNBaseline_Dropout3_BatchNorm:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.250     0.072     0.112       138\n",
      "           1      0.250     0.051     0.085       118\n",
      "           2      0.000     0.000     0.000       120\n",
      "           3      0.239     0.907     0.378       150\n",
      "           4      0.000     0.000     0.000       108\n",
      "\n",
      "    accuracy                          0.240       634\n",
      "   macro avg      0.148     0.206     0.115       634\n",
      "weighted avg      0.157     0.240     0.130       634\n",
      "\n",
      "\n",
      "Gender breakdown for CNNBaseline_Dropout3_BatchNorm:\n",
      "Male: {'accuracy': 0.24522292993630573, 'precision': 0.11334919593042336, 'recall': 0.20149605136269252, 'f1': 0.10875918896478765}\n",
      "Female: {'accuracy': 0.203125, 'precision': 0.09636760805117803, 'recall': 0.1833694474539545, 'f1': 0.08659163800678915}\n",
      "\n",
      "=== Training model: CNNBaseline_Dropout5_BatchNorm ===\n",
      "Epoch  1 | Train Loss: 1030.800 | Train Acc: 20.26% | Train Prec: 25.95% | Train Recall: 20.00% | Train F1:  8.80% || Test Acc: 19.09% | Test Prec: 35.11% | Test Recall: 20.21% | Test F1:  8.96%\n",
      "Epoch  2 | Train Loss: 1017.776 | Train Acc: 23.54% | Train Prec: 12.07% | Train Recall: 19.76% | Train F1:  8.50% || Test Acc: 23.66% | Test Prec: 22.08% | Test Recall: 20.12% | Test F1:  9.09%\n",
      "Epoch  3 | Train Loss: 1004.466 | Train Acc: 17.30% | Train Prec: 15.56% | Train Recall: 19.37% | Train F1:  7.69% || Test Acc: 18.93% | Test Prec: 16.52% | Test Recall: 19.76% | Test F1:  8.62%\n",
      "Epoch  4 | Train Loss: 1002.617 | Train Acc: 15.44% | Train Prec: 20.09% | Train Recall: 19.99% | Train F1:  7.99% || Test Acc: 17.35% | Test Prec: 13.95% | Test Recall: 19.90% | Test F1:  8.55%\n",
      "Epoch  5 | Train Loss: 1001.846 | Train Acc: 23.78% | Train Prec: 23.18% | Train Recall: 20.43% | Train F1: 10.31% || Test Acc: 23.19% | Test Prec: 15.78% | Test Recall: 19.92% | Test F1:  9.96%\n",
      "Epoch  6 | Train Loss: 996.906 | Train Acc: 23.62% | Train Prec: 12.82% | Train Recall: 19.95% | Train F1:  9.66% || Test Acc: 23.66% | Test Prec: 33.55% | Test Recall: 20.22% | Test F1: 10.21%\n",
      "Epoch  7 | Train Loss: 997.970 | Train Acc: 23.97% | Train Prec: 10.50% | Train Recall: 20.22% | Train F1:  8.33% || Test Acc: 23.97% | Test Prec: 12.26% | Test Recall: 20.42% | Test F1:  8.71%\n",
      "Epoch  8 | Train Loss: 993.486 | Train Acc: 20.34% | Train Prec: 13.30% | Train Recall: 20.11% | Train F1:  9.48% || Test Acc: 18.30% | Test Prec:  9.19% | Test Recall: 19.48% | Test F1:  8.13%\n",
      "Epoch  9 | Train Loss: 990.715 | Train Acc: 23.22% | Train Prec: 18.32% | Train Recall: 19.62% | Train F1:  9.06% || Test Acc: 23.19% | Test Prec: 15.66% | Test Recall: 19.73% | Test F1:  9.20%\n",
      "Epoch 10 | Train Loss: 989.013 | Train Acc: 23.18% | Train Prec:  9.49% | Train Recall: 19.46% | Train F1:  8.18% || Test Acc: 23.50% | Test Prec: 15.71% | Test Recall: 19.98% | Test F1:  8.83%\n",
      "\n",
      "Classification Report for CNNBaseline_Dropout5_BatchNorm:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.200     0.022     0.039       138\n",
      "           1      0.200     0.017     0.031       118\n",
      "           2      0.000     0.000     0.000       120\n",
      "           3      0.238     0.967     0.383       150\n",
      "           4      0.000     0.000     0.000       108\n",
      "\n",
      "    accuracy                          0.237       634\n",
      "   macro avg      0.128     0.201     0.091       634\n",
      "weighted avg      0.137     0.237     0.105       634\n",
      "\n",
      "\n",
      "Gender breakdown for CNNBaseline_Dropout5_BatchNorm:\n",
      "Male: {'accuracy': 0.23885350318471338, 'precision': 0.07106710671067107, 'recall': 0.1915970913008349, 'f1': 0.08462976813762155}\n",
      "Female: {'accuracy': 0.228125, 'precision': 0.1895424836601307, 'recall': 0.20590465872156014, 'f1': 0.09454288240495137}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Prepare dataset & split\n",
    "# For 1D data, ensure AccentSpectrogramDataset returns tensors of shape (batch, channels=1, length)\n",
    "dataset = AccentRawWaveformDatasetAug(\n",
    "    '/Users/larsheijnen/DL/Train',\n",
    "    target_sr=16000,\n",
    "    standardize=True\n",
    ")\n",
    "\n",
    "train_len = int(0.8 * len(dataset))\n",
    "test_len  = len(dataset) - train_len\n",
    "train_ds, test_ds = random_split(dataset, [train_len, test_len], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "# For 1D data, pad_collate should pad along the last dimension (length)\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True,  collate_fn=pad_1d_collate)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=4, shuffle=False, collate_fn=pad_1d_collate)\n",
    "\n",
    "device    = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# General (not by gender) evaluation helper\n",
    "def evaluate(loader, model, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for specs, labels, _ in loader:\n",
    "            # For 1D data, specs should be (batch, 1, length)\n",
    "            specs, labels = specs.to(device), labels.to(device)\n",
    "            outputs = model(specs)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_labels.extend(labels.cpu().tolist())\n",
    "    acc    = accuracy_score(all_labels, all_preds)\n",
    "    prec   = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='macro')\n",
    "    f1     = f1_score(all_labels, all_preds, average='macro')\n",
    "    return acc, prec, recall, f1\n",
    "\n",
    "# Gender-based evaluation helper\n",
    "def evaluate_by_gender(loader, model, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels, all_genders = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for specs, labels, genders in loader:\n",
    "            specs, labels = specs.to(device), labels.to(device)\n",
    "            outputs = model(specs)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_labels.extend(labels.cpu().tolist())\n",
    "            all_genders.extend(genders)\n",
    "    results = {}\n",
    "    for gender in ['m', 'f']:\n",
    "        idxs = [i for i, g in enumerate(all_genders) if g == gender]\n",
    "        gender_preds = [all_preds[i] for i in idxs]\n",
    "        gender_labels = [all_labels[i] for i in idxs]\n",
    "        acc = accuracy_score(gender_labels, gender_preds)\n",
    "        prec = precision_score(gender_labels, gender_preds, average='macro', zero_division=0)\n",
    "        recall = recall_score(gender_labels, gender_preds, average='macro')\n",
    "        f1 = f1_score(gender_labels, gender_preds, average='macro')\n",
    "        results[gender] = {'accuracy': acc, 'precision': prec, 'recall': recall, 'f1': f1}\n",
    "    return results\n",
    "\n",
    "def classification_report_for_model(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for specs, labels, _ in loader:\n",
    "            specs, labels = specs.to(device), labels.to(device)\n",
    "            outputs = model(specs)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_labels.extend(labels.cpu().tolist())\n",
    "    print(classification_report(all_labels, all_preds, digits=3))\n",
    "\n",
    "import os\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 20\n",
    "max_epochs = 150\n",
    "min_improvement = 0.005\n",
    "\n",
    "save_dir_base = \"/Users/larsheijnen/DL/saved_models/A/not_augmented_earlystop\"\n",
    "os.makedirs(save_dir_base, exist_ok=True)\n",
    "\n",
    "for model_name, model_class in models_dict.items():\n",
    "    model = model_class().to(device)\n",
    "    print(f\"\\n=== Training model: {type(model).__name__} (Early Stopping) ===\")\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "    best_test_acc = 0.0\n",
    "    patience_counter = 0\n",
    "\n",
    "    best_model_path = os.path.join(save_dir_base, f\"{type(model).__name__}_augmented_best_1d_earlystop.pth\")\n",
    "    final_model_path = os.path.join(save_dir_base, f\"{type(model).__name__}_augmented_latest_1d_earlystop.pth\")\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for specs, labels, genders in train_loader:\n",
    "            specs, labels = specs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(specs), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Compute and print general metrics for this epoch (not by gender)\n",
    "        train_acc, train_prec, train_recall, train_f1 = evaluate(train_loader, model, device)\n",
    "        test_acc, test_prec, test_recall, test_f1 = evaluate(test_loader, model, device)\n",
    "        print(\n",
    "            f\"Epoch {epoch+1:3d}/{max_epochs} | \"\n",
    "            f\"Train Loss: {running_loss:.3f} | \"\n",
    "            f\"Train Acc: {train_acc*100:5.2f}% | \"\n",
    "            f\"Train Prec: {train_prec*100:5.2f}% | \"\n",
    "            f\"Train Recall: {train_recall*100:5.2f}% | \"\n",
    "            f\"Train F1: {train_f1*100:5.2f}% || \"\n",
    "            f\"Test Acc: {test_acc*100:5.2f}% | \"\n",
    "            f\"Test Prec: {test_prec*100:5.2f}% | \"\n",
    "            f\"Test Recall: {test_recall*100:5.2f}% | \"\n",
    "            f\"Test F1: {test_f1*100:5.2f}% | \"\n",
    "            f\"Patience: {patience_counter}/{patience}\"\n",
    "        )\n",
    "\n",
    "        if test_acc > best_test_acc + min_improvement:\n",
    "            best_test_acc = test_acc\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"    → New best test accuracy: {best_test_acc*100:.3f}% (saved to {best_model_path})\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\nEarly stopping triggered for {type(model).__name__} after {epoch+1} epochs.\")\n",
    "            break\n",
    "\n",
    "    torch.save(model.state_dict(), final_model_path)\n",
    "    print(f\"Final training state for {type(model).__name__} saved to {final_model_path}\")\n",
    "    print(f\"\\nTraining completed for {type(model).__name__} after {epoch+1} epochs.\")\n",
    "    print(f\"Best test accuracy achieved during training: {best_test_acc*100:.3f}%\")\n",
    "\n",
    "    # Load the best model for final evaluation\n",
    "    if os.path.exists(best_model_path):\n",
    "        print(f\"\\nLoading best saved model for {type(model).__name__} from {best_model_path} for final evaluation...\")\n",
    "        model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "        eval_model_description = \"best saved\"\n",
    "    else:\n",
    "        print(f\"\\nNo best model was saved for {type(model).__name__}. Using final model state for evaluation.\")\n",
    "        eval_model_description = \"final\"\n",
    "\n",
    "    print(f\"\\nClassification Report for {type(model).__name__} (using {eval_model_description} model):\")\n",
    "    classification_report_for_model(model, test_loader, device)\n",
    "\n",
    "    print(f\"\\nGender breakdown for {type(model).__name__} (using {eval_model_description} model):\")\n",
    "    gender_results = evaluate_by_gender(test_loader, model, device)\n",
    "    for gender in gender_results:\n",
    "        label = \"Male\" if gender == \"m\" else \"Female\"\n",
    "        print(f\"{label}: {gender_results[gender]}\")\n",
    "\n",
    "    final_train_acc, _, _, _ = evaluate(train_loader, model, device)\n",
    "    print(f\"\\n--- Summary for {type(model).__name__} ---\")\n",
    "    print(f\"- Total epochs trained: {epoch+1}\")\n",
    "    print(f\"- Best validation accuracy during training: {best_test_acc*100:.3f}%\")\n",
    "    print(f\"- Training accuracy of loaded ({eval_model_description}) model: {final_train_acc*100:.2f}%\")\n",
    "    if os.path.exists(best_model_path):\n",
    "        print(f\"- Best model saved to: {best_model_path}\")\n",
    "    else:\n",
    "        print(f\"- Best model not saved (or final model is the best achieved). Final model at: {final_model_path}\")\n",
    "    print(f\"---------------------------------------\\n\")\n",
    "\n",
    "print(\"\\nAll model configurations have been trained and evaluated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmented Data and Training with early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Number of training samples: 2532\n",
      "Number of test samples: 634\n",
      "\n",
      "=== Training model: CNNBaseline (Early Stopping, Augmented Data) ===\n",
      "Epoch   1/150 | Loss: 1.5990 | Train Acc: 23.85% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 0/20\n",
      "    → New best test accuracy: 23.659% (saved to /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_best.pth)\n",
      "Epoch   2/150 | Loss: 1.5964 | Train Acc: 23.78% | Test Acc: 21.77% | Test F1:  7.15% | Patience: 0/20\n",
      "Epoch   3/150 | Loss: 1.5963 | Train Acc: 23.93% | Test Acc: 21.29% | Test F1:  7.03% | Patience: 1/20\n",
      "Epoch   4/150 | Loss: 1.5956 | Train Acc: 24.05% | Test Acc: 22.40% | Test F1:  9.03% | Patience: 2/20\n",
      "Epoch   5/150 | Loss: 1.5956 | Train Acc: 23.85% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 3/20\n",
      "Epoch   6/150 | Loss: 1.5949 | Train Acc: 24.13% | Test Acc: 21.92% | Test F1:  8.12% | Patience: 4/20\n",
      "Epoch   7/150 | Loss: 1.5952 | Train Acc: 23.66% | Test Acc: 23.50% | Test F1:  9.38% | Patience: 5/20\n",
      "Epoch   8/150 | Loss: 1.5945 | Train Acc: 23.50% | Test Acc: 22.87% | Test F1:  8.42% | Patience: 6/20\n",
      "Epoch   9/150 | Loss: 1.5951 | Train Acc: 23.89% | Test Acc: 21.77% | Test F1:  7.17% | Patience: 7/20\n",
      "Epoch  10/150 | Loss: 1.5946 | Train Acc: 24.01% | Test Acc: 22.40% | Test F1:  9.16% | Patience: 8/20\n",
      "Epoch  11/150 | Loss: 1.5955 | Train Acc: 23.85% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 9/20\n",
      "Epoch  12/150 | Loss: 1.5949 | Train Acc: 23.66% | Test Acc: 23.19% | Test F1:  7.80% | Patience: 10/20\n",
      "Epoch  13/150 | Loss: 1.5940 | Train Acc: 23.58% | Test Acc: 21.45% | Test F1:  8.69% | Patience: 11/20\n",
      "Epoch  14/150 | Loss: 1.5941 | Train Acc: 23.97% | Test Acc: 20.98% | Test F1:  8.54% | Patience: 12/20\n",
      "Epoch  15/150 | Loss: 1.5956 | Train Acc: 24.21% | Test Acc: 21.77% | Test F1:  9.38% | Patience: 13/20\n",
      "Epoch  16/150 | Loss: 1.5947 | Train Acc: 24.49% | Test Acc: 22.08% | Test F1:  8.72% | Patience: 14/20\n",
      "Epoch  17/150 | Loss: 1.5941 | Train Acc: 23.85% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 15/20\n",
      "Epoch  18/150 | Loss: 1.5933 | Train Acc: 24.13% | Test Acc: 22.08% | Test F1:  9.75% | Patience: 16/20\n",
      "Epoch  19/150 | Loss: 1.5945 | Train Acc: 23.66% | Test Acc: 22.56% | Test F1:  9.79% | Patience: 17/20\n",
      "Epoch  20/150 | Loss: 1.5934 | Train Acc: 23.85% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 18/20\n",
      "Epoch  21/150 | Loss: 1.5946 | Train Acc: 23.82% | Test Acc: 22.40% | Test F1:  9.73% | Patience: 19/20\n",
      "\n",
      "Early stopping triggered for CNNBaseline after 21 epochs.\n",
      "Final training state for CNNBaseline saved to /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_final.pth\n",
      "\n",
      "Training completed for CNNBaseline after 21 epochs.\n",
      "Best test accuracy achieved during training: 23.659%\n",
      "\n",
      "Loading best saved model for CNNBaseline from /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_best.pth for final evaluation...\n",
      "\n",
      "Classification Report for CNNBaseline (using best saved model):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       138\n",
      "           1      0.000     0.000     0.000       118\n",
      "           2      0.000     0.000     0.000       120\n",
      "           3      0.237     1.000     0.383       150\n",
      "           4      0.000     0.000     0.000       108\n",
      "\n",
      "    accuracy                          0.237       634\n",
      "   macro avg      0.047     0.200     0.077       634\n",
      "weighted avg      0.056     0.237     0.091       634\n",
      "\n",
      "\n",
      "Gender breakdown for CNNBaseline (using best saved model):\n",
      "  Male: Accuracy: 25.16%, Precision: 5.03%, Recall: 20.00%, F1: 8.04%\n",
      "  Female: Accuracy: 22.19%, Precision: 4.44%, Recall: 20.00%, F1: 7.26%\n",
      "\n",
      "--- Summary for CNNBaseline ---\n",
      "- Total epochs trained: 21\n",
      "- Best validation accuracy during training: 23.659%\n",
      "- Training accuracy of loaded (best saved) model: 23.85%\n",
      "- Best model saved to: /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_best.pth\n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "=== Training model: CNNBaseline_BatchNorm (Early Stopping, Augmented Data) ===\n",
      "Epoch   1/150 | Loss: 1.6307 | Train Acc: 23.74% | Test Acc: 23.50% | Test F1:  7.91% | Patience: 0/20\n",
      "    → New best test accuracy: 23.502% (saved to /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_BatchNorm_best.pth)\n",
      "Epoch   2/150 | Loss: 1.5977 | Train Acc: 21.25% | Test Acc: 19.09% | Test F1: 10.05% | Patience: 0/20\n",
      "Epoch   3/150 | Loss: 1.5757 | Train Acc: 23.82% | Test Acc: 23.66% | Test F1:  8.65% | Patience: 1/20\n",
      "Epoch   4/150 | Loss: 1.5799 | Train Acc: 23.58% | Test Acc: 23.03% | Test F1:  9.95% | Patience: 2/20\n",
      "Epoch   5/150 | Loss: 1.5621 | Train Acc: 18.80% | Test Acc: 19.72% | Test F1: 11.59% | Patience: 3/20\n",
      "Epoch   6/150 | Loss: 1.5696 | Train Acc: 24.21% | Test Acc: 23.82% | Test F1: 10.79% | Patience: 4/20\n",
      "Epoch   7/150 | Loss: 1.5703 | Train Acc: 23.85% | Test Acc: 21.61% | Test F1:  9.52% | Patience: 5/20\n",
      "Epoch   8/150 | Loss: 1.5600 | Train Acc: 23.58% | Test Acc: 23.50% | Test F1:  9.55% | Patience: 6/20\n",
      "Epoch   9/150 | Loss: 1.5581 | Train Acc: 23.62% | Test Acc: 23.19% | Test F1:  9.34% | Patience: 7/20\n",
      "Epoch  10/150 | Loss: 1.5546 | Train Acc: 23.70% | Test Acc: 22.40% | Test F1:  9.66% | Patience: 8/20\n",
      "Epoch  11/150 | Loss: 1.5533 | Train Acc: 15.09% | Test Acc: 17.03% | Test F1:  8.84% | Patience: 9/20\n",
      "Epoch  12/150 | Loss: 1.5532 | Train Acc: 23.62% | Test Acc: 23.34% | Test F1:  8.12% | Patience: 10/20\n",
      "Epoch  13/150 | Loss: 1.5429 | Train Acc: 23.82% | Test Acc: 21.92% | Test F1: 10.22% | Patience: 11/20\n",
      "Epoch  14/150 | Loss: 1.5473 | Train Acc: 19.75% | Test Acc: 19.24% | Test F1:  9.04% | Patience: 12/20\n",
      "Epoch  15/150 | Loss: 1.5603 | Train Acc: 22.35% | Test Acc: 23.50% | Test F1: 13.83% | Patience: 13/20\n",
      "Epoch  16/150 | Loss: 1.5520 | Train Acc: 23.18% | Test Acc: 22.56% | Test F1:  8.55% | Patience: 14/20\n",
      "Epoch  17/150 | Loss: 1.5597 | Train Acc: 21.68% | Test Acc: 22.40% | Test F1: 14.32% | Patience: 15/20\n",
      "Epoch  18/150 | Loss: 1.5539 | Train Acc: 23.34% | Test Acc: 22.87% | Test F1:  8.70% | Patience: 16/20\n",
      "Epoch  19/150 | Loss: 1.5481 | Train Acc: 22.00% | Test Acc: 20.98% | Test F1: 12.51% | Patience: 17/20\n",
      "Epoch  20/150 | Loss: 1.5432 | Train Acc: 23.93% | Test Acc: 23.82% | Test F1:  9.46% | Patience: 18/20\n",
      "Epoch  21/150 | Loss: 1.5482 | Train Acc: 20.02% | Test Acc: 18.45% | Test F1:  7.67% | Patience: 19/20\n",
      "\n",
      "Early stopping triggered for CNNBaseline_BatchNorm after 21 epochs.\n",
      "Final training state for CNNBaseline_BatchNorm saved to /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_BatchNorm_final.pth\n",
      "\n",
      "Training completed for CNNBaseline_BatchNorm after 21 epochs.\n",
      "Best test accuracy achieved during training: 23.502%\n",
      "\n",
      "Loading best saved model for CNNBaseline_BatchNorm from /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_BatchNorm_best.pth for final evaluation...\n",
      "\n",
      "Classification Report for CNNBaseline_BatchNorm (using best saved model):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.143     0.007     0.014       138\n",
      "           1      0.000     0.000     0.000       118\n",
      "           2      0.000     0.000     0.000       120\n",
      "           3      0.236     0.980     0.380       150\n",
      "           4      1.000     0.009     0.018       108\n",
      "\n",
      "    accuracy                          0.235       634\n",
      "   macro avg      0.276     0.199     0.082       634\n",
      "weighted avg      0.257     0.235     0.096       634\n",
      "\n",
      "\n",
      "Gender breakdown for CNNBaseline_BatchNorm (using best saved model):\n",
      "  Male: Accuracy: 24.84%, Precision: 15.00%, Recall: 19.87%, F1: 8.69%\n",
      "  Female: Accuracy: 22.19%, Precision: 4.44%, Recall: 20.00%, F1: 7.26%\n",
      "\n",
      "--- Summary for CNNBaseline_BatchNorm ---\n",
      "- Total epochs trained: 21\n",
      "- Best validation accuracy during training: 23.502%\n",
      "- Training accuracy of loaded (best saved) model: 23.97%\n",
      "- Best model saved to: /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_BatchNorm_best.pth\n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "=== Training model: CNNBaseline_Dropout3 (Early Stopping, Augmented Data) ===\n",
      "Epoch   1/150 | Loss: 1.5999 | Train Acc: 23.89% | Test Acc: 21.92% | Test F1:  8.11% | Patience: 0/20\n",
      "    → New best test accuracy: 21.924% (saved to /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout3_best.pth)\n",
      "Epoch   2/150 | Loss: 1.5971 | Train Acc: 23.85% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 0/20\n",
      "    → New best test accuracy: 23.659% (saved to /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout3_best.pth)\n",
      "Epoch   3/150 | Loss: 1.5956 | Train Acc: 23.89% | Test Acc: 22.24% | Test F1:  7.98% | Patience: 0/20\n",
      "Epoch   4/150 | Loss: 1.5952 | Train Acc: 23.82% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 1/20\n",
      "Epoch   5/150 | Loss: 1.5961 | Train Acc: 23.93% | Test Acc: 20.82% | Test F1:  8.13% | Patience: 2/20\n",
      "Epoch   6/150 | Loss: 1.5948 | Train Acc: 23.85% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 3/20\n",
      "Epoch   7/150 | Loss: 1.5951 | Train Acc: 23.74% | Test Acc: 20.50% | Test F1:  7.91% | Patience: 4/20\n",
      "Epoch   8/150 | Loss: 1.5952 | Train Acc: 23.78% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 5/20\n",
      "Epoch   9/150 | Loss: 1.5947 | Train Acc: 23.78% | Test Acc: 23.66% | Test F1:  8.17% | Patience: 6/20\n",
      "Epoch  10/150 | Loss: 1.5951 | Train Acc: 23.82% | Test Acc: 23.34% | Test F1:  7.57% | Patience: 7/20\n",
      "Epoch  11/150 | Loss: 1.5944 | Train Acc: 24.01% | Test Acc: 21.45% | Test F1:  7.18% | Patience: 8/20\n",
      "Epoch  12/150 | Loss: 1.5944 | Train Acc: 23.82% | Test Acc: 23.66% | Test F1:  7.67% | Patience: 9/20\n",
      "Epoch  13/150 | Loss: 1.5938 | Train Acc: 24.41% | Test Acc: 21.45% | Test F1:  8.83% | Patience: 10/20\n",
      "Epoch  14/150 | Loss: 1.5947 | Train Acc: 24.01% | Test Acc: 21.61% | Test F1:  9.18% | Patience: 11/20\n",
      "Epoch  15/150 | Loss: 1.5946 | Train Acc: 23.85% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 12/20\n",
      "Epoch  16/150 | Loss: 1.5943 | Train Acc: 23.78% | Test Acc: 21.77% | Test F1:  7.16% | Patience: 13/20\n",
      "Epoch  17/150 | Loss: 1.5940 | Train Acc: 24.09% | Test Acc: 21.77% | Test F1:  7.64% | Patience: 14/20\n",
      "Epoch  18/150 | Loss: 1.5943 | Train Acc: 23.85% | Test Acc: 23.19% | Test F1:  7.53% | Patience: 15/20\n",
      "Epoch  19/150 | Loss: 1.5943 | Train Acc: 23.50% | Test Acc: 22.08% | Test F1:  8.89% | Patience: 16/20\n",
      "Epoch  20/150 | Loss: 1.5941 | Train Acc: 24.64% | Test Acc: 21.77% | Test F1:  9.38% | Patience: 17/20\n",
      "Epoch  21/150 | Loss: 1.5940 | Train Acc: 23.74% | Test Acc: 21.61% | Test F1:  9.33% | Patience: 18/20\n",
      "Epoch  22/150 | Loss: 1.5941 | Train Acc: 23.58% | Test Acc: 21.77% | Test F1:  8.95% | Patience: 19/20\n",
      "\n",
      "Early stopping triggered for CNNBaseline_Dropout3 after 22 epochs.\n",
      "Final training state for CNNBaseline_Dropout3 saved to /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout3_final.pth\n",
      "\n",
      "Training completed for CNNBaseline_Dropout3 after 22 epochs.\n",
      "Best test accuracy achieved during training: 23.659%\n",
      "\n",
      "Loading best saved model for CNNBaseline_Dropout3 from /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout3_best.pth for final evaluation...\n",
      "\n",
      "Classification Report for CNNBaseline_Dropout3 (using best saved model):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       138\n",
      "           1      0.000     0.000     0.000       118\n",
      "           2      0.000     0.000     0.000       120\n",
      "           3      0.237     1.000     0.383       150\n",
      "           4      0.000     0.000     0.000       108\n",
      "\n",
      "    accuracy                          0.237       634\n",
      "   macro avg      0.047     0.200     0.077       634\n",
      "weighted avg      0.056     0.237     0.091       634\n",
      "\n",
      "\n",
      "Gender breakdown for CNNBaseline_Dropout3 (using best saved model):\n",
      "  Male: Accuracy: 25.16%, Precision: 5.03%, Recall: 20.00%, F1: 8.04%\n",
      "  Female: Accuracy: 22.19%, Precision: 4.44%, Recall: 20.00%, F1: 7.26%\n",
      "\n",
      "--- Summary for CNNBaseline_Dropout3 ---\n",
      "- Total epochs trained: 22\n",
      "- Best validation accuracy during training: 23.659%\n",
      "- Training accuracy of loaded (best saved) model: 23.89%\n",
      "- Best model saved to: /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout3_best.pth\n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "=== Training model: CNNBaseline_Dropout5 (Early Stopping, Augmented Data) ===\n",
      "Epoch   1/150 | Loss: 1.6010 | Train Acc: 23.82% | Test Acc: 21.92% | Test F1:  7.43% | Patience: 0/20\n",
      "    → New best test accuracy: 21.924% (saved to /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout5_best.pth)\n",
      "Epoch   2/150 | Loss: 1.5966 | Train Acc: 23.85% | Test Acc: 21.77% | Test F1:  7.16% | Patience: 0/20\n",
      "Epoch   3/150 | Loss: 1.5960 | Train Acc: 24.09% | Test Acc: 23.19% | Test F1:  9.47% | Patience: 1/20\n",
      "    → New best test accuracy: 23.186% (saved to /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout5_best.pth)\n",
      "Epoch   4/150 | Loss: 1.5954 | Train Acc: 23.85% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 0/20\n",
      "Epoch   5/150 | Loss: 1.5959 | Train Acc: 23.85% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 1/20\n",
      "Epoch   6/150 | Loss: 1.5947 | Train Acc: 24.21% | Test Acc: 22.56% | Test F1:  9.97% | Patience: 2/20\n",
      "Epoch   7/150 | Loss: 1.5949 | Train Acc: 23.78% | Test Acc: 23.50% | Test F1:  7.87% | Patience: 3/20\n",
      "Epoch   8/150 | Loss: 1.5942 | Train Acc: 23.85% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 4/20\n",
      "Epoch   9/150 | Loss: 1.5948 | Train Acc: 24.01% | Test Acc: 22.87% | Test F1: 10.40% | Patience: 5/20\n",
      "Epoch  10/150 | Loss: 1.5949 | Train Acc: 24.09% | Test Acc: 21.61% | Test F1:  7.82% | Patience: 6/20\n",
      "Epoch  11/150 | Loss: 1.5942 | Train Acc: 23.85% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 7/20\n",
      "Epoch  12/150 | Loss: 1.5948 | Train Acc: 23.85% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 8/20\n",
      "Epoch  13/150 | Loss: 1.5950 | Train Acc: 23.85% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 9/20\n",
      "Epoch  14/150 | Loss: 1.5950 | Train Acc: 23.97% | Test Acc: 23.03% | Test F1:  9.53% | Patience: 10/20\n",
      "Epoch  15/150 | Loss: 1.5948 | Train Acc: 24.09% | Test Acc: 22.08% | Test F1:  8.57% | Patience: 11/20\n",
      "Epoch  16/150 | Loss: 1.5940 | Train Acc: 23.85% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 12/20\n",
      "Epoch  17/150 | Loss: 1.5940 | Train Acc: 23.70% | Test Acc: 24.13% | Test F1:  8.66% | Patience: 13/20\n",
      "    → New best test accuracy: 24.132% (saved to /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout5_best.pth)\n",
      "Epoch  18/150 | Loss: 1.5941 | Train Acc: 23.97% | Test Acc: 21.92% | Test F1:  9.18% | Patience: 0/20\n",
      "Epoch  19/150 | Loss: 1.5942 | Train Acc: 23.97% | Test Acc: 21.77% | Test F1:  8.94% | Patience: 1/20\n",
      "Epoch  20/150 | Loss: 1.5945 | Train Acc: 23.85% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 2/20\n",
      "Epoch  21/150 | Loss: 1.5935 | Train Acc: 23.97% | Test Acc: 23.82% | Test F1:  7.99% | Patience: 3/20\n",
      "Epoch  22/150 | Loss: 1.5940 | Train Acc: 24.05% | Test Acc: 22.24% | Test F1:  9.63% | Patience: 4/20\n",
      "Epoch  23/150 | Loss: 1.5947 | Train Acc: 24.09% | Test Acc: 22.87% | Test F1: 10.12% | Patience: 5/20\n",
      "Epoch  24/150 | Loss: 1.5944 | Train Acc: 24.29% | Test Acc: 21.92% | Test F1:  9.84% | Patience: 6/20\n",
      "Epoch  25/150 | Loss: 1.5943 | Train Acc: 24.01% | Test Acc: 21.77% | Test F1:  8.79% | Patience: 7/20\n",
      "Epoch  26/150 | Loss: 1.5943 | Train Acc: 23.97% | Test Acc: 22.40% | Test F1: 10.15% | Patience: 8/20\n",
      "Epoch  27/150 | Loss: 1.5940 | Train Acc: 23.78% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 9/20\n",
      "Epoch  28/150 | Loss: 1.5939 | Train Acc: 23.93% | Test Acc: 23.66% | Test F1:  7.91% | Patience: 10/20\n",
      "Epoch  29/150 | Loss: 1.5942 | Train Acc: 23.62% | Test Acc: 21.77% | Test F1:  9.24% | Patience: 11/20\n",
      "Epoch  30/150 | Loss: 1.5942 | Train Acc: 23.85% | Test Acc: 22.24% | Test F1: 10.17% | Patience: 12/20\n",
      "Epoch  31/150 | Loss: 1.5942 | Train Acc: 24.49% | Test Acc: 23.03% | Test F1: 10.34% | Patience: 13/20\n",
      "Epoch  32/150 | Loss: 1.5937 | Train Acc: 24.01% | Test Acc: 21.92% | Test F1:  9.00% | Patience: 14/20\n",
      "Epoch  33/150 | Loss: 1.5940 | Train Acc: 24.29% | Test Acc: 22.71% | Test F1: 10.17% | Patience: 15/20\n",
      "Epoch  34/150 | Loss: 1.5942 | Train Acc: 23.85% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 16/20\n",
      "Epoch  35/150 | Loss: 1.5937 | Train Acc: 23.85% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 17/20\n",
      "Epoch  36/150 | Loss: 1.5946 | Train Acc: 23.85% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 18/20\n",
      "Epoch  37/150 | Loss: 1.5945 | Train Acc: 23.82% | Test Acc: 23.97% | Test F1:  8.25% | Patience: 19/20\n",
      "\n",
      "Early stopping triggered for CNNBaseline_Dropout5 after 37 epochs.\n",
      "Final training state for CNNBaseline_Dropout5 saved to /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout5_final.pth\n",
      "\n",
      "Training completed for CNNBaseline_Dropout5 after 37 epochs.\n",
      "Best test accuracy achieved during training: 24.132%\n",
      "\n",
      "Loading best saved model for CNNBaseline_Dropout5 from /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout5_best.pth for final evaluation...\n",
      "\n",
      "Classification Report for CNNBaseline_Dropout5 (using best saved model):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       138\n",
      "           1      0.000     0.000     0.000       118\n",
      "           2      0.429     0.025     0.047       120\n",
      "           3      0.238     0.993     0.384       150\n",
      "           4      0.000     0.000     0.000       108\n",
      "\n",
      "    accuracy                          0.240       634\n",
      "   macro avg      0.133     0.204     0.086       634\n",
      "weighted avg      0.137     0.240     0.100       634\n",
      "\n",
      "\n",
      "Gender breakdown for CNNBaseline_Dropout5 (using best saved model):\n",
      "  Male: Accuracy: 24.84%, Precision: 4.98%, Recall: 19.75%, F1: 7.96%\n",
      "  Female: Accuracy: 22.19%, Precision: 4.45%, Recall: 20.00%, F1: 7.28%\n",
      "\n",
      "--- Summary for CNNBaseline_Dropout5 ---\n",
      "- Total epochs trained: 37\n",
      "- Best validation accuracy during training: 24.132%\n",
      "- Training accuracy of loaded (best saved) model: 23.82%\n",
      "- Best model saved to: /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout5_best.pth\n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "=== Training model: CNNBaseline_Dropout3_BatchNorm (Early Stopping, Augmented Data) ===\n",
      "Epoch   1/150 | Loss: 1.6203 | Train Acc: 19.91% | Test Acc: 18.93% | Test F1:  8.04% | Patience: 0/20\n",
      "    → New best test accuracy: 18.927% (saved to /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout3_BatchNorm_best.pth)\n",
      "Epoch   2/150 | Loss: 1.5897 | Train Acc: 17.42% | Test Acc: 19.09% | Test F1:  9.74% | Patience: 0/20\n",
      "Epoch   3/150 | Loss: 1.5804 | Train Acc: 17.58% | Test Acc: 18.30% | Test F1:  8.75% | Patience: 1/20\n",
      "Epoch   4/150 | Loss: 1.5741 | Train Acc: 23.66% | Test Acc: 23.50% | Test F1: 10.04% | Patience: 2/20\n",
      "    → New best test accuracy: 23.502% (saved to /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout3_BatchNorm_best.pth)\n",
      "Epoch   5/150 | Loss: 1.5728 | Train Acc: 21.41% | Test Acc: 20.98% | Test F1: 14.19% | Patience: 0/20\n",
      "Epoch   6/150 | Loss: 1.5763 | Train Acc: 23.82% | Test Acc: 21.92% | Test F1:  9.82% | Patience: 1/20\n",
      "Epoch   7/150 | Loss: 1.5630 | Train Acc: 15.05% | Test Acc: 17.03% | Test F1:  6.63% | Patience: 2/20\n",
      "Epoch   8/150 | Loss: 1.5628 | Train Acc: 23.18% | Test Acc: 23.97% | Test F1:  9.71% | Patience: 3/20\n",
      "Epoch   9/150 | Loss: 1.5652 | Train Acc: 23.82% | Test Acc: 23.82% | Test F1:  8.03% | Patience: 4/20\n",
      "Epoch  10/150 | Loss: 1.5616 | Train Acc: 23.14% | Test Acc: 22.87% | Test F1:  8.39% | Patience: 5/20\n",
      "Epoch  11/150 | Loss: 1.5616 | Train Acc: 23.34% | Test Acc: 23.97% | Test F1:  8.82% | Patience: 6/20\n",
      "Epoch  12/150 | Loss: 1.5666 | Train Acc: 23.66% | Test Acc: 23.34% | Test F1:  8.52% | Patience: 7/20\n",
      "Epoch  13/150 | Loss: 1.5553 | Train Acc: 23.10% | Test Acc: 23.97% | Test F1:  9.27% | Patience: 8/20\n",
      "Epoch  14/150 | Loss: 1.5558 | Train Acc: 23.74% | Test Acc: 23.50% | Test F1:  8.18% | Patience: 9/20\n",
      "Epoch  15/150 | Loss: 1.5623 | Train Acc: 23.85% | Test Acc: 23.03% | Test F1:  7.63% | Patience: 10/20\n",
      "Epoch  16/150 | Loss: 1.5592 | Train Acc: 23.03% | Test Acc: 23.34% | Test F1:  9.50% | Patience: 11/20\n",
      "Epoch  17/150 | Loss: 1.5520 | Train Acc: 23.42% | Test Acc: 23.82% | Test F1:  9.31% | Patience: 12/20\n",
      "Epoch  18/150 | Loss: 1.5524 | Train Acc: 23.58% | Test Acc: 23.50% | Test F1:  8.01% | Patience: 13/20\n",
      "Epoch  19/150 | Loss: 1.5507 | Train Acc: 23.74% | Test Acc: 23.34% | Test F1:  8.11% | Patience: 14/20\n",
      "Epoch  20/150 | Loss: 1.5465 | Train Acc: 23.62% | Test Acc: 23.66% | Test F1:  8.05% | Patience: 15/20\n",
      "Epoch  21/150 | Loss: 1.5526 | Train Acc: 23.82% | Test Acc: 24.13% | Test F1:  8.56% | Patience: 16/20\n",
      "    → New best test accuracy: 24.132% (saved to /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout3_BatchNorm_best.pth)\n",
      "Epoch  22/150 | Loss: 1.5536 | Train Acc: 23.78% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 0/20\n",
      "Epoch  23/150 | Loss: 1.5511 | Train Acc: 23.89% | Test Acc: 23.34% | Test F1:  9.40% | Patience: 1/20\n",
      "Epoch  24/150 | Loss: 1.5454 | Train Acc: 23.38% | Test Acc: 23.19% | Test F1:  7.88% | Patience: 2/20\n",
      "Epoch  25/150 | Loss: 1.5477 | Train Acc: 23.70% | Test Acc: 22.71% | Test F1:  9.70% | Patience: 3/20\n",
      "Epoch  26/150 | Loss: 1.5532 | Train Acc: 23.74% | Test Acc: 23.97% | Test F1:  9.35% | Patience: 4/20\n",
      "Epoch  27/150 | Loss: 1.5483 | Train Acc: 23.22% | Test Acc: 23.19% | Test F1:  8.19% | Patience: 5/20\n",
      "Epoch  28/150 | Loss: 1.5443 | Train Acc: 23.30% | Test Acc: 23.97% | Test F1: 10.71% | Patience: 6/20\n",
      "Epoch  29/150 | Loss: 1.5486 | Train Acc: 23.85% | Test Acc: 23.03% | Test F1:  8.77% | Patience: 7/20\n",
      "Epoch  30/150 | Loss: 1.5537 | Train Acc: 23.97% | Test Acc: 23.82% | Test F1:  8.48% | Patience: 8/20\n",
      "Epoch  31/150 | Loss: 1.5597 | Train Acc: 23.38% | Test Acc: 23.19% | Test F1: 10.74% | Patience: 9/20\n",
      "Epoch  32/150 | Loss: 1.5555 | Train Acc: 23.89% | Test Acc: 23.19% | Test F1: 10.29% | Patience: 10/20\n",
      "Epoch  33/150 | Loss: 1.5489 | Train Acc: 23.46% | Test Acc: 23.19% | Test F1: 11.50% | Patience: 11/20\n",
      "Epoch  34/150 | Loss: 1.5434 | Train Acc: 23.66% | Test Acc: 22.56% | Test F1:  9.91% | Patience: 12/20\n",
      "Epoch  35/150 | Loss: 1.5489 | Train Acc: 22.95% | Test Acc: 23.19% | Test F1: 10.46% | Patience: 13/20\n",
      "Epoch  36/150 | Loss: 1.5450 | Train Acc: 23.82% | Test Acc: 23.97% | Test F1: 10.38% | Patience: 14/20\n",
      "Epoch  37/150 | Loss: 1.5408 | Train Acc: 23.62% | Test Acc: 23.19% | Test F1:  8.79% | Patience: 15/20\n",
      "Epoch  38/150 | Loss: 1.5467 | Train Acc: 22.55% | Test Acc: 23.82% | Test F1: 10.45% | Patience: 16/20\n",
      "Epoch  39/150 | Loss: 1.5518 | Train Acc: 23.74% | Test Acc: 23.97% | Test F1:  9.76% | Patience: 17/20\n",
      "Epoch  40/150 | Loss: 1.5521 | Train Acc: 23.18% | Test Acc: 23.66% | Test F1:  9.56% | Patience: 18/20\n",
      "Epoch  41/150 | Loss: 1.5490 | Train Acc: 24.05% | Test Acc: 22.56% | Test F1:  9.45% | Patience: 19/20\n",
      "\n",
      "Early stopping triggered for CNNBaseline_Dropout3_BatchNorm after 41 epochs.\n",
      "Final training state for CNNBaseline_Dropout3_BatchNorm saved to /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout3_BatchNorm_final.pth\n",
      "\n",
      "Training completed for CNNBaseline_Dropout3_BatchNorm after 41 epochs.\n",
      "Best test accuracy achieved during training: 24.132%\n",
      "\n",
      "Loading best saved model for CNNBaseline_Dropout3_BatchNorm from /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout3_BatchNorm_best.pth for final evaluation...\n",
      "\n",
      "Classification Report for CNNBaseline_Dropout3_BatchNorm (using best saved model):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.400     0.014     0.028       138\n",
      "           1      0.000     0.000     0.000       118\n",
      "           2      0.000     0.000     0.000       120\n",
      "           3      0.237     0.993     0.383       150\n",
      "           4      0.000     0.000     0.000       108\n",
      "\n",
      "    accuracy                          0.238       634\n",
      "   macro avg      0.127     0.202     0.082       634\n",
      "weighted avg      0.143     0.238     0.097       634\n",
      "\n",
      "\n",
      "Gender breakdown for CNNBaseline_Dropout3_BatchNorm (using best saved model):\n",
      "  Male: Accuracy: 25.48%, Precision: 8.46%, Recall: 20.43%, F1: 8.92%\n",
      "  Female: Accuracy: 22.19%, Precision: 9.43%, Recall: 19.94%, F1: 7.66%\n",
      "\n",
      "--- Summary for CNNBaseline_Dropout3_BatchNorm ---\n",
      "- Total epochs trained: 41\n",
      "- Best validation accuracy during training: 24.132%\n",
      "- Training accuracy of loaded (best saved) model: 23.74%\n",
      "- Best model saved to: /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout3_BatchNorm_best.pth\n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "=== Training model: CNNBaseline_Dropout5_BatchNorm (Early Stopping, Augmented Data) ===\n",
      "Epoch   1/150 | Loss: 1.6180 | Train Acc: 24.01% | Test Acc: 23.66% | Test F1:  9.50% | Patience: 0/20\n",
      "    → New best test accuracy: 23.659% (saved to /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout5_BatchNorm_best.pth)\n",
      "Epoch   2/150 | Loss: 1.5981 | Train Acc: 23.54% | Test Acc: 23.34% | Test F1:  8.78% | Patience: 0/20\n",
      "Epoch   3/150 | Loss: 1.5807 | Train Acc: 23.50% | Test Acc: 22.56% | Test F1:  9.07% | Patience: 1/20\n",
      "Epoch   4/150 | Loss: 1.5784 | Train Acc: 20.81% | Test Acc: 17.82% | Test F1:  9.27% | Patience: 2/20\n",
      "Epoch   5/150 | Loss: 1.5714 | Train Acc: 23.82% | Test Acc: 22.71% | Test F1: 10.98% | Patience: 3/20\n",
      "Epoch   6/150 | Loss: 1.5668 | Train Acc: 23.14% | Test Acc: 23.19% | Test F1:  9.91% | Patience: 4/20\n",
      "Epoch   7/150 | Loss: 1.5790 | Train Acc: 23.46% | Test Acc: 23.34% | Test F1:  8.54% | Patience: 5/20\n",
      "Epoch   8/150 | Loss: 1.5668 | Train Acc: 19.87% | Test Acc: 19.24% | Test F1:  8.77% | Patience: 6/20\n",
      "Epoch   9/150 | Loss: 1.5719 | Train Acc: 21.88% | Test Acc: 21.77% | Test F1: 11.95% | Patience: 7/20\n",
      "Epoch  10/150 | Loss: 1.5697 | Train Acc: 23.82% | Test Acc: 23.82% | Test F1:  8.31% | Patience: 8/20\n",
      "Epoch  11/150 | Loss: 1.5631 | Train Acc: 23.82% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 9/20\n",
      "Epoch  12/150 | Loss: 1.5767 | Train Acc: 23.93% | Test Acc: 21.77% | Test F1:  9.52% | Patience: 10/20\n",
      "Epoch  13/150 | Loss: 1.5626 | Train Acc: 24.25% | Test Acc: 21.92% | Test F1:  9.76% | Patience: 11/20\n",
      "Epoch  14/150 | Loss: 1.5621 | Train Acc: 23.85% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 12/20\n",
      "Epoch  15/150 | Loss: 1.5715 | Train Acc: 23.66% | Test Acc: 22.24% | Test F1:  8.43% | Patience: 13/20\n",
      "Epoch  16/150 | Loss: 1.5644 | Train Acc: 23.54% | Test Acc: 23.82% | Test F1:  9.84% | Patience: 14/20\n",
      "Epoch  17/150 | Loss: 1.5653 | Train Acc: 23.62% | Test Acc: 23.34% | Test F1:  8.71% | Patience: 15/20\n",
      "Epoch  18/150 | Loss: 1.5625 | Train Acc: 23.85% | Test Acc: 23.82% | Test F1:  8.01% | Patience: 16/20\n",
      "Epoch  19/150 | Loss: 1.5543 | Train Acc: 23.85% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 17/20\n",
      "Epoch  20/150 | Loss: 1.5566 | Train Acc: 23.70% | Test Acc: 23.50% | Test F1:  8.24% | Patience: 18/20\n",
      "Epoch  21/150 | Loss: 1.5629 | Train Acc: 23.82% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 19/20\n",
      "\n",
      "Early stopping triggered for CNNBaseline_Dropout5_BatchNorm after 21 epochs.\n",
      "Final training state for CNNBaseline_Dropout5_BatchNorm saved to /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout5_BatchNorm_final.pth\n",
      "\n",
      "Training completed for CNNBaseline_Dropout5_BatchNorm after 21 epochs.\n",
      "Best test accuracy achieved during training: 23.659%\n",
      "\n",
      "Loading best saved model for CNNBaseline_Dropout5_BatchNorm from /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout5_BatchNorm_best.pth for final evaluation...\n",
      "\n",
      "Classification Report for CNNBaseline_Dropout5_BatchNorm (using best saved model):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.162     0.043     0.069       138\n",
      "           1      0.000     0.000     0.000       118\n",
      "           2      0.000     0.000     0.000       120\n",
      "           3      0.242     0.960     0.387       150\n",
      "           4      0.000     0.000     0.000       108\n",
      "\n",
      "    accuracy                          0.237       634\n",
      "   macro avg      0.081     0.201     0.091       634\n",
      "weighted avg      0.093     0.237     0.106       634\n",
      "\n",
      "\n",
      "Gender breakdown for CNNBaseline_Dropout5_BatchNorm (using best saved model):\n",
      "  Male: Accuracy: 26.11%, Precision: 17.70%, Recall: 21.49%, F1: 11.75%\n",
      "  Female: Accuracy: 21.88%, Precision: 8.59%, Recall: 19.41%, F1: 8.86%\n",
      "\n",
      "--- Summary for CNNBaseline_Dropout5_BatchNorm ---\n",
      "- Total epochs trained: 21\n",
      "- Best validation accuracy during training: 23.659%\n",
      "- Training accuracy of loaded (best saved) model: 23.66%\n",
      "- Best model saved to: /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout5_BatchNorm_best.pth\n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "All model configurations have been trained and evaluated.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# --- Assumptions: all helper classes/functions are defined as in previous cells ---\n",
    "# - AccentSpectrogramDatasetAug\n",
    "# - pad_collate\n",
    "# - models_dict\n",
    "# - evaluate, evaluate_by_gender, classification_report_for_model\n",
    "\n",
    "# 1. Prepare dataset & split (using Augmented Data)\n",
    "dataset = AccentRawWaveformDatasetAug(\n",
    "    '/Users/larsheijnen/DL/Train',\n",
    "    target_sr=16000,\n",
    "    standardize=True\n",
    ")\n",
    "\n",
    "train_len = int(0.8 * len(dataset))\n",
    "test_len  = len(dataset) - train_len\n",
    "train_ds, test_ds = random_split(dataset, [train_len, test_len], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, collate_fn=pad_1d_collate, pin_memory=False)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=4, shuffle=False, collate_fn=pad_1d_collate, pin_memory=False)\n",
    "\n",
    "device    = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Early stopping parameters for Approach A (early stopping on augmented data)\n",
    "patience = 20\n",
    "max_epochs = 150\n",
    "min_improvement = 0.005\n",
    "\n",
    "save_dir_base = \"/Users/larsheijnen/DL/saved_models/A/augmented_earlystop\"\n",
    "os.makedirs(save_dir_base, exist_ok=True)\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Number of training samples: {len(train_ds)}\")\n",
    "print(f\"Number of test samples: {len(test_ds)}\")\n",
    "\n",
    "for model_name, model_class in models_dict.items():\n",
    "    print(f\"\\n=== Training model: {model_class.__name__} (Early Stopping, Augmented Data) ===\")\n",
    "    model = model_class().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "    best_test_acc = 0.0\n",
    "    patience_counter = 0\n",
    "\n",
    "    best_model_path = os.path.join(save_dir_base, f\"{model_class.__name__}_best.pth\")\n",
    "    final_model_path = os.path.join(save_dir_base, f\"{model_class.__name__}_final.pth\")\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for specs, labels, _ in train_loader:\n",
    "            specs, labels = specs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(specs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        avg_epoch_loss = running_loss / len(train_loader)\n",
    "\n",
    "        train_acc, train_prec, train_recall, train_f1 = evaluate(train_loader, model, device)\n",
    "        test_acc, test_prec, test_recall, test_f1 = evaluate(test_loader, model, device)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch+1:3d}/{max_epochs} | \"\n",
    "            f\"Loss: {avg_epoch_loss:.4f} | \"\n",
    "            f\"Train Acc: {train_acc*100:5.2f}% | \"\n",
    "            f\"Test Acc: {test_acc*100:5.2f}% | \"\n",
    "            f\"Test F1: {test_f1*100:5.2f}% | \"\n",
    "            f\"Patience: {patience_counter}/{patience}\"\n",
    "        )\n",
    "\n",
    "        if test_acc > best_test_acc + min_improvement:\n",
    "            best_test_acc = test_acc\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"    → New best test accuracy: {best_test_acc*100:.3f}% (saved to {best_model_path})\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\nEarly stopping triggered for {model_class.__name__} after {epoch+1} epochs.\")\n",
    "            break\n",
    "\n",
    "    torch.save(model.state_dict(), final_model_path)\n",
    "    print(f\"Final training state for {model_class.__name__} saved to {final_model_path}\")\n",
    "    print(f\"\\nTraining completed for {model_class.__name__} after {epoch+1} epochs.\")\n",
    "    print(f\"Best test accuracy achieved during training: {best_test_acc*100:.3f}%\")\n",
    "\n",
    "    # Load the best model for final evaluation\n",
    "    if os.path.exists(best_model_path):\n",
    "        print(f\"\\nLoading best saved model for {model_class.__name__} from {best_model_path} for final evaluation...\")\n",
    "        model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "        eval_model_description = \"best saved\"\n",
    "    else:\n",
    "        print(f\"\\nNo best model was saved for {model_class.__name__}. Using final model state for evaluation.\")\n",
    "        eval_model_description = \"final\"\n",
    "\n",
    "    print(f\"\\nClassification Report for {model_class.__name__} (using {eval_model_description} model):\")\n",
    "    classification_report_for_model(model, test_loader, device)\n",
    "\n",
    "    print(f\"\\nGender breakdown for {model_class.__name__} (using {eval_model_description} model):\")\n",
    "    gender_results = evaluate_by_gender(test_loader, model, device)\n",
    "    for gender in gender_results:\n",
    "        label = \"Male\" if gender == \"m\" else \"Female\"\n",
    "        metrics = gender_results[gender]\n",
    "        metrics_str = \", \".join([f\"{k.capitalize()}: {v*100:.2f}%\" if isinstance(v, float) else f\"{k.capitalize()}: {v}\" for k, v in metrics.items()])\n",
    "        print(f\"  {label}: {metrics_str}\")\n",
    "\n",
    "    final_train_acc, _, _, _ = evaluate(train_loader, model, device)\n",
    "    print(f\"\\n--- Summary for {model_class.__name__} ---\")\n",
    "    print(f\"- Total epochs trained: {epoch+1}\")\n",
    "    print(f\"- Best validation accuracy during training: {best_test_acc*100:.3f}%\")\n",
    "    print(f\"- Training accuracy of loaded ({eval_model_description}) model: {final_train_acc*100:.2f}%\")\n",
    "    if os.path.exists(best_model_path):\n",
    "        print(f\"- Best model saved to: {best_model_path}\")\n",
    "    else:\n",
    "        print(f\"- Best model not saved (or final model is the best achieved). Final model at: {final_model_path}\")\n",
    "    print(f\"---------------------------------------\\n\")\n",
    "\n",
    "print(\"\\nAll model configurations have been trained and evaluated.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
