{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "\n",
    "class AccentSpectrogramDataset(Dataset):\n",
    "    def __init__(self, folder_path,\n",
    "                 target_sr: int = 16000,\n",
    "                 use_mel: bool = False,\n",
    "                 n_fft: int = 400,\n",
    "                 hop_length: int = None,\n",
    "                 n_mels: int = 64,\n",
    "                 log_scale: bool = True):\n",
    "        # store file paths only; transform per item\n",
    "        self.file_paths = [\n",
    "            os.path.join(folder_path, f)\n",
    "            for f in os.listdir(folder_path)\n",
    "            if f.endswith('.wav')\n",
    "        ]\n",
    "        self.target_sr = target_sr\n",
    "        self.use_mel = use_mel\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length or n_fft // 2\n",
    "        self.n_mels = n_mels\n",
    "        self.log_scale = log_scale\n",
    "\n",
    "        # pre-configure transform funct\n",
    "        if self.use_mel:\n",
    "            self._transform = lambda w: T.MelSpectrogram(\n",
    "                sample_rate=self.target_sr,\n",
    "                n_fft=self.n_fft,\n",
    "                hop_length=self.hop_length,\n",
    "                n_mels=self.n_mels\n",
    "            )(w)\n",
    "        else:\n",
    "            self._transform = lambda w: T.Spectrogram(\n",
    "                n_fft=self.n_fft,\n",
    "                hop_length=self.hop_length\n",
    "            )(w)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.file_paths[idx]\n",
    "        waveform, sr = torchaudio.load(path)\n",
    "        if sr != self.target_sr:\n",
    "            waveform = T.Resample(sr, self.target_sr)(waveform)\n",
    "\n",
    "        spec = self._transform(waveform)\n",
    "        if self.log_scale:\n",
    "            spec = torch.log(spec + 1e-6)\n",
    "\n",
    "        fname = os.path.basename(path)\n",
    "        accent = int(fname[0]) - 1          # classes 0â€“4\n",
    "\n",
    "        return spec, accent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn.functional as F\n",
    "\n",
    "# def pad_collate(batch):\n",
    "#     specs, accents = zip(*batch)\n",
    "\n",
    "#     max_len = max([s.shape[-1] for s in specs])\n",
    "#     padded_specs = []\n",
    "\n",
    "#     for s in specs:\n",
    "#         pad_amount = max_len - s.shape[-1]\n",
    "#         padded = F.pad(s, (0, pad_amount))\n",
    "#         padded_specs.append(padded)\n",
    "\n",
    "    # return (\n",
    "#         torch.stack(padded_specs),             # [B, 1, Freq, Time]\n",
    "#         torch.tensor(accents),                # [B]\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #baseline\n",
    "\n",
    "def pad_collate(batch, target_width=208):\n",
    "    specs, accents = zip(*batch)\n",
    "    padded_specs = []\n",
    "    for s in specs:\n",
    "        pad_amount = target_width - s.shape[-1]\n",
    "        if pad_amount > 0:\n",
    "            padded = F.pad(s, (0, pad_amount))\n",
    "        else:\n",
    "            padded = s[..., :target_width]  # crop if too long\n",
    "        padded_specs.append(padded)\n",
    "    return (\n",
    "        torch.stack(padded_specs),\n",
    "        torch.tensor(accents),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 3166\n",
      "Spectrogram shape: torch.Size([1, 201, 526])\n",
      "Label: 1\n"
     ]
    }
   ],
   "source": [
    "dataset = AccentSpectrogramDataset(\"/Users/larsheijnen/DL/Train\")\n",
    "print(f\"Total samples: {len(dataset)}\")\n",
    "\n",
    "# Look at shape of first spectrogram\n",
    "x, y= dataset[6]\n",
    "print(f\"Spectrogram shape: {x.shape}\")\n",
    "print(f\"Label: {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectrograms: torch.Size([4, 1, 201, 208])\n",
      "Accents: tensor([1, 3, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Use batch_size=4 for low RAM, pin_memory is False for macOS/MPS\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=pad_collate, pin_memory=False)\n",
    "\n",
    "# Try again\n",
    "for batch in dataloader:\n",
    "    spectrograms, accents = batch\n",
    "    print(f\"Spectrograms: {spectrograms.shape}\")  # (B, 1, F, T)\n",
    "    print(f\"Accents: {accents}\")                  # (B,)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AccentCNNBaseline(nn.Module):\n",
    "    def __init__(self, num_classes: int = 5):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.AdaptiveAvgPool2d((16, 16))  \n",
    "        self.fc = nn.Linear(32 * 16 * 16, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "    \n",
    "\n",
    "class AccentCNNBaseline_BatchNorm(nn.Module):\n",
    "    def __init__(self, num_classes: int = 5):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=3, padding=1)\n",
    "        self.bn1   = nn.BatchNorm2d(8)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3, padding=1)\n",
    "        self.bn2   = nn.BatchNorm2d(16)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn3   = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool2d((16, 16))  \n",
    "        self.fc = nn.Linear(32 * 16 * 16, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "    \n",
    "\n",
    "class AccentCNNBaseline_Dropout(nn.Module):\n",
    "    def __init__(self, num_classes: int = 5, dropout_p: float = 0.3):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3, padding=1)\n",
    "                \n",
    "        self.conv3 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.AdaptiveAvgPool2d((16, 16))  \n",
    "\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_p) # Initialize the dropout layer\n",
    "        self.fc = nn.Linear(32 * 16 * 16, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "    \n",
    "\n",
    "\n",
    "class AccentCNNBaseline_Dropout_BatchNorm(nn.Module):\n",
    "    def __init__(self, num_classes: int = 5, dropout_p: float = 0.3):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=3, padding=1)\n",
    "        self.bn1   = nn.BatchNorm2d(8)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3, padding=1)\n",
    "        self.bn2   = nn.BatchNorm2d(16)\n",
    "                \n",
    "        self.conv3 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn3   = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool2d((16, 16))  \n",
    "\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_p) # Initialize the dropout layer\n",
    "        self.fc = nn.Linear(32 * 16 * 16, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "class AccentCNN(nn.Module):\n",
    "    def __init__(self, num_classes: int = 5, dropout_p: float = 0.3):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=3, padding=1)\n",
    "        self.bn1   = nn.BatchNorm2d(8)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3, padding=1)\n",
    "        self.bn2   = nn.BatchNorm2d(16)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn3   = nn.BatchNorm2d(32)\n",
    "        self.pool3 = nn.AdaptiveAvgPool2d((1,1))\n",
    "\n",
    "        self.fc = nn.Linear(32, num_classes) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = x.view(x.size(0), -1)               # â†’ (B, 32)\n",
    "        return self.fc(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 | Train Loss: 1015.482 | Train Acc: 30.69% | Train Recall: 25.81% | Train F1: 16.50% ||  Test Acc: 28.08% | Test Recall: 25.14% | Test F1: 15.09%\n",
      "Epoch  2 | Train Loss: 932.154 | Train Acc: 53.24% | Train Recall: 52.36% | Train F1: 50.07% ||  Test Acc: 44.32% | Test Recall: 44.29% | Test F1: 41.03%\n",
      "Epoch  3 | Train Loss: 676.444 | Train Acc: 72.43% | Train Recall: 68.44% | Train F1: 66.66% ||  Test Acc: 59.62% | Test Recall: 57.57% | Test F1: 52.95%\n",
      "Epoch  4 | Train Loss: 322.329 | Train Acc: 92.50% | Train Recall: 91.42% | Train F1: 91.56% ||  Test Acc: 77.60% | Test Recall: 76.49% | Test F1: 76.66%\n",
      "Epoch  5 | Train Loss: 181.414 | Train Acc: 94.55% | Train Recall: 93.47% | Train F1: 93.85% ||  Test Acc: 81.23% | Test Recall: 80.26% | Test F1: 79.59%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 56\u001b[39m\n\u001b[32m     54\u001b[39m     loss.backward()\n\u001b[32m     55\u001b[39m     optimizer.step()\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     running_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# compute metrics\u001b[39;00m\n\u001b[32m     59\u001b[39m train_acc, train_recall, train_f1 = evaluate(train_loader)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
    "\n",
    "# 1) Prepare dataset & split\n",
    "dataset = AccentSpectrogramDataset(\n",
    "    \"/Users/larsheijnen/DL/Train\",\n",
    "    target_sr=16000,\n",
    "    use_mel=True,\n",
    "    n_fft=1024,\n",
    "    hop_length=256,\n",
    "    n_mels=64,\n",
    "    log_scale=True\n",
    ")\n",
    "train_len = int(0.8 * len(dataset))\n",
    "test_len  = len(dataset) - train_len\n",
    "train_ds, test_ds = random_split(dataset, [train_len, test_len], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True,  collate_fn=pad_collate)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=4, shuffle=False, collate_fn=pad_collate)\n",
    "\n",
    "# 2) Model, criterion, optimizer with weight_decay\n",
    "device    = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model     = AccentCNNBaseline_Dropout_BatchNorm().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# 3) Helper to evaluate on any loader\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for specs, labels in loader:\n",
    "            specs, labels = specs.to(device), labels.to(device)\n",
    "            outputs = model(specs)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_labels.extend(labels.cpu().tolist())\n",
    "    acc    = accuracy_score(all_labels, all_preds)\n",
    "    recall = recall_score(all_labels, all_preds, average='macro')\n",
    "    f1     = f1_score(all_labels, all_preds, average='macro')\n",
    "    return acc, recall, f1\n",
    "\n",
    "# 4) Training loop with train/test metrics per epoch\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for specs, labels in train_loader:\n",
    "        specs, labels = specs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(model(specs), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # compute metrics\n",
    "    train_acc, train_recall, train_f1 = evaluate(train_loader)\n",
    "    test_acc,  test_recall,  test_f1  = evaluate(test_loader)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1:2d} | \"\n",
    "        f\"Train Loss: {running_loss:.3f} | \"\n",
    "        f\"Train Acc: {train_acc*100:5.2f}% | \"\n",
    "        f\"Train Recall: {train_recall*100:5.2f}% | \"\n",
    "        f\"Train F1: {train_f1*100:5.2f}% || \"\n",
    "        f\" Test Acc: {test_acc*100:5.2f}% | \"\n",
    "        f\"Test Recall: {test_recall*100:5.2f}% | \"\n",
    "        f\"Test F1: {test_f1*100:5.2f}%\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
