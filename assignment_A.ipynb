{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data (not augmented)\n",
    "\n",
    "Data augmentation does not happen here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class AccentRawWaveformDataset(Dataset):\n",
    "    def __init__(self, folder_path,\n",
    "                 target_sr: int = 16000,\n",
    "                 standardize: bool = True):\n",
    "        # store file paths only; transform per item\n",
    "        self.file_paths = [\n",
    "            os.path.join(folder_path, f)\n",
    "            for f in os.listdir(folder_path)\n",
    "            if f.endswith('.wav')\n",
    "        ]\n",
    "        self.target_sr = target_sr\n",
    "        self.standardize = standardize\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.file_paths[idx]\n",
    "        waveform, sr = torchaudio.load(path)\n",
    "        if sr != self.target_sr:\n",
    "            waveform = torchaudio.transforms.Resample(sr, self.target_sr)(waveform)\n",
    "        # Convert to mono if not already\n",
    "        if waveform.shape[0] > 1:\n",
    "            waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "        # Standardize (zero mean, unit variance) if requested\n",
    "        if self.standardize:\n",
    "            mean = waveform.mean()\n",
    "            std = waveform.std() if waveform.std() > 0 else 1.0\n",
    "            waveform = (waveform - mean) / std\n",
    "\n",
    "        fname = os.path.basename(path)\n",
    "        accent = int(fname[0]) - 1          # classes 0–4\n",
    "        gender = fname[1]  # 'm' or 'f' \n",
    "        return waveform, accent, gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def pad_1d_collate(batch, target_length=208):\n",
    "    waveforms, accents, genders = zip(*batch)\n",
    "    padded_waveforms = []\n",
    "    for w in waveforms:\n",
    "        pad_amount = target_length - w.shape[-1]\n",
    "        if pad_amount > 0:\n",
    "            # Pad at the end (right side) for 1D waveform\n",
    "            padded = F.pad(w, (0, pad_amount))\n",
    "        else:\n",
    "            padded = w[..., :target_length]\n",
    "        padded_waveforms.append(padded)\n",
    "    return (\n",
    "        torch.stack(padded_waveforms),  # (B, 1, T)\n",
    "        torch.tensor(accents),\n",
    "        list(genders)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's instantiate the dataset and inspect a sample\n",
    "# (Assume the folder path is './data' - change as needed)\n",
    "dataset = AccentRawWaveformDataset(\"/Users/larsheijnen/DL/Train\")\n",
    "\n",
    "print(f\"Number of samples in dataset: {len(dataset)}\")\n",
    "\n",
    "# Get the first sample\n",
    "sample_waveform, sample_accent, sample_gender = dataset[0]\n",
    "\n",
    "print(\"Sample 0 waveform shape:\", sample_waveform.shape)\n",
    "print(\"Sample 0 accent label:\", sample_accent)\n",
    "print(\"Sample 0 gender label:\", sample_gender)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Use batch_size=4 for low RAM, pin_memory is False for macOS/MPS\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=pad_1d_collate, pin_memory=False)\n",
    "\n",
    "# Try again\n",
    "for batch in dataloader:\n",
    "    waveforms, accents, gender = batch\n",
    "    print(f\"Waveforms: {waveforms.shape}\")  # (B, 1, T)\n",
    "    print(f\"Accents: {accents}\")            # (B,)\n",
    "    print(f\"Gender: {gender}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Model 1 (baseline)\n",
    "class CNNBaseline(nn.Module):\n",
    "    def __init__(self, num_classes: int = 5):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 8, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(8, 16, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(16)  # Output: (B, 32, 256)\n",
    "        self.fc = nn.Linear(32 * 16, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, 1, T)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool(x)  # (B, 32, 256)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Model 2 (baseline + batch normalization)\n",
    "class CNNBaseline_BatchNorm(nn.Module):\n",
    "    def __init__(self, num_classes: int = 5):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 8, kernel_size=3, padding=1)\n",
    "        self.bn1   = nn.BatchNorm1d(8)\n",
    "        self.conv2 = nn.Conv1d(8, 16, kernel_size=3, padding=1)\n",
    "        self.bn2   = nn.BatchNorm1d(16)\n",
    "        self.conv3 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn3   = nn.BatchNorm1d(32)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(16)\n",
    "        self.fc = nn.Linear(32 * 16, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Model 3 (baseline + dropout 0.3)\n",
    "class CNNBaseline_Dropout3(nn.Module):\n",
    "    def __init__(self, num_classes: int = 5, dropout_p: float = 0.3):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 8, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(8, 16, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(16)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.fc = nn.Linear(32 * 16, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Model 4 (baseline + dropout 0.5)\n",
    "class CNNBaseline_Dropout5(nn.Module):\n",
    "    def __init__(self, num_classes: int = 5, dropout_p: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 8, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(8, 16, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(16)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.fc = nn.Linear(32 * 16, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Model 5 (baseline + batch normalization + dropout 0.3)\n",
    "class CNNBaseline_Dropout3_BatchNorm(nn.Module):\n",
    "    def __init__(self, num_classes: int = 5, dropout_p: float = 0.3):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 8, kernel_size=3, padding=1)\n",
    "        self.bn1   = nn.BatchNorm1d(8)\n",
    "        self.conv2 = nn.Conv1d(8, 16, kernel_size=3, padding=1)\n",
    "        self.bn2   = nn.BatchNorm1d(16)\n",
    "        self.conv3 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn3   = nn.BatchNorm1d(32)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(16)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.fc = nn.Linear(32 * 16, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Model 6 (baseline + batch normalization + dropout 0.5)\n",
    "class CNNBaseline_Dropout5_BatchNorm(nn.Module):\n",
    "    def __init__(self, num_classes: int = 5, dropout_p: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 8, kernel_size=3, padding=1)\n",
    "        self.bn1   = nn.BatchNorm1d(8)\n",
    "        self.conv2 = nn.Conv1d(8, 16, kernel_size=3, padding=1)\n",
    "        self.bn2   = nn.BatchNorm1d(16)\n",
    "        self.conv3 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn3   = nn.BatchNorm1d(32)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(16)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.fc = nn.Linear(32 * 16, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {\n",
    "    \"Model1\": CNNBaseline,\n",
    "    \"Model2\": CNNBaseline_BatchNorm, \n",
    "    \"Model3\": CNNBaseline_Dropout3,\n",
    "    \"Model4\": CNNBaseline_Dropout5,\n",
    "    \"Model5\": CNNBaseline_Dropout3_BatchNorm,\n",
    "    \"Model6\": CNNBaseline_Dropout5_BatchNorm,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Prepare dataset & split\n",
    "# For 1D data, ensure AccentSpectrogramDataset returns tensors of shape (batch, channels=1, length)\n",
    "dataset = AccentRawWaveformDataset(\n",
    "    '/Users/larsheijnen/DL/Train',\n",
    "    target_sr=16000,\n",
    "    standardize=True\n",
    ")\n",
    "\n",
    "train_len = int(0.8 * len(dataset))\n",
    "test_len  = len(dataset) - train_len\n",
    "train_ds, test_ds = random_split(dataset, [train_len, test_len], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "# For 1D data, pad_collate should pad along the last dimension (length)\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True,  collate_fn=pad_1d_collate)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=4, shuffle=False, collate_fn=pad_1d_collate)\n",
    "\n",
    "device    = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# General (not by gender) evaluation helper\n",
    "def evaluate(loader, model, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for specs, labels, _ in loader:\n",
    "            # For 1D data, specs should be (batch, 1, length)\n",
    "            specs, labels = specs.to(device), labels.to(device)\n",
    "            outputs = model(specs)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_labels.extend(labels.cpu().tolist())\n",
    "    acc    = accuracy_score(all_labels, all_preds)\n",
    "    prec   = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='macro')\n",
    "    f1     = f1_score(all_labels, all_preds, average='macro')\n",
    "    return acc, prec, recall, f1\n",
    "\n",
    "# Gender-based evaluation helper\n",
    "def evaluate_by_gender(loader, model, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels, all_genders = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for specs, labels, genders in loader:\n",
    "            specs, labels = specs.to(device), labels.to(device)\n",
    "            outputs = model(specs)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_labels.extend(labels.cpu().tolist())\n",
    "            all_genders.extend(genders)\n",
    "    results = {}\n",
    "    for gender in ['m', 'f']:\n",
    "        idxs = [i for i, g in enumerate(all_genders) if g == gender]\n",
    "        gender_preds = [all_preds[i] for i in idxs]\n",
    "        gender_labels = [all_labels[i] for i in idxs]\n",
    "        acc = accuracy_score(gender_labels, gender_preds)\n",
    "        prec = precision_score(gender_labels, gender_preds, average='macro', zero_division=0)\n",
    "        recall = recall_score(gender_labels, gender_preds, average='macro')\n",
    "        f1 = f1_score(gender_labels, gender_preds, average='macro')\n",
    "        results[gender] = {'accuracy': acc, 'precision': prec, 'recall': recall, 'f1': f1}\n",
    "    return results\n",
    "\n",
    "def classification_report_for_model(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for specs, labels, _ in loader:\n",
    "            specs, labels = specs.to(device), labels.to(device)\n",
    "            outputs = model(specs)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_labels.extend(labels.cpu().tolist())\n",
    "    print(classification_report(all_labels, all_preds, digits=3))\n",
    "\n",
    "for model_name, model_class in models_dict.items():\n",
    "    model = model_class().to(device)\n",
    "    print(f\"\\n=== Training model: {type(model).__name__} ===\")\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    num_epochs = 10\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for specs, labels, genders in train_loader:\n",
    "            specs, labels = specs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(specs), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Compute and print general metrics for this epoch (not by gender)\n",
    "        train_acc, train_prec, train_recall, train_f1 = evaluate(train_loader, model, device)\n",
    "        test_acc, test_prec, test_recall, test_f1 = evaluate(test_loader, model, device)\n",
    "        print(\n",
    "            f\"Epoch {epoch+1:2d} | \"\n",
    "            f\"Train Loss: {running_loss:.3f} | \"\n",
    "            f\"Train Acc: {train_acc*100:5.2f}% | \"\n",
    "            f\"Train Prec: {train_prec*100:5.2f}% | \"\n",
    "            f\"Train Recall: {train_recall*100:5.2f}% | \"\n",
    "            f\"Train F1: {train_f1*100:5.2f}% || \"\n",
    "            f\"Test Acc: {test_acc*100:5.2f}% | \"\n",
    "            f\"Test Prec: {test_prec*100:5.2f}% | \"\n",
    "            f\"Test Recall: {test_recall*100:5.2f}% | \"\n",
    "            f\"Test F1: {test_f1*100:5.2f}%\"\n",
    "        )\n",
    "        \n",
    "    os.makedirs(\"/Users/larsheijnen/DL/saved_models/A/not_augmented\", exist_ok=True)\n",
    "    torch.save(\n",
    "        model.state_dict(),\n",
    "        f\"/Users/larsheijnen/DL/saved_models/A/not_augmented/{type(model).__name__}_not_augmented_latest_1d.pth\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\nClassification Report for {type(model).__name__}:\")\n",
    "    classification_report_for_model(model, test_loader, device)\n",
    "\n",
    "    print(f\"\\nGender breakdown for {type(model).__name__}:\")\n",
    "    gender_results = evaluate_by_gender(test_loader, model, device)\n",
    "    for gender in gender_results:\n",
    "        label = \"Male\" if gender == \"m\" else \"Female\"\n",
    "        print(f\"{label}: {gender_results[gender]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting acccent on Test data\n",
    "\n",
    "To hand in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = AccentRawWaveformDataset(\n",
    "    '/Users/larsheijnen/DL/Test set',\n",
    "    target_sr=16000,\n",
    "    standardize=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, collate_fn=pad_1d_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# Dynamically determine the saved models directory relative to this script or notebook\n",
    "base_dir = os.path.dirname(os.path.abspath('assignment_A.ipynb'))  # or __file__ if in .py\n",
    "saved_models_dir = os.path.join(base_dir, \"saved_models\", \"A\", \"not_augmented\")\n",
    "\n",
    "# List all .pth files in the directory\n",
    "model_files = [f for f in os.listdir(saved_models_dir) if f.endswith(\".pth\")]\n",
    "\n",
    "# Map model file names to their classes (assumes naming convention: class name is prefix before first underscore or before '_latest')\n",
    "model_classes = {}\n",
    "for fname in model_files:\n",
    "    if fname.startswith(\"CNNBaseline_Dropout3_BatchNorm\"):\n",
    "        model_classes[fname] = CNNBaseline_Dropout3_BatchNorm\n",
    "    elif fname.startswith(\"CNNBaseline_Dropout5_BatchNorm\"):\n",
    "        model_classes[fname] = CNNBaseline_Dropout5_BatchNorm\n",
    "    elif fname.startswith(\"CNNBaseline_Dropout3\"):\n",
    "        model_classes[fname] = CNNBaseline_Dropout3\n",
    "    elif fname.startswith(\"CNNBaseline_Dropout5\"):\n",
    "        model_classes[fname] = CNNBaseline_Dropout5\n",
    "    elif fname.startswith(\"CNNBaseline_BatchNorm\"):\n",
    "        model_classes[fname] = CNNBaseline_BatchNorm\n",
    "    elif fname.startswith(\"CNNBaseline\"):\n",
    "        model_classes[fname] = CNNBaseline\n",
    "    # Add more elifs if you have more model types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_accent_on_testset(model, test_loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_fnames = []\n",
    "    with torch.no_grad():\n",
    "        for i, (specs, _, _) in enumerate(test_loader):  # gender is ignored\n",
    "            specs = specs.to(device)\n",
    "            outputs = model(specs)\n",
    "            preds = outputs.argmax(dim=1).cpu().tolist()\n",
    "            all_preds.extend(preds)\n",
    "            # Get filenames for this batch\n",
    "            batch_indices = range(i * test_loader.batch_size, i * test_loader.batch_size + len(preds))\n",
    "            fnames = [os.path.basename(test_dataset.file_paths[idx]) for idx in batch_indices]\n",
    "            all_fnames.extend(fnames)\n",
    "    return list(zip(all_fnames, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "for model_file, model_class in model_classes.items():\n",
    "    model = model_class().to(device)\n",
    "    model_path = os.path.join(saved_models_dir, model_file)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "    print(f\"\\nPredictions for model: {model_file}\")\n",
    "    results = predict_accent_on_testset(model, test_loader, device)\n",
    "    for fname, pred in results:\n",
    "        print(f\"File: {fname} | Predicted Accent: {pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check models on train data\n",
    "\n",
    "Checking predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_dataset = AccentRawWaveformDataset(\n",
    "    '/Users/larsheijnen/DL/Train',\n",
    "    target_sr=16000,\n",
    "    standardize=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, collate_fn=pad_1d_collate)\n",
    "\n",
    "np.random.seed(42)\n",
    "subset_indices = np.random.choice(len(full_train_dataset), size=100, replace=False)\n",
    "subset_dataset = Subset(full_train_dataset, subset_indices)\n",
    "subset_loader = DataLoader(subset_dataset, batch_size=4, shuffle=False, collate_fn=pad_1d_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_subset(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_fnames = []\n",
    "    with torch.no_grad():\n",
    "        for i, (specs, labels, _) in enumerate(loader):  # ignore gender\n",
    "            specs = specs.to(device)\n",
    "            outputs = model(specs)\n",
    "            preds = outputs.argmax(dim=1).cpu().tolist()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.tolist())\n",
    "            # Get filenames for this batch\n",
    "            batch_indices = range(i * loader.batch_size, i * loader.batch_size + len(preds))\n",
    "            fnames = [os.path.basename(full_train_dataset.file_paths[idx]) for idx in subset_indices[batch_indices.start:batch_indices.stop]]\n",
    "            all_fnames.extend(fnames)\n",
    "    return list(zip(all_fnames, all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_file in model_files:\n",
    "    model_class = model_classes[model_file]\n",
    "    model = model_class().to(device)\n",
    "    model_path = os.path.join(saved_models_dir, model_file)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "    print(f\"\\nEvaluation on subset for model: {model_file}\")\n",
    "    results = evaluate_on_subset(model, subset_loader, device)\n",
    "    correct = 0\n",
    "    for fname, true_label, pred_label in results:\n",
    "        is_correct = true_label == pred_label\n",
    "        correct += is_correct\n",
    "        print(f\"File: {fname} | True Accent: {true_label + 1} | Predicted Accent: {pred_label + 1} | {'✔️' if is_correct else '❌'}\")\n",
    "    print(f\"Accuracy on subset: {correct/len(results)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation\n",
    "\n",
    "Hier voegen we onder andere noise toe, en trainen we de modellen opnieuw. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import os\n",
    "\n",
    "class AccentRawWaveformDatasetAug(AccentRawWaveformDataset):\n",
    "    def __init__(self, *args, noise_level=0.005, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.noise_level = noise_level\n",
    "\n",
    "    def add_noise(self, waveform, noise_level=None):\n",
    "        if noise_level is None:\n",
    "            noise_level = self.noise_level\n",
    "        noise = torch.randn_like(waveform) * noise_level\n",
    "        return waveform + noise\n",
    "\n",
    "    def time_shift(self, waveform, shift_max=0.2):\n",
    "        shift = int(waveform.size(1) * shift_max * (2 * torch.rand(1) - 1))\n",
    "        return torch.roll(waveform, shifts=shift, dims=1)\n",
    "\n",
    "    def random_volume(self, waveform, min_gain=0.8, max_gain=1.2):\n",
    "        gain = torch.empty(1).uniform_(min_gain, max_gain)\n",
    "        return waveform * gain\n",
    "\n",
    "    def augment(self, waveform, sr):\n",
    "        if torch.rand(1).item() < 0.5:\n",
    "            waveform = self.add_noise(waveform)\n",
    "        if torch.rand(1).item() < 0.5:\n",
    "            waveform = self.time_shift(waveform)\n",
    "        if torch.rand(1).item() < 0.5:\n",
    "            waveform = self.random_volume(waveform)\n",
    "        return waveform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        waveform, accent, gender = super().__getitem__(idx)\n",
    "        waveform = self.augment(waveform, self.target_sr)\n",
    "        return waveform, accent, gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def pad_1d_collate(batch, target_length=208):\n",
    "    waveforms, accents, genders = zip(*batch)\n",
    "    padded_waveforms = []\n",
    "    for w in waveforms:\n",
    "        pad_amount = target_length - w.shape[-1]\n",
    "        if pad_amount > 0:\n",
    "            # Pad at the end (right side) for 1D waveform\n",
    "            padded = F.pad(w, (0, pad_amount))\n",
    "        else:\n",
    "            padded = w[..., :target_length]\n",
    "        padded_waveforms.append(padded)\n",
    "    return (\n",
    "        torch.stack(padded_waveforms),  # (B, 1, T)\n",
    "        torch.tensor(accents),\n",
    "        list(genders)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in dataset: 3166\n",
      "Sample 0 waveform shape: torch.Size([1, 41400])\n",
      "Sample 0 accent label: 1\n",
      "Sample 0 gender label: m\n"
     ]
    }
   ],
   "source": [
    "# Let's instantiate the dataset and inspect a sample\n",
    "# (Assume the folder path is './data' - change as needed)\n",
    "dataset = AccentRawWaveformDatasetAug(\"/Users/larsheijnen/DL/Train\")\n",
    "\n",
    "print(f\"Number of samples in dataset: {len(dataset)}\")\n",
    "\n",
    "# Get the first sample\n",
    "sample_waveform, sample_accent, sample_gender = dataset[0]\n",
    "\n",
    "print(\"Sample 0 waveform shape:\", sample_waveform.shape)\n",
    "print(\"Sample 0 accent label:\", sample_accent)\n",
    "print(\"Sample 0 gender label:\", sample_gender)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waveforms: torch.Size([4, 1, 208])\n",
      "Accents: tensor([3, 3, 0, 0])\n",
      "Gender: ['m', 'm', 'f', 'f']\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Use batch_size=4 for low RAM, pin_memory is False for macOS/MPS\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=pad_1d_collate, pin_memory=False)\n",
    "\n",
    "# Try again\n",
    "for batch in dataloader:\n",
    "    waveforms, accents, gender = batch\n",
    "    print(f\"Waveforms: {waveforms.shape}\")  # (B, 1, T)\n",
    "    print(f\"Accents: {accents}\")            # (B,)\n",
    "    print(f\"Gender: {gender}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Model 1 (baseline)\n",
    "class CNNBaseline(nn.Module):\n",
    "    def __init__(self, num_classes: int = 5):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 8, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(8, 16, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(16)  # Output: (B, 32, 256)\n",
    "        self.fc = nn.Linear(32 * 16, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, 1, T)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool(x)  # (B, 32, 256)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Model 2 (baseline + batch normalization)\n",
    "class CNNBaseline_BatchNorm(nn.Module):\n",
    "    def __init__(self, num_classes: int = 5):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 8, kernel_size=3, padding=1)\n",
    "        self.bn1   = nn.BatchNorm1d(8)\n",
    "        self.conv2 = nn.Conv1d(8, 16, kernel_size=3, padding=1)\n",
    "        self.bn2   = nn.BatchNorm1d(16)\n",
    "        self.conv3 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn3   = nn.BatchNorm1d(32)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(16)\n",
    "        self.fc = nn.Linear(32 * 16, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Model 3 (baseline + dropout 0.3)\n",
    "class CNNBaseline_Dropout3(nn.Module):\n",
    "    def __init__(self, num_classes: int = 5, dropout_p: float = 0.3):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 8, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(8, 16, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(16)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.fc = nn.Linear(32 * 16, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Model 4 (baseline + dropout 0.5)\n",
    "class CNNBaseline_Dropout5(nn.Module):\n",
    "    def __init__(self, num_classes: int = 5, dropout_p: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 8, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(8, 16, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(16)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.fc = nn.Linear(32 * 16, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Model 5 (baseline + batch normalization + dropout 0.3)\n",
    "class CNNBaseline_Dropout3_BatchNorm(nn.Module):\n",
    "    def __init__(self, num_classes: int = 5, dropout_p: float = 0.3):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 8, kernel_size=3, padding=1)\n",
    "        self.bn1   = nn.BatchNorm1d(8)\n",
    "        self.conv2 = nn.Conv1d(8, 16, kernel_size=3, padding=1)\n",
    "        self.bn2   = nn.BatchNorm1d(16)\n",
    "        self.conv3 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn3   = nn.BatchNorm1d(32)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(16)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.fc = nn.Linear(32 * 16, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Model 6 (baseline + batch normalization + dropout 0.5)\n",
    "class CNNBaseline_Dropout5_BatchNorm(nn.Module):\n",
    "    def __init__(self, num_classes: int = 5, dropout_p: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 8, kernel_size=3, padding=1)\n",
    "        self.bn1   = nn.BatchNorm1d(8)\n",
    "        self.conv2 = nn.Conv1d(8, 16, kernel_size=3, padding=1)\n",
    "        self.bn2   = nn.BatchNorm1d(16)\n",
    "        self.conv3 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn3   = nn.BatchNorm1d(32)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(16)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.fc = nn.Linear(32 * 16, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {\n",
    "    \"Model1\": CNNBaseline,\n",
    "    \"Model2\": CNNBaseline_BatchNorm, \n",
    "    \"Model3\": CNNBaseline_Dropout3,\n",
    "    \"Model4\": CNNBaseline_Dropout5,\n",
    "    \"Model5\": CNNBaseline_Dropout3_BatchNorm,\n",
    "    \"Model6\": CNNBaseline_Dropout5_BatchNorm,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training model: CNNBaseline ===\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 89\u001b[39m\n\u001b[32m     87\u001b[39m specs, labels = specs.to(device), labels.to(device)\n\u001b[32m     88\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m loss = criterion(\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspecs\u001b[49m\u001b[43m)\u001b[49m, labels)\n\u001b[32m     90\u001b[39m loss.backward()\n\u001b[32m     91\u001b[39m optimizer.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DL/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DL/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mCNNBaseline.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     19\u001b[39m x = \u001b[38;5;28mself\u001b[39m.pool(x)  \u001b[38;5;66;03m# (B, 32, 256)\u001b[39;00m\n\u001b[32m     20\u001b[39m x = x.view(x.size(\u001b[32m0\u001b[39m), -\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DL/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DL/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DL/.venv/lib/python3.11/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Prepare dataset & split\n",
    "# For 1D data, ensure AccentSpectrogramDataset returns tensors of shape (batch, channels=1, length)\n",
    "dataset = AccentRawWaveformDatasetAug(\n",
    "    '/Users/larsheijnen/DL/Train',\n",
    "    target_sr=16000,\n",
    "    standardize=True\n",
    ")\n",
    "\n",
    "train_len = int(0.8 * len(dataset))\n",
    "test_len  = len(dataset) - train_len\n",
    "train_ds, test_ds = random_split(dataset, [train_len, test_len], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "# For 1D data, pad_collate should pad along the last dimension (length)\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True,  collate_fn=pad_1d_collate)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=4, shuffle=False, collate_fn=pad_1d_collate)\n",
    "\n",
    "device    = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# General (not by gender) evaluation helper\n",
    "def evaluate(loader, model, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for specs, labels, _ in loader:\n",
    "            # For 1D data, specs should be (batch, 1, length)\n",
    "            specs, labels = specs.to(device), labels.to(device)\n",
    "            outputs = model(specs)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_labels.extend(labels.cpu().tolist())\n",
    "    acc    = accuracy_score(all_labels, all_preds)\n",
    "    prec   = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='macro')\n",
    "    f1     = f1_score(all_labels, all_preds, average='macro')\n",
    "    return acc, prec, recall, f1\n",
    "\n",
    "# Gender-based evaluation helper\n",
    "def evaluate_by_gender(loader, model, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels, all_genders = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for specs, labels, genders in loader:\n",
    "            specs, labels = specs.to(device), labels.to(device)\n",
    "            outputs = model(specs)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_labels.extend(labels.cpu().tolist())\n",
    "            all_genders.extend(genders)\n",
    "    results = {}\n",
    "    for gender in ['m', 'f']:\n",
    "        idxs = [i for i, g in enumerate(all_genders) if g == gender]\n",
    "        gender_preds = [all_preds[i] for i in idxs]\n",
    "        gender_labels = [all_labels[i] for i in idxs]\n",
    "        acc = accuracy_score(gender_labels, gender_preds)\n",
    "        prec = precision_score(gender_labels, gender_preds, average='macro', zero_division=0)\n",
    "        recall = recall_score(gender_labels, gender_preds, average='macro')\n",
    "        f1 = f1_score(gender_labels, gender_preds, average='macro')\n",
    "        results[gender] = {'accuracy': acc, 'precision': prec, 'recall': recall, 'f1': f1}\n",
    "    return results\n",
    "\n",
    "def classification_report_for_model(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for specs, labels, _ in loader:\n",
    "            specs, labels = specs.to(device), labels.to(device)\n",
    "            outputs = model(specs)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_labels.extend(labels.cpu().tolist())\n",
    "    print(classification_report(all_labels, all_preds, digits=3))\n",
    "\n",
    "for model_name, model_class in models_dict.items():\n",
    "    model = model_class().to(device)\n",
    "    print(f\"\\n=== Training model: {type(model).__name__} ===\")\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    num_epochs = 10\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for specs, labels, genders in train_loader:\n",
    "            specs, labels = specs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(specs), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Compute and print general metrics for this epoch (not by gender)\n",
    "        train_acc, train_prec, train_recall, train_f1 = evaluate(train_loader, model, device)\n",
    "        test_acc, test_prec, test_recall, test_f1 = evaluate(test_loader, model, device)\n",
    "        print(\n",
    "            f\"Epoch {epoch+1:2d} | \"\n",
    "            f\"Train Loss: {running_loss:.3f} | \"\n",
    "            f\"Train Acc: {train_acc*100:5.2f}% | \"\n",
    "            f\"Train Prec: {train_prec*100:5.2f}% | \"\n",
    "            f\"Train Recall: {train_recall*100:5.2f}% | \"\n",
    "            f\"Train F1: {train_f1*100:5.2f}% || \"\n",
    "            f\"Test Acc: {test_acc*100:5.2f}% | \"\n",
    "            f\"Test Prec: {test_prec*100:5.2f}% | \"\n",
    "            f\"Test Recall: {test_recall*100:5.2f}% | \"\n",
    "            f\"Test F1: {test_f1*100:5.2f}%\"\n",
    "        )\n",
    "        \n",
    "    os.makedirs(\"/Users/larsheijnen/DL/saved_models/A/augmented\", exist_ok=True)\n",
    "    torch.save(\n",
    "        model.state_dict(),\n",
    "        f\"/Users/larsheijnen/DL/saved_models/A/augmented/{type(model).__name__}_augmented_latest_1d.pth\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\nClassification Report for {type(model).__name__}:\")\n",
    "    classification_report_for_model(model, test_loader, device)\n",
    "\n",
    "    print(f\"\\nGender breakdown for {type(model).__name__}:\")\n",
    "    gender_results = evaluate_by_gender(test_loader, model, device)\n",
    "    for gender in gender_results:\n",
    "        label = \"Male\" if gender == \"m\" else \"Female\"\n",
    "        print(f\"{label}: {gender_results[gender]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmented Data and Training with early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Number of training samples: 2532\n",
      "Number of test samples: 634\n",
      "\n",
      "=== Training model: CNNBaseline (Early Stopping, Augmented Data) ===\n",
      "Epoch   1/150 | Loss: 1.5990 | Train Acc: 23.85% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 0/20\n",
      "    → New best test accuracy: 23.659% (saved to /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_best.pth)\n",
      "Epoch   2/150 | Loss: 1.5964 | Train Acc: 23.78% | Test Acc: 21.77% | Test F1:  7.15% | Patience: 0/20\n",
      "Epoch   3/150 | Loss: 1.5963 | Train Acc: 23.93% | Test Acc: 21.29% | Test F1:  7.03% | Patience: 1/20\n",
      "Epoch   4/150 | Loss: 1.5956 | Train Acc: 24.05% | Test Acc: 22.40% | Test F1:  9.03% | Patience: 2/20\n",
      "Epoch   5/150 | Loss: 1.5956 | Train Acc: 23.85% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 3/20\n",
      "Epoch   6/150 | Loss: 1.5949 | Train Acc: 24.13% | Test Acc: 21.92% | Test F1:  8.12% | Patience: 4/20\n",
      "Epoch   7/150 | Loss: 1.5952 | Train Acc: 23.66% | Test Acc: 23.50% | Test F1:  9.38% | Patience: 5/20\n",
      "Epoch   8/150 | Loss: 1.5945 | Train Acc: 23.50% | Test Acc: 22.87% | Test F1:  8.42% | Patience: 6/20\n",
      "Epoch   9/150 | Loss: 1.5951 | Train Acc: 23.89% | Test Acc: 21.77% | Test F1:  7.17% | Patience: 7/20\n",
      "Epoch  10/150 | Loss: 1.5946 | Train Acc: 24.01% | Test Acc: 22.40% | Test F1:  9.16% | Patience: 8/20\n",
      "Epoch  11/150 | Loss: 1.5955 | Train Acc: 23.85% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 9/20\n",
      "Epoch  12/150 | Loss: 1.5949 | Train Acc: 23.66% | Test Acc: 23.19% | Test F1:  7.80% | Patience: 10/20\n",
      "Epoch  13/150 | Loss: 1.5940 | Train Acc: 23.58% | Test Acc: 21.45% | Test F1:  8.69% | Patience: 11/20\n",
      "Epoch  14/150 | Loss: 1.5941 | Train Acc: 23.97% | Test Acc: 20.98% | Test F1:  8.54% | Patience: 12/20\n",
      "Epoch  15/150 | Loss: 1.5956 | Train Acc: 24.21% | Test Acc: 21.77% | Test F1:  9.38% | Patience: 13/20\n",
      "Epoch  16/150 | Loss: 1.5947 | Train Acc: 24.49% | Test Acc: 22.08% | Test F1:  8.72% | Patience: 14/20\n",
      "Epoch  17/150 | Loss: 1.5941 | Train Acc: 23.85% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 15/20\n",
      "Epoch  18/150 | Loss: 1.5933 | Train Acc: 24.13% | Test Acc: 22.08% | Test F1:  9.75% | Patience: 16/20\n",
      "Epoch  19/150 | Loss: 1.5945 | Train Acc: 23.66% | Test Acc: 22.56% | Test F1:  9.79% | Patience: 17/20\n",
      "Epoch  20/150 | Loss: 1.5934 | Train Acc: 23.85% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 18/20\n",
      "Epoch  21/150 | Loss: 1.5946 | Train Acc: 23.82% | Test Acc: 22.40% | Test F1:  9.73% | Patience: 19/20\n",
      "\n",
      "Early stopping triggered for CNNBaseline after 21 epochs.\n",
      "Final training state for CNNBaseline saved to /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_final.pth\n",
      "\n",
      "Training completed for CNNBaseline after 21 epochs.\n",
      "Best test accuracy achieved during training: 23.659%\n",
      "\n",
      "Loading best saved model for CNNBaseline from /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_best.pth for final evaluation...\n",
      "\n",
      "Classification Report for CNNBaseline (using best saved model):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       138\n",
      "           1      0.000     0.000     0.000       118\n",
      "           2      0.000     0.000     0.000       120\n",
      "           3      0.237     1.000     0.383       150\n",
      "           4      0.000     0.000     0.000       108\n",
      "\n",
      "    accuracy                          0.237       634\n",
      "   macro avg      0.047     0.200     0.077       634\n",
      "weighted avg      0.056     0.237     0.091       634\n",
      "\n",
      "\n",
      "Gender breakdown for CNNBaseline (using best saved model):\n",
      "  Male: Accuracy: 25.16%, Precision: 5.03%, Recall: 20.00%, F1: 8.04%\n",
      "  Female: Accuracy: 22.19%, Precision: 4.44%, Recall: 20.00%, F1: 7.26%\n",
      "\n",
      "--- Summary for CNNBaseline ---\n",
      "- Total epochs trained: 21\n",
      "- Best validation accuracy during training: 23.659%\n",
      "- Training accuracy of loaded (best saved) model: 23.85%\n",
      "- Best model saved to: /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_best.pth\n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "=== Training model: CNNBaseline_BatchNorm (Early Stopping, Augmented Data) ===\n",
      "Epoch   1/150 | Loss: 1.6307 | Train Acc: 23.74% | Test Acc: 23.50% | Test F1:  7.91% | Patience: 0/20\n",
      "    → New best test accuracy: 23.502% (saved to /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_BatchNorm_best.pth)\n",
      "Epoch   2/150 | Loss: 1.5977 | Train Acc: 21.25% | Test Acc: 19.09% | Test F1: 10.05% | Patience: 0/20\n",
      "Epoch   3/150 | Loss: 1.5757 | Train Acc: 23.82% | Test Acc: 23.66% | Test F1:  8.65% | Patience: 1/20\n",
      "Epoch   4/150 | Loss: 1.5799 | Train Acc: 23.58% | Test Acc: 23.03% | Test F1:  9.95% | Patience: 2/20\n",
      "Epoch   5/150 | Loss: 1.5621 | Train Acc: 18.80% | Test Acc: 19.72% | Test F1: 11.59% | Patience: 3/20\n",
      "Epoch   6/150 | Loss: 1.5696 | Train Acc: 24.21% | Test Acc: 23.82% | Test F1: 10.79% | Patience: 4/20\n",
      "Epoch   7/150 | Loss: 1.5703 | Train Acc: 23.85% | Test Acc: 21.61% | Test F1:  9.52% | Patience: 5/20\n",
      "Epoch   8/150 | Loss: 1.5600 | Train Acc: 23.58% | Test Acc: 23.50% | Test F1:  9.55% | Patience: 6/20\n",
      "Epoch   9/150 | Loss: 1.5581 | Train Acc: 23.62% | Test Acc: 23.19% | Test F1:  9.34% | Patience: 7/20\n",
      "Epoch  10/150 | Loss: 1.5546 | Train Acc: 23.70% | Test Acc: 22.40% | Test F1:  9.66% | Patience: 8/20\n",
      "Epoch  11/150 | Loss: 1.5533 | Train Acc: 15.09% | Test Acc: 17.03% | Test F1:  8.84% | Patience: 9/20\n",
      "Epoch  12/150 | Loss: 1.5532 | Train Acc: 23.62% | Test Acc: 23.34% | Test F1:  8.12% | Patience: 10/20\n",
      "Epoch  13/150 | Loss: 1.5429 | Train Acc: 23.82% | Test Acc: 21.92% | Test F1: 10.22% | Patience: 11/20\n",
      "Epoch  14/150 | Loss: 1.5473 | Train Acc: 19.75% | Test Acc: 19.24% | Test F1:  9.04% | Patience: 12/20\n",
      "Epoch  15/150 | Loss: 1.5603 | Train Acc: 22.35% | Test Acc: 23.50% | Test F1: 13.83% | Patience: 13/20\n",
      "Epoch  16/150 | Loss: 1.5520 | Train Acc: 23.18% | Test Acc: 22.56% | Test F1:  8.55% | Patience: 14/20\n",
      "Epoch  17/150 | Loss: 1.5597 | Train Acc: 21.68% | Test Acc: 22.40% | Test F1: 14.32% | Patience: 15/20\n",
      "Epoch  18/150 | Loss: 1.5539 | Train Acc: 23.34% | Test Acc: 22.87% | Test F1:  8.70% | Patience: 16/20\n",
      "Epoch  19/150 | Loss: 1.5481 | Train Acc: 22.00% | Test Acc: 20.98% | Test F1: 12.51% | Patience: 17/20\n",
      "Epoch  20/150 | Loss: 1.5432 | Train Acc: 23.93% | Test Acc: 23.82% | Test F1:  9.46% | Patience: 18/20\n",
      "Epoch  21/150 | Loss: 1.5482 | Train Acc: 20.02% | Test Acc: 18.45% | Test F1:  7.67% | Patience: 19/20\n",
      "\n",
      "Early stopping triggered for CNNBaseline_BatchNorm after 21 epochs.\n",
      "Final training state for CNNBaseline_BatchNorm saved to /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_BatchNorm_final.pth\n",
      "\n",
      "Training completed for CNNBaseline_BatchNorm after 21 epochs.\n",
      "Best test accuracy achieved during training: 23.502%\n",
      "\n",
      "Loading best saved model for CNNBaseline_BatchNorm from /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_BatchNorm_best.pth for final evaluation...\n",
      "\n",
      "Classification Report for CNNBaseline_BatchNorm (using best saved model):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.143     0.007     0.014       138\n",
      "           1      0.000     0.000     0.000       118\n",
      "           2      0.000     0.000     0.000       120\n",
      "           3      0.236     0.980     0.380       150\n",
      "           4      1.000     0.009     0.018       108\n",
      "\n",
      "    accuracy                          0.235       634\n",
      "   macro avg      0.276     0.199     0.082       634\n",
      "weighted avg      0.257     0.235     0.096       634\n",
      "\n",
      "\n",
      "Gender breakdown for CNNBaseline_BatchNorm (using best saved model):\n",
      "  Male: Accuracy: 24.84%, Precision: 15.00%, Recall: 19.87%, F1: 8.69%\n",
      "  Female: Accuracy: 22.19%, Precision: 4.44%, Recall: 20.00%, F1: 7.26%\n",
      "\n",
      "--- Summary for CNNBaseline_BatchNorm ---\n",
      "- Total epochs trained: 21\n",
      "- Best validation accuracy during training: 23.502%\n",
      "- Training accuracy of loaded (best saved) model: 23.97%\n",
      "- Best model saved to: /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_BatchNorm_best.pth\n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "=== Training model: CNNBaseline_Dropout3 (Early Stopping, Augmented Data) ===\n",
      "Epoch   1/150 | Loss: 1.5999 | Train Acc: 23.89% | Test Acc: 21.92% | Test F1:  8.11% | Patience: 0/20\n",
      "    → New best test accuracy: 21.924% (saved to /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout3_best.pth)\n",
      "Epoch   2/150 | Loss: 1.5971 | Train Acc: 23.85% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 0/20\n",
      "    → New best test accuracy: 23.659% (saved to /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout3_best.pth)\n",
      "Epoch   3/150 | Loss: 1.5956 | Train Acc: 23.89% | Test Acc: 22.24% | Test F1:  7.98% | Patience: 0/20\n",
      "Epoch   4/150 | Loss: 1.5952 | Train Acc: 23.82% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 1/20\n",
      "Epoch   5/150 | Loss: 1.5961 | Train Acc: 23.93% | Test Acc: 20.82% | Test F1:  8.13% | Patience: 2/20\n",
      "Epoch   6/150 | Loss: 1.5948 | Train Acc: 23.85% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 3/20\n",
      "Epoch   7/150 | Loss: 1.5951 | Train Acc: 23.74% | Test Acc: 20.50% | Test F1:  7.91% | Patience: 4/20\n",
      "Epoch   8/150 | Loss: 1.5952 | Train Acc: 23.78% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 5/20\n",
      "Epoch   9/150 | Loss: 1.5947 | Train Acc: 23.78% | Test Acc: 23.66% | Test F1:  8.17% | Patience: 6/20\n",
      "Epoch  10/150 | Loss: 1.5951 | Train Acc: 23.82% | Test Acc: 23.34% | Test F1:  7.57% | Patience: 7/20\n",
      "Epoch  11/150 | Loss: 1.5944 | Train Acc: 24.01% | Test Acc: 21.45% | Test F1:  7.18% | Patience: 8/20\n",
      "Epoch  12/150 | Loss: 1.5944 | Train Acc: 23.82% | Test Acc: 23.66% | Test F1:  7.67% | Patience: 9/20\n",
      "Epoch  13/150 | Loss: 1.5938 | Train Acc: 24.41% | Test Acc: 21.45% | Test F1:  8.83% | Patience: 10/20\n",
      "Epoch  14/150 | Loss: 1.5947 | Train Acc: 24.01% | Test Acc: 21.61% | Test F1:  9.18% | Patience: 11/20\n",
      "Epoch  15/150 | Loss: 1.5946 | Train Acc: 23.85% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 12/20\n",
      "Epoch  16/150 | Loss: 1.5943 | Train Acc: 23.78% | Test Acc: 21.77% | Test F1:  7.16% | Patience: 13/20\n",
      "Epoch  17/150 | Loss: 1.5940 | Train Acc: 24.09% | Test Acc: 21.77% | Test F1:  7.64% | Patience: 14/20\n",
      "Epoch  18/150 | Loss: 1.5943 | Train Acc: 23.85% | Test Acc: 23.19% | Test F1:  7.53% | Patience: 15/20\n",
      "Epoch  19/150 | Loss: 1.5943 | Train Acc: 23.50% | Test Acc: 22.08% | Test F1:  8.89% | Patience: 16/20\n",
      "Epoch  20/150 | Loss: 1.5941 | Train Acc: 24.64% | Test Acc: 21.77% | Test F1:  9.38% | Patience: 17/20\n",
      "Epoch  21/150 | Loss: 1.5940 | Train Acc: 23.74% | Test Acc: 21.61% | Test F1:  9.33% | Patience: 18/20\n",
      "Epoch  22/150 | Loss: 1.5941 | Train Acc: 23.58% | Test Acc: 21.77% | Test F1:  8.95% | Patience: 19/20\n",
      "\n",
      "Early stopping triggered for CNNBaseline_Dropout3 after 22 epochs.\n",
      "Final training state for CNNBaseline_Dropout3 saved to /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout3_final.pth\n",
      "\n",
      "Training completed for CNNBaseline_Dropout3 after 22 epochs.\n",
      "Best test accuracy achieved during training: 23.659%\n",
      "\n",
      "Loading best saved model for CNNBaseline_Dropout3 from /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout3_best.pth for final evaluation...\n",
      "\n",
      "Classification Report for CNNBaseline_Dropout3 (using best saved model):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       138\n",
      "           1      0.000     0.000     0.000       118\n",
      "           2      0.000     0.000     0.000       120\n",
      "           3      0.237     1.000     0.383       150\n",
      "           4      0.000     0.000     0.000       108\n",
      "\n",
      "    accuracy                          0.237       634\n",
      "   macro avg      0.047     0.200     0.077       634\n",
      "weighted avg      0.056     0.237     0.091       634\n",
      "\n",
      "\n",
      "Gender breakdown for CNNBaseline_Dropout3 (using best saved model):\n",
      "  Male: Accuracy: 25.16%, Precision: 5.03%, Recall: 20.00%, F1: 8.04%\n",
      "  Female: Accuracy: 22.19%, Precision: 4.44%, Recall: 20.00%, F1: 7.26%\n",
      "\n",
      "--- Summary for CNNBaseline_Dropout3 ---\n",
      "- Total epochs trained: 22\n",
      "- Best validation accuracy during training: 23.659%\n",
      "- Training accuracy of loaded (best saved) model: 23.89%\n",
      "- Best model saved to: /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout3_best.pth\n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "=== Training model: CNNBaseline_Dropout5 (Early Stopping, Augmented Data) ===\n",
      "Epoch   1/150 | Loss: 1.6010 | Train Acc: 23.82% | Test Acc: 21.92% | Test F1:  7.43% | Patience: 0/20\n",
      "    → New best test accuracy: 21.924% (saved to /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout5_best.pth)\n",
      "Epoch   2/150 | Loss: 1.5966 | Train Acc: 23.85% | Test Acc: 21.77% | Test F1:  7.16% | Patience: 0/20\n",
      "Epoch   3/150 | Loss: 1.5960 | Train Acc: 24.09% | Test Acc: 23.19% | Test F1:  9.47% | Patience: 1/20\n",
      "    → New best test accuracy: 23.186% (saved to /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout5_best.pth)\n",
      "Epoch   4/150 | Loss: 1.5954 | Train Acc: 23.85% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 0/20\n",
      "Epoch   5/150 | Loss: 1.5959 | Train Acc: 23.85% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 1/20\n",
      "Epoch   6/150 | Loss: 1.5947 | Train Acc: 24.21% | Test Acc: 22.56% | Test F1:  9.97% | Patience: 2/20\n",
      "Epoch   7/150 | Loss: 1.5949 | Train Acc: 23.78% | Test Acc: 23.50% | Test F1:  7.87% | Patience: 3/20\n",
      "Epoch   8/150 | Loss: 1.5942 | Train Acc: 23.85% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 4/20\n",
      "Epoch   9/150 | Loss: 1.5948 | Train Acc: 24.01% | Test Acc: 22.87% | Test F1: 10.40% | Patience: 5/20\n",
      "Epoch  10/150 | Loss: 1.5949 | Train Acc: 24.09% | Test Acc: 21.61% | Test F1:  7.82% | Patience: 6/20\n",
      "Epoch  11/150 | Loss: 1.5942 | Train Acc: 23.85% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 7/20\n",
      "Epoch  12/150 | Loss: 1.5948 | Train Acc: 23.85% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 8/20\n",
      "Epoch  13/150 | Loss: 1.5950 | Train Acc: 23.85% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 9/20\n",
      "Epoch  14/150 | Loss: 1.5950 | Train Acc: 23.97% | Test Acc: 23.03% | Test F1:  9.53% | Patience: 10/20\n",
      "Epoch  15/150 | Loss: 1.5948 | Train Acc: 24.09% | Test Acc: 22.08% | Test F1:  8.57% | Patience: 11/20\n",
      "Epoch  16/150 | Loss: 1.5940 | Train Acc: 23.85% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 12/20\n",
      "Epoch  17/150 | Loss: 1.5940 | Train Acc: 23.70% | Test Acc: 24.13% | Test F1:  8.66% | Patience: 13/20\n",
      "    → New best test accuracy: 24.132% (saved to /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout5_best.pth)\n",
      "Epoch  18/150 | Loss: 1.5941 | Train Acc: 23.97% | Test Acc: 21.92% | Test F1:  9.18% | Patience: 0/20\n",
      "Epoch  19/150 | Loss: 1.5942 | Train Acc: 23.97% | Test Acc: 21.77% | Test F1:  8.94% | Patience: 1/20\n",
      "Epoch  20/150 | Loss: 1.5945 | Train Acc: 23.85% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 2/20\n",
      "Epoch  21/150 | Loss: 1.5935 | Train Acc: 23.97% | Test Acc: 23.82% | Test F1:  7.99% | Patience: 3/20\n",
      "Epoch  22/150 | Loss: 1.5940 | Train Acc: 24.05% | Test Acc: 22.24% | Test F1:  9.63% | Patience: 4/20\n",
      "Epoch  23/150 | Loss: 1.5947 | Train Acc: 24.09% | Test Acc: 22.87% | Test F1: 10.12% | Patience: 5/20\n",
      "Epoch  24/150 | Loss: 1.5944 | Train Acc: 24.29% | Test Acc: 21.92% | Test F1:  9.84% | Patience: 6/20\n",
      "Epoch  25/150 | Loss: 1.5943 | Train Acc: 24.01% | Test Acc: 21.77% | Test F1:  8.79% | Patience: 7/20\n",
      "Epoch  26/150 | Loss: 1.5943 | Train Acc: 23.97% | Test Acc: 22.40% | Test F1: 10.15% | Patience: 8/20\n",
      "Epoch  27/150 | Loss: 1.5940 | Train Acc: 23.78% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 9/20\n",
      "Epoch  28/150 | Loss: 1.5939 | Train Acc: 23.93% | Test Acc: 23.66% | Test F1:  7.91% | Patience: 10/20\n",
      "Epoch  29/150 | Loss: 1.5942 | Train Acc: 23.62% | Test Acc: 21.77% | Test F1:  9.24% | Patience: 11/20\n",
      "Epoch  30/150 | Loss: 1.5942 | Train Acc: 23.85% | Test Acc: 22.24% | Test F1: 10.17% | Patience: 12/20\n",
      "Epoch  31/150 | Loss: 1.5942 | Train Acc: 24.49% | Test Acc: 23.03% | Test F1: 10.34% | Patience: 13/20\n",
      "Epoch  32/150 | Loss: 1.5937 | Train Acc: 24.01% | Test Acc: 21.92% | Test F1:  9.00% | Patience: 14/20\n",
      "Epoch  33/150 | Loss: 1.5940 | Train Acc: 24.29% | Test Acc: 22.71% | Test F1: 10.17% | Patience: 15/20\n",
      "Epoch  34/150 | Loss: 1.5942 | Train Acc: 23.85% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 16/20\n",
      "Epoch  35/150 | Loss: 1.5937 | Train Acc: 23.85% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 17/20\n",
      "Epoch  36/150 | Loss: 1.5946 | Train Acc: 23.85% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 18/20\n",
      "Epoch  37/150 | Loss: 1.5945 | Train Acc: 23.82% | Test Acc: 23.97% | Test F1:  8.25% | Patience: 19/20\n",
      "\n",
      "Early stopping triggered for CNNBaseline_Dropout5 after 37 epochs.\n",
      "Final training state for CNNBaseline_Dropout5 saved to /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout5_final.pth\n",
      "\n",
      "Training completed for CNNBaseline_Dropout5 after 37 epochs.\n",
      "Best test accuracy achieved during training: 24.132%\n",
      "\n",
      "Loading best saved model for CNNBaseline_Dropout5 from /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout5_best.pth for final evaluation...\n",
      "\n",
      "Classification Report for CNNBaseline_Dropout5 (using best saved model):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       138\n",
      "           1      0.000     0.000     0.000       118\n",
      "           2      0.429     0.025     0.047       120\n",
      "           3      0.238     0.993     0.384       150\n",
      "           4      0.000     0.000     0.000       108\n",
      "\n",
      "    accuracy                          0.240       634\n",
      "   macro avg      0.133     0.204     0.086       634\n",
      "weighted avg      0.137     0.240     0.100       634\n",
      "\n",
      "\n",
      "Gender breakdown for CNNBaseline_Dropout5 (using best saved model):\n",
      "  Male: Accuracy: 24.84%, Precision: 4.98%, Recall: 19.75%, F1: 7.96%\n",
      "  Female: Accuracy: 22.19%, Precision: 4.45%, Recall: 20.00%, F1: 7.28%\n",
      "\n",
      "--- Summary for CNNBaseline_Dropout5 ---\n",
      "- Total epochs trained: 37\n",
      "- Best validation accuracy during training: 24.132%\n",
      "- Training accuracy of loaded (best saved) model: 23.82%\n",
      "- Best model saved to: /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout5_best.pth\n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "=== Training model: CNNBaseline_Dropout3_BatchNorm (Early Stopping, Augmented Data) ===\n",
      "Epoch   1/150 | Loss: 1.6203 | Train Acc: 19.91% | Test Acc: 18.93% | Test F1:  8.04% | Patience: 0/20\n",
      "    → New best test accuracy: 18.927% (saved to /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout3_BatchNorm_best.pth)\n",
      "Epoch   2/150 | Loss: 1.5897 | Train Acc: 17.42% | Test Acc: 19.09% | Test F1:  9.74% | Patience: 0/20\n",
      "Epoch   3/150 | Loss: 1.5804 | Train Acc: 17.58% | Test Acc: 18.30% | Test F1:  8.75% | Patience: 1/20\n",
      "Epoch   4/150 | Loss: 1.5741 | Train Acc: 23.66% | Test Acc: 23.50% | Test F1: 10.04% | Patience: 2/20\n",
      "    → New best test accuracy: 23.502% (saved to /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout3_BatchNorm_best.pth)\n",
      "Epoch   5/150 | Loss: 1.5728 | Train Acc: 21.41% | Test Acc: 20.98% | Test F1: 14.19% | Patience: 0/20\n",
      "Epoch   6/150 | Loss: 1.5763 | Train Acc: 23.82% | Test Acc: 21.92% | Test F1:  9.82% | Patience: 1/20\n",
      "Epoch   7/150 | Loss: 1.5630 | Train Acc: 15.05% | Test Acc: 17.03% | Test F1:  6.63% | Patience: 2/20\n",
      "Epoch   8/150 | Loss: 1.5628 | Train Acc: 23.18% | Test Acc: 23.97% | Test F1:  9.71% | Patience: 3/20\n",
      "Epoch   9/150 | Loss: 1.5652 | Train Acc: 23.82% | Test Acc: 23.82% | Test F1:  8.03% | Patience: 4/20\n",
      "Epoch  10/150 | Loss: 1.5616 | Train Acc: 23.14% | Test Acc: 22.87% | Test F1:  8.39% | Patience: 5/20\n",
      "Epoch  11/150 | Loss: 1.5616 | Train Acc: 23.34% | Test Acc: 23.97% | Test F1:  8.82% | Patience: 6/20\n",
      "Epoch  12/150 | Loss: 1.5666 | Train Acc: 23.66% | Test Acc: 23.34% | Test F1:  8.52% | Patience: 7/20\n",
      "Epoch  13/150 | Loss: 1.5553 | Train Acc: 23.10% | Test Acc: 23.97% | Test F1:  9.27% | Patience: 8/20\n",
      "Epoch  14/150 | Loss: 1.5558 | Train Acc: 23.74% | Test Acc: 23.50% | Test F1:  8.18% | Patience: 9/20\n",
      "Epoch  15/150 | Loss: 1.5623 | Train Acc: 23.85% | Test Acc: 23.03% | Test F1:  7.63% | Patience: 10/20\n",
      "Epoch  16/150 | Loss: 1.5592 | Train Acc: 23.03% | Test Acc: 23.34% | Test F1:  9.50% | Patience: 11/20\n",
      "Epoch  17/150 | Loss: 1.5520 | Train Acc: 23.42% | Test Acc: 23.82% | Test F1:  9.31% | Patience: 12/20\n",
      "Epoch  18/150 | Loss: 1.5524 | Train Acc: 23.58% | Test Acc: 23.50% | Test F1:  8.01% | Patience: 13/20\n",
      "Epoch  19/150 | Loss: 1.5507 | Train Acc: 23.74% | Test Acc: 23.34% | Test F1:  8.11% | Patience: 14/20\n",
      "Epoch  20/150 | Loss: 1.5465 | Train Acc: 23.62% | Test Acc: 23.66% | Test F1:  8.05% | Patience: 15/20\n",
      "Epoch  21/150 | Loss: 1.5526 | Train Acc: 23.82% | Test Acc: 24.13% | Test F1:  8.56% | Patience: 16/20\n",
      "    → New best test accuracy: 24.132% (saved to /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout3_BatchNorm_best.pth)\n",
      "Epoch  22/150 | Loss: 1.5536 | Train Acc: 23.78% | Test Acc: 23.66% | Test F1:  7.65% | Patience: 0/20\n",
      "Epoch  23/150 | Loss: 1.5511 | Train Acc: 23.89% | Test Acc: 23.34% | Test F1:  9.40% | Patience: 1/20\n",
      "Epoch  24/150 | Loss: 1.5454 | Train Acc: 23.38% | Test Acc: 23.19% | Test F1:  7.88% | Patience: 2/20\n",
      "Epoch  25/150 | Loss: 1.5477 | Train Acc: 23.70% | Test Acc: 22.71% | Test F1:  9.70% | Patience: 3/20\n",
      "Epoch  26/150 | Loss: 1.5532 | Train Acc: 23.74% | Test Acc: 23.97% | Test F1:  9.35% | Patience: 4/20\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# --- Assumptions: all helper classes/functions are defined as in previous cells ---\n",
    "# - AccentSpectrogramDatasetAug\n",
    "# - pad_collate\n",
    "# - models_dict\n",
    "# - evaluate, evaluate_by_gender, classification_report_for_model\n",
    "\n",
    "# 1. Prepare dataset & split (using Augmented Data)\n",
    "dataset = AccentRawWaveformDatasetAug(\n",
    "    '/Users/larsheijnen/DL/Train',\n",
    "    target_sr=16000,\n",
    "    standardize=True\n",
    ")\n",
    "\n",
    "train_len = int(0.8 * len(dataset))\n",
    "test_len  = len(dataset) - train_len\n",
    "train_ds, test_ds = random_split(dataset, [train_len, test_len], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, collate_fn=pad_1d_collate, pin_memory=False)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=4, shuffle=False, collate_fn=pad_1d_collate, pin_memory=False)\n",
    "\n",
    "device    = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Early stopping parameters for Approach A (early stopping on augmented data)\n",
    "patience = 20\n",
    "max_epochs = 150\n",
    "min_improvement = 0.005\n",
    "\n",
    "save_dir_base = \"/Users/larsheijnen/DL/saved_models/A/augmented_earlystop\"\n",
    "os.makedirs(save_dir_base, exist_ok=True)\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Number of training samples: {len(train_ds)}\")\n",
    "print(f\"Number of test samples: {len(test_ds)}\")\n",
    "\n",
    "for model_name, model_class in models_dict.items():\n",
    "    print(f\"\\n=== Training model: {model_class.__name__} (Early Stopping, Augmented Data) ===\")\n",
    "    model = model_class().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "    best_test_acc = 0.0\n",
    "    patience_counter = 0\n",
    "\n",
    "    best_model_path = os.path.join(save_dir_base, f\"{model_class.__name__}_best.pth\")\n",
    "    final_model_path = os.path.join(save_dir_base, f\"{model_class.__name__}_final.pth\")\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for specs, labels, _ in train_loader:\n",
    "            specs, labels = specs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(specs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        avg_epoch_loss = running_loss / len(train_loader)\n",
    "\n",
    "        train_acc, train_prec, train_recall, train_f1 = evaluate(train_loader, model, device)\n",
    "        test_acc, test_prec, test_recall, test_f1 = evaluate(test_loader, model, device)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch+1:3d}/{max_epochs} | \"\n",
    "            f\"Loss: {avg_epoch_loss:.4f} | \"\n",
    "            f\"Train Acc: {train_acc*100:5.2f}% | \"\n",
    "            f\"Test Acc: {test_acc*100:5.2f}% | \"\n",
    "            f\"Test F1: {test_f1*100:5.2f}% | \"\n",
    "            f\"Patience: {patience_counter}/{patience}\"\n",
    "        )\n",
    "\n",
    "        if test_acc > best_test_acc + min_improvement:\n",
    "            best_test_acc = test_acc\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"    → New best test accuracy: {best_test_acc*100:.3f}% (saved to {best_model_path})\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\nEarly stopping triggered for {model_class.__name__} after {epoch+1} epochs.\")\n",
    "            break\n",
    "\n",
    "    torch.save(model.state_dict(), final_model_path)\n",
    "    print(f\"Final training state for {model_class.__name__} saved to {final_model_path}\")\n",
    "    print(f\"\\nTraining completed for {model_class.__name__} after {epoch+1} epochs.\")\n",
    "    print(f\"Best test accuracy achieved during training: {best_test_acc*100:.3f}%\")\n",
    "\n",
    "    # Load the best model for final evaluation\n",
    "    if os.path.exists(best_model_path):\n",
    "        print(f\"\\nLoading best saved model for {model_class.__name__} from {best_model_path} for final evaluation...\")\n",
    "        model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "        eval_model_description = \"best saved\"\n",
    "    else:\n",
    "        print(f\"\\nNo best model was saved for {model_class.__name__}. Using final model state for evaluation.\")\n",
    "        eval_model_description = \"final\"\n",
    "\n",
    "    print(f\"\\nClassification Report for {model_class.__name__} (using {eval_model_description} model):\")\n",
    "    classification_report_for_model(model, test_loader, device)\n",
    "\n",
    "    print(f\"\\nGender breakdown for {model_class.__name__} (using {eval_model_description} model):\")\n",
    "    gender_results = evaluate_by_gender(test_loader, model, device)\n",
    "    for gender in gender_results:\n",
    "        label = \"Male\" if gender == \"m\" else \"Female\"\n",
    "        metrics = gender_results[gender]\n",
    "        metrics_str = \", \".join([f\"{k.capitalize()}: {v*100:.2f}%\" if isinstance(v, float) else f\"{k.capitalize()}: {v}\" for k, v in metrics.items()])\n",
    "        print(f\"  {label}: {metrics_str}\")\n",
    "\n",
    "    final_train_acc, _, _, _ = evaluate(train_loader, model, device)\n",
    "    print(f\"\\n--- Summary for {model_class.__name__} ---\")\n",
    "    print(f\"- Total epochs trained: {epoch+1}\")\n",
    "    print(f\"- Best validation accuracy during training: {best_test_acc*100:.3f}%\")\n",
    "    print(f\"- Training accuracy of loaded ({eval_model_description}) model: {final_train_acc*100:.2f}%\")\n",
    "    if os.path.exists(best_model_path):\n",
    "        print(f\"- Best model saved to: {best_model_path}\")\n",
    "    else:\n",
    "        print(f\"- Best model not saved (or final model is the best achieved). Final model at: {final_model_path}\")\n",
    "    print(f\"---------------------------------------\\n\")\n",
    "\n",
    "print(\"\\nAll model configurations have been trained and evaluated.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
