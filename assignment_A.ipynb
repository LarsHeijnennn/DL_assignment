{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data (not augmented)\n",
    "\n",
    "Data augmentation does not happen here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class AccentRawWaveformDataset(Dataset):\n",
    "    def __init__(self, folder_path,\n",
    "                 target_sr: int = 16000,\n",
    "                 standardize: bool = True):\n",
    "        # store file paths only; transform per item\n",
    "        self.file_paths = [\n",
    "            os.path.join(folder_path, f)\n",
    "            for f in os.listdir(folder_path)\n",
    "            if f.endswith('.wav')\n",
    "        ]\n",
    "        self.target_sr = target_sr\n",
    "        self.standardize = standardize\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.file_paths[idx]\n",
    "        waveform, sr = torchaudio.load(path)\n",
    "        if sr != self.target_sr:\n",
    "            waveform = torchaudio.transforms.Resample(sr, self.target_sr)(waveform)\n",
    "        # Convert to mono if not already\n",
    "        if waveform.shape[0] > 1:\n",
    "            waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "        # Standardize (zero mean, unit variance) if requested\n",
    "        if self.standardize:\n",
    "            mean = waveform.mean()\n",
    "            std = waveform.std() if waveform.std() > 0 else 1.0\n",
    "            waveform = (waveform - mean) / std\n",
    "\n",
    "        fname = os.path.basename(path)\n",
    "        accent = int(fname[0]) - 1          # classes 0–4\n",
    "        gender = fname[1]  # 'm' or 'f' \n",
    "        return waveform, accent, gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def pad_1d_collate(batch, target_length=208):\n",
    "    waveforms, accents, genders = zip(*batch)\n",
    "    padded_waveforms = []\n",
    "    for w in waveforms:\n",
    "        pad_amount = target_length - w.shape[-1]\n",
    "        if pad_amount > 0:\n",
    "            # Pad at the end (right side) for 1D waveform\n",
    "            padded = F.pad(w, (0, pad_amount))\n",
    "        else:\n",
    "            padded = w[..., :target_length]\n",
    "        padded_waveforms.append(padded)\n",
    "    return (\n",
    "        torch.stack(padded_waveforms),  # (B, 1, T)\n",
    "        torch.tensor(accents),\n",
    "        list(genders)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in dataset: 3166\n",
      "Sample 0 waveform shape: torch.Size([1, 41400])\n",
      "Sample 0 accent label: 1\n",
      "Sample 0 gender label: m\n"
     ]
    }
   ],
   "source": [
    "# Let's instantiate the dataset and inspect a sample\n",
    "# (Assume the folder path is './data' - change as needed)\n",
    "dataset = AccentRawWaveformDataset(\"/Users/larsheijnen/DL/Train\")\n",
    "\n",
    "print(f\"Number of samples in dataset: {len(dataset)}\")\n",
    "\n",
    "# Get the first sample\n",
    "sample_waveform, sample_accent, sample_gender = dataset[0]\n",
    "\n",
    "print(\"Sample 0 waveform shape:\", sample_waveform.shape)\n",
    "print(\"Sample 0 accent label:\", sample_accent)\n",
    "print(\"Sample 0 gender label:\", sample_gender)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waveforms: torch.Size([4, 1, 208])\n",
      "Accents: tensor([2, 0, 1, 0])\n",
      "Gender: ['m', 'm', 'f', 'f']\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Use batch_size=4 for low RAM, pin_memory is False for macOS/MPS\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=pad_1d_collate, pin_memory=False)\n",
    "\n",
    "# Try again\n",
    "for batch in dataloader:\n",
    "    waveforms, accents, gender = batch\n",
    "    print(f\"Waveforms: {waveforms.shape}\")  # (B, 1, T)\n",
    "    print(f\"Accents: {accents}\")            # (B,)\n",
    "    print(f\"Gender: {gender}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Model 1 (baseline)\n",
    "class CNNBaseline(nn.Module):\n",
    "    def __init__(self, num_classes: int = 5):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 8, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(8, 16, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(16)  # Output: (B, 32, 256)\n",
    "        self.fc = nn.Linear(32 * 16, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, 1, T)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool(x)  # (B, 32, 256)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Model 2 (baseline + batch normalization)\n",
    "class CNNBaseline_BatchNorm(nn.Module):\n",
    "    def __init__(self, num_classes: int = 5):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 8, kernel_size=3, padding=1)\n",
    "        self.bn1   = nn.BatchNorm1d(8)\n",
    "        self.conv2 = nn.Conv1d(8, 16, kernel_size=3, padding=1)\n",
    "        self.bn2   = nn.BatchNorm1d(16)\n",
    "        self.conv3 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn3   = nn.BatchNorm1d(32)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(16)\n",
    "        self.fc = nn.Linear(32 * 16, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Model 3 (baseline + dropout 0.3)\n",
    "class CNNBaseline_Dropout3(nn.Module):\n",
    "    def __init__(self, num_classes: int = 5, dropout_p: float = 0.3):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 8, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(8, 16, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(16)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.fc = nn.Linear(32 * 16, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Model 4 (baseline + dropout 0.5)\n",
    "class CNNBaseline_Dropout5(nn.Module):\n",
    "    def __init__(self, num_classes: int = 5, dropout_p: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 8, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(8, 16, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(16)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.fc = nn.Linear(32 * 16, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Model 5 (baseline + batch normalization + dropout 0.3)\n",
    "class CNNBaseline_Dropout3_BatchNorm(nn.Module):\n",
    "    def __init__(self, num_classes: int = 5, dropout_p: float = 0.3):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 8, kernel_size=3, padding=1)\n",
    "        self.bn1   = nn.BatchNorm1d(8)\n",
    "        self.conv2 = nn.Conv1d(8, 16, kernel_size=3, padding=1)\n",
    "        self.bn2   = nn.BatchNorm1d(16)\n",
    "        self.conv3 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn3   = nn.BatchNorm1d(32)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(16)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.fc = nn.Linear(32 * 16, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Model 6 (baseline + batch normalization + dropout 0.5)\n",
    "class CNNBaseline_Dropout5_BatchNorm(nn.Module):\n",
    "    def __init__(self, num_classes: int = 5, dropout_p: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 8, kernel_size=3, padding=1)\n",
    "        self.bn1   = nn.BatchNorm1d(8)\n",
    "        self.conv2 = nn.Conv1d(8, 16, kernel_size=3, padding=1)\n",
    "        self.bn2   = nn.BatchNorm1d(16)\n",
    "        self.conv3 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn3   = nn.BatchNorm1d(32)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(16)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.fc = nn.Linear(32 * 16, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {\n",
    "    \"Model1\": CNNBaseline,\n",
    "    \"Model2\": CNNBaseline_BatchNorm, \n",
    "    \"Model3\": CNNBaseline_Dropout3,\n",
    "    \"Model4\": CNNBaseline_Dropout5,\n",
    "    \"Model5\": CNNBaseline_Dropout3_BatchNorm,\n",
    "    \"Model6\": CNNBaseline_Dropout5_BatchNorm,}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training models using early stop on non-augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training model: CNNBaseline (Early Stopping) ===\n",
      "Epoch   1/150 | Train Loss: 1012.309 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 0/20\n",
      "    → New best test accuracy: 23.659% (saved to /Users/larsheijnen/DL/saved_models/A/not_augmented_earlystop/CNNBaseline_not_augmented_best_1d_earlystop.pth)\n",
      "Epoch   2/150 | Train Loss: 1011.110 | Train Acc: 23.82% | Train Prec:  4.76% | Train Recall: 19.97% | Train F1:  7.69% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 0/20\n",
      "Epoch   3/150 | Train Loss: 1010.694 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 1/20\n",
      "Epoch   4/150 | Train Loss: 1009.884 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 2/20\n",
      "Epoch   5/150 | Train Loss: 1010.169 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 3/20\n",
      "Epoch   6/150 | Train Loss: 1009.849 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 4/20\n",
      "Epoch   7/150 | Train Loss: 1009.750 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 5/20\n",
      "Epoch   8/150 | Train Loss: 1009.720 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 6/20\n",
      "Epoch   9/150 | Train Loss: 1009.463 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 7/20\n",
      "Epoch  10/150 | Train Loss: 1009.850 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 8/20\n",
      "Epoch  11/150 | Train Loss: 1009.775 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 9/20\n",
      "Epoch  12/150 | Train Loss: 1009.505 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 10/20\n",
      "Epoch  13/150 | Train Loss: 1009.650 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 11/20\n",
      "Epoch  14/150 | Train Loss: 1009.556 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 12/20\n",
      "Epoch  15/150 | Train Loss: 1009.509 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 13/20\n",
      "Epoch  16/150 | Train Loss: 1009.045 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 14/20\n",
      "Epoch  17/150 | Train Loss: 1009.444 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 15/20\n",
      "Epoch  18/150 | Train Loss: 1009.780 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 16/20\n",
      "Epoch  19/150 | Train Loss: 1009.458 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 17/20\n",
      "Epoch  20/150 | Train Loss: 1009.455 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 18/20\n",
      "Epoch  21/150 | Train Loss: 1009.442 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 19/20\n",
      "\n",
      "Early stopping triggered for CNNBaseline after 21 epochs.\n",
      "Final training state for CNNBaseline saved to /Users/larsheijnen/DL/saved_models/A/not_augmented_earlystop/CNNBaseline_not_augmented_latest_1d_earlystop.pth\n",
      "\n",
      "Training completed for CNNBaseline after 21 epochs.\n",
      "Best test accuracy achieved during training: 23.659%\n",
      "\n",
      "Loading best saved model for CNNBaseline from /Users/larsheijnen/DL/saved_models/A/not_augmented_earlystop/CNNBaseline_not_augmented_best_1d_earlystop.pth for final evaluation...\n",
      "\n",
      "Classification Report for CNNBaseline (using best saved model):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       138\n",
      "           1      0.000     0.000     0.000       118\n",
      "           2      0.000     0.000     0.000       120\n",
      "           3      0.237     1.000     0.383       150\n",
      "           4      0.000     0.000     0.000       108\n",
      "\n",
      "    accuracy                          0.237       634\n",
      "   macro avg      0.047     0.200     0.077       634\n",
      "weighted avg      0.056     0.237     0.091       634\n",
      "\n",
      "\n",
      "Gender breakdown for CNNBaseline (using best saved model):\n",
      "Male: {'accuracy': 0.2515923566878981, 'precision': 0.05031847133757962, 'recall': 0.2, 'f1': 0.08040712468193384}\n",
      "Female: {'accuracy': 0.221875, 'precision': 0.044375, 'recall': 0.2, 'f1': 0.07263427109974424}\n",
      "\n",
      "--- Summary for CNNBaseline ---\n",
      "- Total epochs trained: 21\n",
      "- Best validation accuracy during training: 23.659%\n",
      "- Training accuracy of loaded (best saved) model: 23.85%\n",
      "- Best model saved to: /Users/larsheijnen/DL/saved_models/A/not_augmented_earlystop/CNNBaseline_not_augmented_best_1d_earlystop.pth\n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "=== Training model: CNNBaseline_BatchNorm (Early Stopping) ===\n",
      "Epoch   1/150 | Train Loss: 997.851 | Train Acc: 22.43% | Train Prec: 22.88% | Train Recall: 19.92% | Train F1: 11.68% || Test Acc: 24.29% | Test Prec: 16.28% | Test Recall: 21.74% | Test F1: 13.02% | Patience: 0/20\n",
      "    → New best test accuracy: 24.290% (saved to /Users/larsheijnen/DL/saved_models/A/not_augmented_earlystop/CNNBaseline_BatchNorm_not_augmented_best_1d_earlystop.pth)\n",
      "Epoch   2/150 | Train Loss: 975.915 | Train Acc: 27.65% | Train Prec: 21.58% | Train Recall: 23.29% | Train F1: 14.81% || Test Acc: 26.66% | Test Prec: 19.91% | Test Recall: 22.87% | Test F1: 13.98% | Patience: 0/20\n",
      "    → New best test accuracy: 26.656% (saved to /Users/larsheijnen/DL/saved_models/A/not_augmented_earlystop/CNNBaseline_BatchNorm_not_augmented_best_1d_earlystop.pth)\n",
      "Epoch   3/150 | Train Loss: 950.827 | Train Acc: 25.00% | Train Prec: 21.31% | Train Recall: 24.19% | Train F1: 16.42% || Test Acc: 24.45% | Test Prec: 22.51% | Test Recall: 25.33% | Test F1: 17.03% | Patience: 0/20\n",
      "Epoch   4/150 | Train Loss: 951.633 | Train Acc: 24.96% | Train Prec: 25.03% | Train Recall: 20.94% | Train F1: 10.39% || Test Acc: 25.24% | Test Prec: 40.20% | Test Recall: 21.48% | Test F1: 10.73% | Patience: 1/20\n",
      "Epoch   5/150 | Train Loss: 935.260 | Train Acc: 23.97% | Train Prec: 12.29% | Train Recall: 20.33% | Train F1: 10.02% || Test Acc: 23.34% | Test Prec:  7.27% | Test Recall: 19.95% | Test F1:  9.23% | Patience: 2/20\n",
      "Epoch   6/150 | Train Loss: 926.164 | Train Acc: 23.78% | Train Prec: 45.18% | Train Recall: 23.51% | Train F1: 14.28% || Test Acc: 20.82% | Test Prec: 33.23% | Test Recall: 21.97% | Test F1: 12.58% | Patience: 3/20\n",
      "Epoch   7/150 | Train Loss: 912.580 | Train Acc: 21.72% | Train Prec: 18.48% | Train Recall: 19.98% | Train F1: 12.63% || Test Acc: 20.82% | Test Prec: 22.89% | Test Recall: 18.83% | Test F1: 11.76% | Patience: 4/20\n",
      "Epoch   8/150 | Train Loss: 904.626 | Train Acc: 22.08% | Train Prec: 43.29% | Train Recall: 21.60% | Train F1: 10.73% || Test Acc: 19.87% | Test Prec: 37.07% | Test Recall: 21.11% | Test F1:  9.21% | Patience: 5/20\n",
      "Epoch   9/150 | Train Loss: 887.139 | Train Acc: 32.35% | Train Prec: 38.50% | Train Recall: 27.48% | Train F1: 20.01% || Test Acc: 30.76% | Test Prec: 17.92% | Test Recall: 27.69% | Test F1: 19.73% | Patience: 6/20\n",
      "    → New best test accuracy: 30.757% (saved to /Users/larsheijnen/DL/saved_models/A/not_augmented_earlystop/CNNBaseline_BatchNorm_not_augmented_best_1d_earlystop.pth)\n",
      "Epoch  10/150 | Train Loss: 883.243 | Train Acc: 17.06% | Train Prec: 23.71% | Train Recall: 21.64% | Train F1: 11.02% || Test Acc: 19.56% | Test Prec: 35.21% | Test Recall: 22.13% | Test F1: 12.96% | Patience: 0/20\n",
      "Epoch  11/150 | Train Loss: 859.932 | Train Acc: 26.07% | Train Prec: 31.81% | Train Recall: 22.06% | Train F1: 13.21% || Test Acc: 25.39% | Test Prec: 31.38% | Test Recall: 21.78% | Test F1: 12.60% | Patience: 1/20\n",
      "Epoch  12/150 | Train Loss: 863.730 | Train Acc: 21.45% | Train Prec: 36.20% | Train Recall: 21.01% | Train F1: 17.35% || Test Acc: 19.56% | Test Prec: 22.33% | Test Recall: 20.25% | Test F1: 14.91% | Patience: 2/20\n",
      "Epoch  13/150 | Train Loss: 861.728 | Train Acc: 14.85% | Train Prec: 27.96% | Train Recall: 20.07% | Train F1:  5.30% || Test Acc: 17.03% | Test Prec:  3.41% | Test Recall: 20.00% | Test F1:  5.82% | Patience: 3/20\n",
      "Epoch  14/150 | Train Loss: 843.267 | Train Acc: 25.79% | Train Prec: 44.77% | Train Recall: 22.23% | Train F1: 12.31% || Test Acc: 22.56% | Test Prec: 22.83% | Test Recall: 20.88% | Test F1:  9.67% | Patience: 4/20\n",
      "Epoch  15/150 | Train Loss: 839.983 | Train Acc: 30.73% | Train Prec: 29.54% | Train Recall: 30.35% | Train F1: 27.23% || Test Acc: 26.50% | Test Prec: 25.92% | Test Recall: 26.93% | Test F1: 24.27% | Patience: 5/20\n",
      "Epoch  16/150 | Train Loss: 825.995 | Train Acc: 16.47% | Train Prec: 20.59% | Train Recall: 21.29% | Train F1:  9.13% || Test Acc: 18.14% | Test Prec: 33.61% | Test Recall: 20.98% | Test F1:  8.80% | Patience: 6/20\n",
      "Epoch  17/150 | Train Loss: 817.529 | Train Acc: 27.49% | Train Prec: 47.91% | Train Recall: 23.60% | Train F1: 16.56% || Test Acc: 25.71% | Test Prec: 47.65% | Test Recall: 22.42% | Test F1: 15.41% | Patience: 7/20\n",
      "Epoch  18/150 | Train Loss: 812.713 | Train Acc: 19.87% | Train Prec: 34.39% | Train Recall: 20.04% | Train F1:  8.35% || Test Acc: 19.24% | Test Prec:  9.50% | Test Recall: 20.77% | Test F1:  8.21% | Patience: 8/20\n",
      "Epoch  19/150 | Train Loss: 805.357 | Train Acc: 26.54% | Train Prec: 55.50% | Train Recall: 25.19% | Train F1: 15.71% || Test Acc: 22.71% | Test Prec: 14.66% | Test Recall: 23.50% | Test F1: 13.44% | Patience: 9/20\n",
      "Epoch  20/150 | Train Loss: 794.216 | Train Acc: 17.34% | Train Prec: 19.50% | Train Recall: 21.81% | Train F1: 11.07% || Test Acc: 19.24% | Test Prec: 24.46% | Test Recall: 21.87% | Test F1: 12.20% | Patience: 10/20\n",
      "Epoch  21/150 | Train Loss: 798.628 | Train Acc: 20.22% | Train Prec: 43.02% | Train Recall: 20.20% | Train F1:  7.17% || Test Acc: 18.61% | Test Prec:  3.72% | Test Recall: 20.00% | Test F1:  6.28% | Patience: 11/20\n",
      "Epoch  22/150 | Train Loss: 779.311 | Train Acc: 27.37% | Train Prec: 23.33% | Train Recall: 23.51% | Train F1: 18.46% || Test Acc: 25.24% | Test Prec: 21.00% | Test Recall: 22.64% | Test F1: 17.56% | Patience: 12/20\n",
      "Epoch  23/150 | Train Loss: 787.663 | Train Acc: 23.89% | Train Prec: 18.69% | Train Recall: 20.88% | Train F1: 12.68% || Test Acc: 22.87% | Test Prec: 11.68% | Test Recall: 19.85% | Test F1: 11.06% | Patience: 13/20\n",
      "Epoch  24/150 | Train Loss: 771.801 | Train Acc: 22.00% | Train Prec: 27.79% | Train Recall: 26.26% | Train F1: 18.51% || Test Acc: 21.61% | Test Prec: 28.44% | Test Recall: 23.98% | Test F1: 17.56% | Patience: 14/20\n",
      "Epoch  25/150 | Train Loss: 762.079 | Train Acc: 24.76% | Train Prec: 21.24% | Train Recall: 21.25% | Train F1: 12.27% || Test Acc: 23.50% | Test Prec: 11.96% | Test Recall: 20.29% | Test F1: 10.78% | Patience: 15/20\n",
      "Epoch  26/150 | Train Loss: 763.191 | Train Acc: 21.56% | Train Prec: 29.29% | Train Recall: 23.26% | Train F1: 17.04% || Test Acc: 21.14% | Test Prec: 25.75% | Test Recall: 21.82% | Test F1: 15.33% | Patience: 16/20\n",
      "Epoch  27/150 | Train Loss: 757.978 | Train Acc: 25.20% | Train Prec: 28.70% | Train Recall: 25.50% | Train F1: 21.22% || Test Acc: 26.03% | Test Prec: 28.79% | Test Recall: 25.69% | Test F1: 21.88% | Patience: 17/20\n",
      "Epoch  28/150 | Train Loss: 759.984 | Train Acc: 33.21% | Train Prec: 49.24% | Train Recall: 30.72% | Train F1: 21.40% || Test Acc: 27.76% | Test Prec: 33.65% | Test Recall: 27.74% | Test F1: 17.46% | Patience: 18/20\n",
      "Epoch  29/150 | Train Loss: 747.285 | Train Acc: 18.33% | Train Prec: 30.86% | Train Recall: 23.01% | Train F1: 11.76% || Test Acc: 18.93% | Test Prec: 21.65% | Test Recall: 21.65% | Test F1: 10.45% | Patience: 19/20\n",
      "\n",
      "Early stopping triggered for CNNBaseline_BatchNorm after 29 epochs.\n",
      "Final training state for CNNBaseline_BatchNorm saved to /Users/larsheijnen/DL/saved_models/A/not_augmented_earlystop/CNNBaseline_BatchNorm_not_augmented_latest_1d_earlystop.pth\n",
      "\n",
      "Training completed for CNNBaseline_BatchNorm after 29 epochs.\n",
      "Best test accuracy achieved during training: 30.757%\n",
      "\n",
      "Loading best saved model for CNNBaseline_BatchNorm from /Users/larsheijnen/DL/saved_models/A/not_augmented_earlystop/CNNBaseline_BatchNorm_not_augmented_best_1d_earlystop.pth for final evaluation...\n",
      "\n",
      "Classification Report for CNNBaseline_BatchNorm (using best saved model):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.323     0.761     0.454       138\n",
      "           1      0.277     0.110     0.158       118\n",
      "           2      0.000     0.000     0.000       120\n",
      "           3      0.296     0.513     0.376       150\n",
      "           4      0.000     0.000     0.000       108\n",
      "\n",
      "    accuracy                          0.308       634\n",
      "   macro avg      0.179     0.277     0.197       634\n",
      "weighted avg      0.192     0.308     0.217       634\n",
      "\n",
      "\n",
      "Gender breakdown for CNNBaseline_BatchNorm (using best saved model):\n",
      "Male: {'accuracy': 0.24203821656050956, 'precision': 0.14423664306017248, 'recall': 0.2593164383204608, 'f1': 0.16530681542566095}\n",
      "Female: {'accuracy': 0.371875, 'precision': 0.23380694646336558, 'recall': 0.29702058504875406, 'f1': 0.22648083623693385}\n",
      "\n",
      "--- Summary for CNNBaseline_BatchNorm ---\n",
      "- Total epochs trained: 29\n",
      "- Best validation accuracy during training: 30.757%\n",
      "- Training accuracy of loaded (best saved) model: 32.35%\n",
      "- Best model saved to: /Users/larsheijnen/DL/saved_models/A/not_augmented_earlystop/CNNBaseline_BatchNorm_not_augmented_best_1d_earlystop.pth\n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "=== Training model: CNNBaseline_Dropout3 (Early Stopping) ===\n",
      "Epoch   1/150 | Train Loss: 1012.034 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 0/20\n",
      "    → New best test accuracy: 21.767% (saved to /Users/larsheijnen/DL/saved_models/A/not_augmented_earlystop/CNNBaseline_Dropout3_not_augmented_best_1d_earlystop.pth)\n",
      "Epoch   2/150 | Train Loss: 1010.506 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 0/20\n",
      "Epoch   3/150 | Train Loss: 1010.147 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 1/20\n",
      "    → New best test accuracy: 23.659% (saved to /Users/larsheijnen/DL/saved_models/A/not_augmented_earlystop/CNNBaseline_Dropout3_not_augmented_best_1d_earlystop.pth)\n",
      "Epoch   4/150 | Train Loss: 1009.963 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 0/20\n",
      "Epoch   5/150 | Train Loss: 1009.942 | Train Acc: 23.82% | Train Prec:  4.76% | Train Recall: 19.97% | Train F1:  7.69% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 1/20\n",
      "Epoch   6/150 | Train Loss: 1009.782 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 2/20\n",
      "Epoch   7/150 | Train Loss: 1009.806 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 3/20\n",
      "Epoch   8/150 | Train Loss: 1009.722 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 4/20\n",
      "Epoch   9/150 | Train Loss: 1009.566 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 5/20\n",
      "Epoch  10/150 | Train Loss: 1009.450 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 6/20\n",
      "Epoch  11/150 | Train Loss: 1009.557 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 7/20\n",
      "Epoch  12/150 | Train Loss: 1009.692 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 8/20\n",
      "Epoch  13/150 | Train Loss: 1009.419 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 9/20\n",
      "Epoch  14/150 | Train Loss: 1009.261 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 10/20\n",
      "Epoch  15/150 | Train Loss: 1009.266 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 11/20\n",
      "Epoch  16/150 | Train Loss: 1009.441 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 12/20\n",
      "Epoch  17/150 | Train Loss: 1009.303 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 13/20\n",
      "Epoch  18/150 | Train Loss: 1009.323 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 14/20\n",
      "Epoch  19/150 | Train Loss: 1009.245 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 15/20\n",
      "Epoch  20/150 | Train Loss: 1009.544 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 16/20\n",
      "Epoch  21/150 | Train Loss: 1009.125 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 17/20\n",
      "Epoch  22/150 | Train Loss: 1009.391 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 18/20\n",
      "Epoch  23/150 | Train Loss: 1009.413 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 19/20\n",
      "\n",
      "Early stopping triggered for CNNBaseline_Dropout3 after 23 epochs.\n",
      "Final training state for CNNBaseline_Dropout3 saved to /Users/larsheijnen/DL/saved_models/A/not_augmented_earlystop/CNNBaseline_Dropout3_not_augmented_latest_1d_earlystop.pth\n",
      "\n",
      "Training completed for CNNBaseline_Dropout3 after 23 epochs.\n",
      "Best test accuracy achieved during training: 23.659%\n",
      "\n",
      "Loading best saved model for CNNBaseline_Dropout3 from /Users/larsheijnen/DL/saved_models/A/not_augmented_earlystop/CNNBaseline_Dropout3_not_augmented_best_1d_earlystop.pth for final evaluation...\n",
      "\n",
      "Classification Report for CNNBaseline_Dropout3 (using best saved model):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       138\n",
      "           1      0.000     0.000     0.000       118\n",
      "           2      0.000     0.000     0.000       120\n",
      "           3      0.237     1.000     0.383       150\n",
      "           4      0.000     0.000     0.000       108\n",
      "\n",
      "    accuracy                          0.237       634\n",
      "   macro avg      0.047     0.200     0.077       634\n",
      "weighted avg      0.056     0.237     0.091       634\n",
      "\n",
      "\n",
      "Gender breakdown for CNNBaseline_Dropout3 (using best saved model):\n",
      "Male: {'accuracy': 0.2515923566878981, 'precision': 0.05031847133757962, 'recall': 0.2, 'f1': 0.08040712468193384}\n",
      "Female: {'accuracy': 0.221875, 'precision': 0.044375, 'recall': 0.2, 'f1': 0.07263427109974424}\n",
      "\n",
      "--- Summary for CNNBaseline_Dropout3 ---\n",
      "- Total epochs trained: 23\n",
      "- Best validation accuracy during training: 23.659%\n",
      "- Training accuracy of loaded (best saved) model: 23.85%\n",
      "- Best model saved to: /Users/larsheijnen/DL/saved_models/A/not_augmented_earlystop/CNNBaseline_Dropout3_not_augmented_best_1d_earlystop.pth\n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "=== Training model: CNNBaseline_Dropout5 (Early Stopping) ===\n",
      "Epoch   1/150 | Train Loss: 1012.290 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 0/20\n",
      "    → New best test accuracy: 23.659% (saved to /Users/larsheijnen/DL/saved_models/A/not_augmented_earlystop/CNNBaseline_Dropout5_not_augmented_best_1d_earlystop.pth)\n",
      "Epoch   2/150 | Train Loss: 1010.279 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 0/20\n",
      "Epoch   3/150 | Train Loss: 1010.945 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 1/20\n",
      "Epoch   4/150 | Train Loss: 1010.501 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 2/20\n",
      "Epoch   5/150 | Train Loss: 1010.652 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 3/20\n",
      "Epoch   6/150 | Train Loss: 1010.253 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 4/20\n",
      "Epoch   7/150 | Train Loss: 1009.843 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 5/20\n",
      "Epoch   8/150 | Train Loss: 1009.744 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 6/20\n",
      "Epoch   9/150 | Train Loss: 1009.223 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 7/20\n",
      "Epoch  10/150 | Train Loss: 1009.716 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 8/20\n",
      "Epoch  11/150 | Train Loss: 1009.908 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 9/20\n",
      "Epoch  12/150 | Train Loss: 1009.909 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 10/20\n",
      "Epoch  13/150 | Train Loss: 1009.555 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 11/20\n",
      "Epoch  14/150 | Train Loss: 1009.679 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 12/20\n",
      "Epoch  15/150 | Train Loss: 1009.373 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.71% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 13/20\n",
      "Epoch  16/150 | Train Loss: 1009.539 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 14/20\n",
      "Epoch  17/150 | Train Loss: 1009.323 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 15/20\n",
      "Epoch  18/150 | Train Loss: 1009.296 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 16/20\n",
      "Epoch  19/150 | Train Loss: 1009.316 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 17/20\n",
      "Epoch  20/150 | Train Loss: 1009.433 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 18/20\n",
      "Epoch  21/150 | Train Loss: 1009.209 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 19/20\n",
      "\n",
      "Early stopping triggered for CNNBaseline_Dropout5 after 21 epochs.\n",
      "Final training state for CNNBaseline_Dropout5 saved to /Users/larsheijnen/DL/saved_models/A/not_augmented_earlystop/CNNBaseline_Dropout5_not_augmented_latest_1d_earlystop.pth\n",
      "\n",
      "Training completed for CNNBaseline_Dropout5 after 21 epochs.\n",
      "Best test accuracy achieved during training: 23.659%\n",
      "\n",
      "Loading best saved model for CNNBaseline_Dropout5 from /Users/larsheijnen/DL/saved_models/A/not_augmented_earlystop/CNNBaseline_Dropout5_not_augmented_best_1d_earlystop.pth for final evaluation...\n",
      "\n",
      "Classification Report for CNNBaseline_Dropout5 (using best saved model):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       138\n",
      "           1      0.000     0.000     0.000       118\n",
      "           2      0.000     0.000     0.000       120\n",
      "           3      0.237     1.000     0.383       150\n",
      "           4      0.000     0.000     0.000       108\n",
      "\n",
      "    accuracy                          0.237       634\n",
      "   macro avg      0.047     0.200     0.077       634\n",
      "weighted avg      0.056     0.237     0.091       634\n",
      "\n",
      "\n",
      "Gender breakdown for CNNBaseline_Dropout5 (using best saved model):\n",
      "Male: {'accuracy': 0.2515923566878981, 'precision': 0.05031847133757962, 'recall': 0.2, 'f1': 0.08040712468193384}\n",
      "Female: {'accuracy': 0.221875, 'precision': 0.044375, 'recall': 0.2, 'f1': 0.07263427109974424}\n",
      "\n",
      "--- Summary for CNNBaseline_Dropout5 ---\n",
      "- Total epochs trained: 21\n",
      "- Best validation accuracy during training: 23.659%\n",
      "- Training accuracy of loaded (best saved) model: 23.85%\n",
      "- Best model saved to: /Users/larsheijnen/DL/saved_models/A/not_augmented_earlystop/CNNBaseline_Dropout5_not_augmented_best_1d_earlystop.pth\n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "=== Training model: CNNBaseline_Dropout3_BatchNorm (Early Stopping) ===\n",
      "Epoch   1/150 | Train Loss: 1007.195 | Train Acc: 30.13% | Train Prec: 28.34% | Train Recall: 27.12% | Train F1: 24.85% || Test Acc: 27.44% | Test Prec: 22.37% | Test Recall: 25.19% | Test F1: 21.89% | Patience: 0/20\n",
      "    → New best test accuracy: 27.445% (saved to /Users/larsheijnen/DL/saved_models/A/not_augmented_earlystop/CNNBaseline_Dropout3_BatchNorm_not_augmented_best_1d_earlystop.pth)\n",
      "Epoch   2/150 | Train Loss: 987.217 | Train Acc: 25.71% | Train Prec: 26.77% | Train Recall: 21.59% | Train F1: 11.72% || Test Acc: 25.55% | Test Prec: 17.34% | Test Recall: 21.77% | Test F1: 11.46% | Patience: 0/20\n",
      "Epoch   3/150 | Train Loss: 975.065 | Train Acc: 33.37% | Train Prec: 19.34% | Train Recall: 32.94% | Train F1: 24.34% || Test Acc: 30.91% | Test Prec: 18.26% | Test Recall: 31.56% | Test F1: 23.00% | Patience: 1/20\n",
      "    → New best test accuracy: 30.915% (saved to /Users/larsheijnen/DL/saved_models/A/not_augmented_earlystop/CNNBaseline_Dropout3_BatchNorm_not_augmented_best_1d_earlystop.pth)\n",
      "Epoch   4/150 | Train Loss: 960.817 | Train Acc: 29.98% | Train Prec: 33.30% | Train Recall: 30.88% | Train F1: 22.60% || Test Acc: 29.50% | Test Prec: 22.79% | Test Recall: 30.14% | Test F1: 21.86% | Patience: 0/20\n",
      "Epoch   5/150 | Train Loss: 963.952 | Train Acc: 29.11% | Train Prec: 26.29% | Train Recall: 28.53% | Train F1: 19.63% || Test Acc: 27.76% | Test Prec: 25.60% | Test Recall: 27.85% | Test F1: 19.20% | Patience: 1/20\n",
      "Epoch   6/150 | Train Loss: 954.830 | Train Acc: 24.09% | Train Prec: 15.13% | Train Recall: 20.24% | Train F1:  9.57% || Test Acc: 24.45% | Test Prec: 20.30% | Test Recall: 20.76% | Test F1:  9.54% | Patience: 2/20\n",
      "Epoch   7/150 | Train Loss: 944.933 | Train Acc: 24.29% | Train Prec: 20.09% | Train Recall: 21.37% | Train F1: 13.65% || Test Acc: 21.61% | Test Prec: 23.59% | Test Recall: 18.94% | Test F1: 11.32% | Patience: 3/20\n",
      "Epoch   8/150 | Train Loss: 939.862 | Train Acc: 28.67% | Train Prec: 32.22% | Train Recall: 29.98% | Train F1: 17.34% || Test Acc: 29.34% | Test Prec: 31.99% | Test Recall: 30.36% | Test F1: 17.31% | Patience: 4/20\n",
      "Epoch   9/150 | Train Loss: 931.845 | Train Acc: 23.70% | Train Prec: 20.10% | Train Recall: 20.40% | Train F1: 13.03% || Test Acc: 23.34% | Test Prec: 21.83% | Test Recall: 20.19% | Test F1: 11.89% | Patience: 5/20\n",
      "Epoch  10/150 | Train Loss: 940.564 | Train Acc: 26.90% | Train Prec: 20.83% | Train Recall: 23.02% | Train F1: 16.31% || Test Acc: 23.19% | Test Prec: 22.08% | Test Recall: 20.16% | Test F1: 13.39% | Patience: 6/20\n",
      "Epoch  11/150 | Train Loss: 930.976 | Train Acc: 21.84% | Train Prec: 26.97% | Train Recall: 21.41% | Train F1: 10.47% || Test Acc: 19.87% | Test Prec: 15.97% | Test Recall: 21.09% | Test F1:  9.11% | Patience: 7/20\n",
      "Epoch  12/150 | Train Loss: 931.871 | Train Acc: 24.21% | Train Prec: 33.25% | Train Recall: 20.47% | Train F1:  8.76% || Test Acc: 21.92% | Test Prec: 14.37% | Test Recall: 20.17% | Test F1:  7.50% | Patience: 8/20\n",
      "Epoch  13/150 | Train Loss: 927.273 | Train Acc: 20.34% | Train Prec: 30.69% | Train Recall: 20.24% | Train F1:  7.54% || Test Acc: 18.93% | Test Prec: 23.75% | Test Recall: 20.29% | Test F1:  6.88% | Patience: 9/20\n",
      "Epoch  14/150 | Train Loss: 917.887 | Train Acc: 21.05% | Train Prec: 28.92% | Train Recall: 24.71% | Train F1: 15.41% || Test Acc: 21.14% | Test Prec: 22.83% | Test Recall: 23.70% | Test F1: 14.41% | Patience: 10/20\n",
      "Epoch  15/150 | Train Loss: 922.811 | Train Acc: 29.66% | Train Prec: 31.16% | Train Recall: 32.07% | Train F1: 25.45% || Test Acc: 29.81% | Test Prec: 24.05% | Test Recall: 31.47% | Test F1: 25.09% | Patience: 11/20\n",
      "Epoch  16/150 | Train Loss: 921.922 | Train Acc: 23.93% | Train Prec: 16.30% | Train Recall: 20.12% | Train F1:  8.71% || Test Acc: 23.82% | Test Prec: 18.76% | Test Recall: 20.18% | Test F1:  8.29% | Patience: 12/20\n",
      "Epoch  17/150 | Train Loss: 922.855 | Train Acc: 26.07% | Train Prec: 21.52% | Train Recall: 22.07% | Train F1: 13.06% || Test Acc: 24.45% | Test Prec: 22.32% | Test Recall: 20.96% | Test F1: 11.94% | Patience: 13/20\n",
      "Epoch  18/150 | Train Loss: 919.979 | Train Acc: 26.22% | Train Prec: 27.57% | Train Recall: 25.03% | Train F1: 15.96% || Test Acc: 23.82% | Test Prec: 15.34% | Test Recall: 24.59% | Test F1: 14.33% | Patience: 14/20\n",
      "Epoch  19/150 | Train Loss: 925.760 | Train Acc: 24.41% | Train Prec: 16.08% | Train Recall: 20.60% | Train F1: 10.46% || Test Acc: 24.29% | Test Prec: 19.69% | Test Recall: 20.70% | Test F1: 10.01% | Patience: 15/20\n",
      "Epoch  20/150 | Train Loss: 917.699 | Train Acc: 30.06% | Train Prec: 35.94% | Train Recall: 31.56% | Train F1: 21.96% || Test Acc: 27.76% | Test Prec: 20.10% | Test Recall: 28.71% | Test F1: 19.39% | Patience: 16/20\n",
      "Epoch  21/150 | Train Loss: 911.783 | Train Acc: 24.17% | Train Prec: 15.99% | Train Recall: 20.37% | Train F1:  9.69% || Test Acc: 23.82% | Test Prec: 17.05% | Test Recall: 20.22% | Test F1:  8.63% | Patience: 17/20\n",
      "Epoch  22/150 | Train Loss: 914.014 | Train Acc: 23.93% | Train Prec: 21.36% | Train Recall: 20.12% | Train F1:  9.07% || Test Acc: 24.29% | Test Prec: 22.12% | Test Recall: 20.62% | Test F1:  9.16% | Patience: 18/20\n",
      "Epoch  23/150 | Train Loss: 907.031 | Train Acc: 29.98% | Train Prec: 32.35% | Train Recall: 27.74% | Train F1: 23.24% || Test Acc: 28.23% | Test Prec: 25.41% | Test Recall: 27.49% | Test F1: 22.45% | Patience: 19/20\n",
      "\n",
      "Early stopping triggered for CNNBaseline_Dropout3_BatchNorm after 23 epochs.\n",
      "Final training state for CNNBaseline_Dropout3_BatchNorm saved to /Users/larsheijnen/DL/saved_models/A/not_augmented_earlystop/CNNBaseline_Dropout3_BatchNorm_not_augmented_latest_1d_earlystop.pth\n",
      "\n",
      "Training completed for CNNBaseline_Dropout3_BatchNorm after 23 epochs.\n",
      "Best test accuracy achieved during training: 30.915%\n",
      "\n",
      "Loading best saved model for CNNBaseline_Dropout3_BatchNorm from /Users/larsheijnen/DL/saved_models/A/not_augmented_earlystop/CNNBaseline_Dropout3_BatchNorm_not_augmented_best_1d_earlystop.pth for final evaluation...\n",
      "\n",
      "Classification Report for CNNBaseline_Dropout3_BatchNorm (using best saved model):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.350     0.703     0.467       138\n",
      "           1      0.256     0.449     0.326       118\n",
      "           2      0.000     0.000     0.000       120\n",
      "           3      0.000     0.000     0.000       150\n",
      "           4      0.307     0.426     0.357       108\n",
      "\n",
      "    accuracy                          0.309       634\n",
      "   macro avg      0.183     0.316     0.230       634\n",
      "weighted avg      0.176     0.309     0.223       634\n",
      "\n",
      "\n",
      "Gender breakdown for CNNBaseline_Dropout3_BatchNorm (using best saved model):\n",
      "Male: {'accuracy': 0.2802547770700637, 'precision': 0.1721453720723934, 'recall': 0.32954636692091527, 'f1': 0.22321701424736737}\n",
      "Female: {'accuracy': 0.3375, 'precision': 0.18835294117647058, 'recall': 0.2949150849150849, 'f1': 0.22868813991989914}\n",
      "\n",
      "--- Summary for CNNBaseline_Dropout3_BatchNorm ---\n",
      "- Total epochs trained: 23\n",
      "- Best validation accuracy during training: 30.915%\n",
      "- Training accuracy of loaded (best saved) model: 33.37%\n",
      "- Best model saved to: /Users/larsheijnen/DL/saved_models/A/not_augmented_earlystop/CNNBaseline_Dropout3_BatchNorm_not_augmented_best_1d_earlystop.pth\n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "=== Training model: CNNBaseline_Dropout5_BatchNorm (Early Stopping) ===\n",
      "Epoch   1/150 | Train Loss: 1007.046 | Train Acc: 22.67% | Train Prec: 22.41% | Train Recall: 22.04% | Train F1: 12.01% || Test Acc: 20.82% | Test Prec: 24.38% | Test Recall: 21.79% | Test F1: 11.50% | Patience: 0/20\n",
      "    → New best test accuracy: 20.820% (saved to /Users/larsheijnen/DL/saved_models/A/not_augmented_earlystop/CNNBaseline_Dropout5_BatchNorm_not_augmented_best_1d_earlystop.pth)\n",
      "Epoch   2/150 | Train Loss: 989.227 | Train Acc: 22.27% | Train Prec: 19.08% | Train Recall: 21.57% | Train F1: 12.26% || Test Acc: 20.35% | Test Prec: 22.32% | Test Recall: 21.16% | Test F1: 11.72% | Patience: 0/20\n",
      "Epoch   3/150 | Train Loss: 979.508 | Train Acc: 29.19% | Train Prec: 33.12% | Train Recall: 30.99% | Train F1: 26.47% || Test Acc: 27.92% | Test Prec: 26.99% | Test Recall: 28.90% | Test F1: 24.31% | Patience: 1/20\n",
      "    → New best test accuracy: 27.918% (saved to /Users/larsheijnen/DL/saved_models/A/not_augmented_earlystop/CNNBaseline_Dropout5_BatchNorm_not_augmented_best_1d_earlystop.pth)\n",
      "Epoch   4/150 | Train Loss: 965.090 | Train Acc: 20.22% | Train Prec: 15.85% | Train Recall: 20.08% | Train F1:  7.95% || Test Acc: 18.30% | Test Prec: 25.51% | Test Recall: 19.60% | Test F1:  6.74% | Patience: 0/20\n",
      "Epoch   5/150 | Train Loss: 972.795 | Train Acc: 27.05% | Train Prec: 29.92% | Train Recall: 26.23% | Train F1: 22.81% || Test Acc: 22.40% | Test Prec: 28.21% | Test Recall: 22.59% | Test F1: 19.58% | Patience: 1/20\n",
      "Epoch   6/150 | Train Loss: 963.042 | Train Acc: 20.97% | Train Prec: 15.00% | Train Recall: 20.48% | Train F1: 10.22% || Test Acc: 19.40% | Test Prec: 28.35% | Test Recall: 20.17% | Test F1:  9.67% | Patience: 2/20\n",
      "Epoch   7/150 | Train Loss: 957.094 | Train Acc: 22.00% | Train Prec: 24.09% | Train Recall: 22.10% | Train F1: 14.24% || Test Acc: 20.03% | Test Prec: 27.61% | Test Recall: 21.35% | Test F1: 13.48% | Patience: 3/20\n",
      "Epoch   8/150 | Train Loss: 962.644 | Train Acc: 23.78% | Train Prec: 12.63% | Train Recall: 19.95% | Train F1:  8.15% || Test Acc: 23.82% | Test Prec: 11.42% | Test Recall: 20.17% | Test F1:  8.01% | Patience: 4/20\n",
      "Epoch   9/150 | Train Loss: 951.485 | Train Acc: 26.42% | Train Prec: 28.30% | Train Recall: 22.33% | Train F1: 13.96% || Test Acc: 24.76% | Test Prec: 19.15% | Test Recall: 21.24% | Test F1: 12.85% | Patience: 5/20\n",
      "Epoch  10/150 | Train Loss: 948.646 | Train Acc: 26.66% | Train Prec: 30.38% | Train Recall: 25.01% | Train F1: 18.67% || Test Acc: 23.03% | Test Prec: 20.20% | Test Recall: 23.03% | Test F1: 16.35% | Patience: 6/20\n",
      "Epoch  11/150 | Train Loss: 949.659 | Train Acc: 23.18% | Train Prec: 15.25% | Train Recall: 19.80% | Train F1: 11.36% || Test Acc: 23.03% | Test Prec: 20.96% | Test Recall: 20.01% | Test F1: 11.56% | Patience: 7/20\n",
      "Epoch  12/150 | Train Loss: 945.661 | Train Acc: 32.46% | Train Prec: 32.90% | Train Recall: 30.04% | Train F1: 25.59% || Test Acc: 30.44% | Test Prec: 44.32% | Test Recall: 29.91% | Test F1: 25.15% | Patience: 8/20\n",
      "    → New best test accuracy: 30.442% (saved to /Users/larsheijnen/DL/saved_models/A/not_augmented_earlystop/CNNBaseline_Dropout5_BatchNorm_not_augmented_best_1d_earlystop.pth)\n",
      "Epoch  13/150 | Train Loss: 942.348 | Train Acc: 28.40% | Train Prec: 32.39% | Train Recall: 25.00% | Train F1: 17.70% || Test Acc: 25.55% | Test Prec: 18.88% | Test Recall: 24.12% | Test F1: 15.17% | Patience: 0/20\n",
      "Epoch  14/150 | Train Loss: 940.185 | Train Acc: 23.85% | Train Prec: 18.90% | Train Recall: 20.11% | Train F1:  8.96% || Test Acc: 23.50% | Test Prec:  6.20% | Test Recall: 19.90% | Test F1:  7.99% | Patience: 1/20\n",
      "Epoch  15/150 | Train Loss: 937.249 | Train Acc: 24.21% | Train Prec: 18.24% | Train Recall: 20.35% | Train F1:  9.50% || Test Acc: 24.92% | Test Prec: 26.03% | Test Recall: 21.20% | Test F1: 10.23% | Patience: 2/20\n",
      "Epoch  16/150 | Train Loss: 940.422 | Train Acc: 25.28% | Train Prec: 29.94% | Train Recall: 21.48% | Train F1: 12.67% || Test Acc: 23.97% | Test Prec: 20.16% | Test Recall: 20.45% | Test F1: 10.77% | Patience: 3/20\n",
      "Epoch  17/150 | Train Loss: 935.861 | Train Acc: 30.92% | Train Prec: 32.23% | Train Recall: 32.21% | Train F1: 28.57% || Test Acc: 30.28% | Test Prec: 33.04% | Test Recall: 31.20% | Test F1: 28.69% | Patience: 4/20\n",
      "Epoch  18/150 | Train Loss: 939.809 | Train Acc: 31.28% | Train Prec: 32.72% | Train Recall: 29.69% | Train F1: 25.27% || Test Acc: 29.34% | Test Prec: 22.83% | Test Recall: 28.16% | Test F1: 24.36% | Patience: 5/20\n",
      "Epoch  19/150 | Train Loss: 936.402 | Train Acc: 19.39% | Train Prec: 16.34% | Train Recall: 17.84% | Train F1: 13.13% || Test Acc: 17.82% | Test Prec: 24.38% | Test Recall: 17.00% | Test F1: 12.44% | Patience: 6/20\n",
      "Epoch  20/150 | Train Loss: 935.858 | Train Acc: 25.75% | Train Prec: 19.35% | Train Recall: 22.95% | Train F1: 14.57% || Test Acc: 24.45% | Test Prec: 13.39% | Test Recall: 23.19% | Test F1: 13.36% | Patience: 7/20\n",
      "Epoch  21/150 | Train Loss: 931.692 | Train Acc: 20.22% | Train Prec: 23.47% | Train Recall: 19.78% | Train F1: 14.96% || Test Acc: 20.35% | Test Prec: 21.69% | Test Recall: 20.40% | Test F1: 13.98% | Patience: 8/20\n",
      "Epoch  22/150 | Train Loss: 934.545 | Train Acc: 23.54% | Train Prec: 16.52% | Train Recall: 20.11% | Train F1: 10.65% || Test Acc: 23.66% | Test Prec: 27.75% | Test Recall: 20.24% | Test F1:  9.92% | Patience: 9/20\n",
      "Epoch  23/150 | Train Loss: 926.707 | Train Acc: 19.47% | Train Prec: 15.85% | Train Recall: 19.76% | Train F1:  8.93% || Test Acc: 17.35% | Test Prec: 25.05% | Test Recall: 18.70% | Test F1:  7.56% | Patience: 10/20\n",
      "Epoch  24/150 | Train Loss: 927.158 | Train Acc: 16.55% | Train Prec: 24.26% | Train Recall: 21.49% | Train F1:  8.71% || Test Acc: 17.67% | Test Prec: 17.86% | Test Recall: 20.47% | Test F1:  8.16% | Patience: 11/20\n",
      "Epoch  25/150 | Train Loss: 929.517 | Train Acc: 24.49% | Train Prec: 28.75% | Train Recall: 21.42% | Train F1: 15.16% || Test Acc: 23.66% | Test Prec: 26.42% | Test Recall: 22.34% | Test F1: 14.53% | Patience: 12/20\n",
      "Epoch  26/150 | Train Loss: 924.052 | Train Acc: 27.53% | Train Prec: 25.58% | Train Recall: 27.59% | Train F1: 19.54% || Test Acc: 26.81% | Test Prec: 25.20% | Test Recall: 25.65% | Test F1: 18.23% | Patience: 13/20\n",
      "Epoch  27/150 | Train Loss: 930.846 | Train Acc: 16.75% | Train Prec: 23.37% | Train Recall: 21.69% | Train F1:  9.01% || Test Acc: 17.35% | Test Prec: 17.64% | Test Recall: 20.16% | Test F1:  8.16% | Patience: 14/20\n",
      "Epoch  28/150 | Train Loss: 931.809 | Train Acc: 26.74% | Train Prec: 31.00% | Train Recall: 29.04% | Train F1: 19.77% || Test Acc: 23.97% | Test Prec: 25.48% | Test Recall: 25.40% | Test F1: 17.21% | Patience: 15/20\n",
      "Epoch  29/150 | Train Loss: 926.539 | Train Acc: 30.13% | Train Prec: 34.18% | Train Recall: 30.49% | Train F1: 25.65% || Test Acc: 29.18% | Test Prec: 28.95% | Test Recall: 28.63% | Test F1: 24.30% | Patience: 16/20\n",
      "Epoch  30/150 | Train Loss: 927.228 | Train Acc: 14.93% | Train Prec: 23.63% | Train Recall: 20.10% | Train F1:  5.58% || Test Acc: 17.03% | Test Prec:  3.41% | Test Recall: 20.00% | Test F1:  5.82% | Patience: 17/20\n",
      "Epoch  31/150 | Train Loss: 920.792 | Train Acc: 25.36% | Train Prec: 28.45% | Train Recall: 21.55% | Train F1: 12.75% || Test Acc: 24.61% | Test Prec: 20.36% | Test Recall: 20.96% | Test F1: 10.91% | Patience: 18/20\n",
      "Epoch  32/150 | Train Loss: 926.841 | Train Acc: 26.46% | Train Prec: 28.86% | Train Recall: 28.17% | Train F1: 23.15% || Test Acc: 24.76% | Test Prec: 34.76% | Test Recall: 25.95% | Test F1: 21.81% | Patience: 19/20\n",
      "\n",
      "Early stopping triggered for CNNBaseline_Dropout5_BatchNorm after 32 epochs.\n",
      "Final training state for CNNBaseline_Dropout5_BatchNorm saved to /Users/larsheijnen/DL/saved_models/A/not_augmented_earlystop/CNNBaseline_Dropout5_BatchNorm_not_augmented_latest_1d_earlystop.pth\n",
      "\n",
      "Training completed for CNNBaseline_Dropout5_BatchNorm after 32 epochs.\n",
      "Best test accuracy achieved during training: 30.442%\n",
      "\n",
      "Loading best saved model for CNNBaseline_Dropout5_BatchNorm from /Users/larsheijnen/DL/saved_models/A/not_augmented_earlystop/CNNBaseline_Dropout5_BatchNorm_not_augmented_best_1d_earlystop.pth for final evaluation...\n",
      "\n",
      "Classification Report for CNNBaseline_Dropout5_BatchNorm (using best saved model):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.461     0.638     0.535       138\n",
      "           1      0.220     0.559     0.316       118\n",
      "           2      1.000     0.025     0.049       120\n",
      "           3      0.240     0.153     0.187       150\n",
      "           4      0.295     0.120     0.171       108\n",
      "\n",
      "    accuracy                          0.304       634\n",
      "   macro avg      0.443     0.299     0.252       634\n",
      "weighted avg      0.438     0.304     0.258       634\n",
      "\n",
      "\n",
      "Gender breakdown for CNNBaseline_Dropout5_BatchNorm (using best saved model):\n",
      "Male: {'accuracy': 0.2515923566878981, 'precision': 0.397573451701543, 'recall': 0.2765020236844653, 'f1': 0.22476192187974417}\n",
      "Female: {'accuracy': 0.35625, 'precision': 0.2837936507936508, 'recall': 0.3052954791687186, 'f1': 0.25321633992674575}\n",
      "\n",
      "--- Summary for CNNBaseline_Dropout5_BatchNorm ---\n",
      "- Total epochs trained: 32\n",
      "- Best validation accuracy during training: 30.442%\n",
      "- Training accuracy of loaded (best saved) model: 32.46%\n",
      "- Best model saved to: /Users/larsheijnen/DL/saved_models/A/not_augmented_earlystop/CNNBaseline_Dropout5_BatchNorm_not_augmented_best_1d_earlystop.pth\n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "All model configurations have been trained and evaluated.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "import os\n",
    "\n",
    "# Prepare dataset & split\n",
    "dataset = AccentRawWaveformDataset(\n",
    "    '/Users/larsheijnen/DL/Train',\n",
    "    target_sr=16000,\n",
    "    standardize=True\n",
    ")\n",
    "\n",
    "train_len = int(0.8 * len(dataset))\n",
    "test_len  = len(dataset) - train_len\n",
    "train_ds, test_ds = random_split(dataset, [train_len, test_len], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True,  collate_fn=pad_1d_collate)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=4, shuffle=False, collate_fn=pad_1d_collate)\n",
    "\n",
    "device    = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def evaluate(loader, model, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for specs, labels, _ in loader:\n",
    "            specs, labels = specs.to(device), labels.to(device)\n",
    "            outputs = model(specs)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_labels.extend(labels.cpu().tolist())\n",
    "    acc    = accuracy_score(all_labels, all_preds)\n",
    "    prec   = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='macro')\n",
    "    f1     = f1_score(all_labels, all_preds, average='macro')\n",
    "    return acc, prec, recall, f1\n",
    "\n",
    "def evaluate_by_gender(loader, model, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels, all_genders = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for specs, labels, genders in loader:\n",
    "            specs, labels = specs.to(device), labels.to(device)\n",
    "            outputs = model(specs)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_labels.extend(labels.cpu().tolist())\n",
    "            all_genders.extend(genders)\n",
    "    results = {}\n",
    "    for gender in ['m', 'f']:\n",
    "        idxs = [i for i, g in enumerate(all_genders) if g == gender]\n",
    "        gender_preds = [all_preds[i] for i in idxs]\n",
    "        gender_labels = [all_labels[i] for i in idxs]\n",
    "        acc = accuracy_score(gender_labels, gender_preds)\n",
    "        prec = precision_score(gender_labels, gender_preds, average='macro', zero_division=0)\n",
    "        recall = recall_score(gender_labels, gender_preds, average='macro')\n",
    "        f1 = f1_score(gender_labels, gender_preds, average='macro')\n",
    "        results[gender] = {'accuracy': acc, 'precision': prec, 'recall': recall, 'f1': f1}\n",
    "    return results\n",
    "\n",
    "def classification_report_for_model(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for specs, labels, _ in loader:\n",
    "            specs, labels = specs.to(device), labels.to(device)\n",
    "            outputs = model(specs)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_labels.extend(labels.cpu().tolist())\n",
    "    print(classification_report(all_labels, all_preds, digits=3))\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 20\n",
    "max_epochs = 150\n",
    "min_improvement = 0.005\n",
    "\n",
    "save_dir_base = \"/Users/larsheijnen/DL/saved_models/A/not_augmented_earlystop\"\n",
    "os.makedirs(save_dir_base, exist_ok=True)\n",
    "\n",
    "for model_name, model_class in models_dict.items():\n",
    "    model = model_class().to(device)\n",
    "    print(f\"\\n=== Training model: {type(model).__name__} (Early Stopping) ===\")\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "    best_test_acc = 0.0\n",
    "    patience_counter = 0\n",
    "\n",
    "    best_model_path = os.path.join(save_dir_base, f\"{type(model).__name__}_not_augmented_best_1d_earlystop.pth\")\n",
    "    final_model_path = os.path.join(save_dir_base, f\"{type(model).__name__}_not_augmented_latest_1d_earlystop.pth\")\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for specs, labels, genders in train_loader:\n",
    "            specs, labels = specs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(specs), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Compute and print general metrics for this epoch (not by gender)\n",
    "        train_acc, train_prec, train_recall, train_f1 = evaluate(train_loader, model, device)\n",
    "        test_acc, test_prec, test_recall, test_f1 = evaluate(test_loader, model, device)\n",
    "        print(\n",
    "            f\"Epoch {epoch+1:3d}/{max_epochs} | \"\n",
    "            f\"Train Loss: {running_loss:.3f} | \"\n",
    "            f\"Train Acc: {train_acc*100:5.2f}% | \"\n",
    "            f\"Train Prec: {train_prec*100:5.2f}% | \"\n",
    "            f\"Train Recall: {train_recall*100:5.2f}% | \"\n",
    "            f\"Train F1: {train_f1*100:5.2f}% || \"\n",
    "            f\"Test Acc: {test_acc*100:5.2f}% | \"\n",
    "            f\"Test Prec: {test_prec*100:5.2f}% | \"\n",
    "            f\"Test Recall: {test_recall*100:5.2f}% | \"\n",
    "            f\"Test F1: {test_f1*100:5.2f}% | \"\n",
    "            f\"Patience: {patience_counter}/{patience}\"\n",
    "        )\n",
    "\n",
    "        if test_acc > best_test_acc + min_improvement:\n",
    "            best_test_acc = test_acc\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"    → New best test accuracy: {best_test_acc*100:.3f}% (saved to {best_model_path})\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\nEarly stopping triggered for {type(model).__name__} after {epoch+1} epochs.\")\n",
    "            break\n",
    "\n",
    "    torch.save(model.state_dict(), final_model_path)\n",
    "    print(f\"Final training state for {type(model).__name__} saved to {final_model_path}\")\n",
    "    print(f\"\\nTraining completed for {type(model).__name__} after {epoch+1} epochs.\")\n",
    "    print(f\"Best test accuracy achieved during training: {best_test_acc*100:.3f}%\")\n",
    "\n",
    "    # Load the best model for final evaluation\n",
    "    if os.path.exists(best_model_path):\n",
    "        print(f\"\\nLoading best saved model for {type(model).__name__} from {best_model_path} for final evaluation...\")\n",
    "        model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "        eval_model_description = \"best saved\"\n",
    "    else:\n",
    "        print(f\"\\nNo best model was saved for {type(model).__name__}. Using final model state for evaluation.\")\n",
    "        eval_model_description = \"final\"\n",
    "\n",
    "    print(f\"\\nClassification Report for {type(model).__name__} (using {eval_model_description} model):\")\n",
    "    classification_report_for_model(model, test_loader, device)\n",
    "\n",
    "    print(f\"\\nGender breakdown for {type(model).__name__} (using {eval_model_description} model):\")\n",
    "    gender_results = evaluate_by_gender(test_loader, model, device)\n",
    "    for gender in gender_results:\n",
    "        label = \"Male\" if gender == \"m\" else \"Female\"\n",
    "        print(f\"{label}: {gender_results[gender]}\")\n",
    "\n",
    "    final_train_acc, _, _, _ = evaluate(train_loader, model, device)\n",
    "    print(f\"\\n--- Summary for {type(model).__name__} ---\")\n",
    "    print(f\"- Total epochs trained: {epoch+1}\")\n",
    "    print(f\"- Best validation accuracy during training: {best_test_acc*100:.3f}%\")\n",
    "    print(f\"- Training accuracy of loaded ({eval_model_description}) model: {final_train_acc*100:.2f}%\")\n",
    "    if os.path.exists(best_model_path):\n",
    "        print(f\"- Best model saved to: {best_model_path}\")\n",
    "    else:\n",
    "        print(f\"- Best model not saved (or final model is the best achieved). Final model at: {final_model_path}\")\n",
    "    print(f\"---------------------------------------\\n\")\n",
    "\n",
    "print(\"\\nAll model configurations have been trained and evaluated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting acccent on Test data using non-augmented models\n",
    "\n",
    "To hand in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = AccentRawWaveformDataset(\n",
    "    '/Users/larsheijnen/DL/Test set',\n",
    "    target_sr=16000,\n",
    "    standardize=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, collate_fn=pad_1d_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# Dynamically determine the saved models directory relative to this script or notebook\n",
    "base_dir = os.path.dirname(os.path.abspath('assignment_A.ipynb'))  # or __file__ if in .py\n",
    "saved_models_dir = os.path.join(base_dir, \"saved_models\", \"A\", \"not_augmented\")\n",
    "\n",
    "# List all .pth files in the directory\n",
    "model_files = [f for f in os.listdir(saved_models_dir) if f.endswith(\".pth\")]\n",
    "\n",
    "# Map model file names to their classes (assumes naming convention: class name is prefix before first underscore or before '_latest')\n",
    "model_classes = {}\n",
    "for fname in model_files:\n",
    "    if fname.startswith(\"CNNBaseline_Dropout3_BatchNorm\"):\n",
    "        model_classes[fname] = CNNBaseline_Dropout3_BatchNorm\n",
    "    elif fname.startswith(\"CNNBaseline_Dropout5_BatchNorm\"):\n",
    "        model_classes[fname] = CNNBaseline_Dropout5_BatchNorm\n",
    "    elif fname.startswith(\"CNNBaseline_Dropout3\"):\n",
    "        model_classes[fname] = CNNBaseline_Dropout3\n",
    "    elif fname.startswith(\"CNNBaseline_Dropout5\"):\n",
    "        model_classes[fname] = CNNBaseline_Dropout5\n",
    "    elif fname.startswith(\"CNNBaseline_BatchNorm\"):\n",
    "        model_classes[fname] = CNNBaseline_BatchNorm\n",
    "    elif fname.startswith(\"CNNBaseline\"):\n",
    "        model_classes[fname] = CNNBaseline\n",
    "    # Add more elifs if you have more model types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_accent_on_testset(model, test_loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_fnames = []\n",
    "    with torch.no_grad():\n",
    "        for i, (specs, _, _) in enumerate(test_loader):  # gender is ignored\n",
    "            specs = specs.to(device)\n",
    "            outputs = model(specs)\n",
    "            preds = outputs.argmax(dim=1).cpu().tolist()\n",
    "            all_preds.extend(preds)\n",
    "            # Get filenames for this batch\n",
    "            batch_indices = range(i * test_loader.batch_size, i * test_loader.batch_size + len(preds))\n",
    "            fnames = [os.path.basename(test_dataset.file_paths[idx]) for idx in batch_indices]\n",
    "            all_fnames.extend(fnames)\n",
    "    return list(zip(all_fnames, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "for model_file, model_class in model_classes.items():\n",
    "    model = model_class().to(device)\n",
    "    model_path = os.path.join(saved_models_dir, model_file)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "    print(f\"\\nPredictions for model: {model_file}\")\n",
    "    results = predict_accent_on_testset(model, test_loader, device)\n",
    "    for fname, pred in results:\n",
    "        print(f\"File: {fname} | Predicted Accent: {pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check non-augmented models on train data\n",
    "\n",
    "Checking predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_dataset = AccentRawWaveformDataset(\n",
    "    '/Users/larsheijnen/DL/Train',\n",
    "    target_sr=16000,\n",
    "    standardize=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, collate_fn=pad_1d_collate)\n",
    "\n",
    "np.random.seed(42)\n",
    "subset_indices = np.random.choice(len(full_train_dataset), size=100, replace=False)\n",
    "subset_dataset = Subset(full_train_dataset, subset_indices)\n",
    "subset_loader = DataLoader(subset_dataset, batch_size=4, shuffle=False, collate_fn=pad_1d_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_subset(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_fnames = []\n",
    "    with torch.no_grad():\n",
    "        for i, (specs, labels, _) in enumerate(loader):  # ignore gender\n",
    "            specs = specs.to(device)\n",
    "            outputs = model(specs)\n",
    "            preds = outputs.argmax(dim=1).cpu().tolist()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.tolist())\n",
    "            # Get filenames for this batch\n",
    "            batch_indices = range(i * loader.batch_size, i * loader.batch_size + len(preds))\n",
    "            fnames = [os.path.basename(full_train_dataset.file_paths[idx]) for idx in subset_indices[batch_indices.start:batch_indices.stop]]\n",
    "            all_fnames.extend(fnames)\n",
    "    return list(zip(all_fnames, all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_file in model_files:\n",
    "    model_class = model_classes[model_file]\n",
    "    model = model_class().to(device)\n",
    "    model_path = os.path.join(saved_models_dir, model_file)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "    print(f\"\\nEvaluation on subset for model: {model_file}\")\n",
    "    results = evaluate_on_subset(model, subset_loader, device)\n",
    "    correct = 0\n",
    "    for fname, true_label, pred_label in results:\n",
    "        is_correct = true_label == pred_label\n",
    "        correct += is_correct\n",
    "        print(f\"File: {fname} | True Accent: {true_label + 1} | Predicted Accent: {pred_label + 1} | {'✔️' if is_correct else '❌'}\")\n",
    "    print(f\"Accuracy on subset: {correct/len(results)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation\n",
    "\n",
    "Hier voegen we onder andere noise toe, en trainen we de modellen opnieuw. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import os\n",
    "\n",
    "class AccentRawWaveformDatasetAug(AccentRawWaveformDataset):\n",
    "    def __init__(self, *args, noise_level=0.005, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.noise_level = noise_level\n",
    "\n",
    "    def add_noise(self, waveform, noise_level=None):\n",
    "        if noise_level is None:\n",
    "            noise_level = self.noise_level\n",
    "        noise = torch.randn_like(waveform) * noise_level\n",
    "        return waveform + noise\n",
    "\n",
    "    def time_shift(self, waveform, shift_max=0.2):\n",
    "        shift = int(waveform.size(1) * shift_max * (2 * torch.rand(1) - 1))\n",
    "        return torch.roll(waveform, shifts=shift, dims=1)\n",
    "\n",
    "    def random_volume(self, waveform, min_gain=0.8, max_gain=1.2):\n",
    "        gain = torch.empty(1).uniform_(min_gain, max_gain)\n",
    "        return waveform * gain\n",
    "\n",
    "    def augment(self, waveform, sr):\n",
    "        if torch.rand(1).item() < 0.5:\n",
    "            waveform = self.add_noise(waveform)\n",
    "        if torch.rand(1).item() < 0.5:\n",
    "            waveform = self.time_shift(waveform)\n",
    "        if torch.rand(1).item() < 0.5:\n",
    "            waveform = self.random_volume(waveform)\n",
    "        return waveform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        waveform, accent, gender = super().__getitem__(idx)\n",
    "        waveform = self.augment(waveform, self.target_sr)\n",
    "        return waveform, accent, gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def pad_1d_collate(batch, target_length=208):\n",
    "    waveforms, accents, genders = zip(*batch)\n",
    "    padded_waveforms = []\n",
    "    for w in waveforms:\n",
    "        pad_amount = target_length - w.shape[-1]\n",
    "        if pad_amount > 0:\n",
    "            # Pad at the end (right side) for 1D waveform\n",
    "            padded = F.pad(w, (0, pad_amount))\n",
    "        else:\n",
    "            padded = w[..., :target_length]\n",
    "        padded_waveforms.append(padded)\n",
    "    return (\n",
    "        torch.stack(padded_waveforms),  # (B, 1, T)\n",
    "        torch.tensor(accents),\n",
    "        list(genders)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in dataset: 3166\n",
      "Sample 0 waveform shape: torch.Size([1, 41400])\n",
      "Sample 0 accent label: 1\n",
      "Sample 0 gender label: m\n"
     ]
    }
   ],
   "source": [
    "# Let's instantiate the dataset and inspect a sample\n",
    "# (Assume the folder path is './data' - change as needed)\n",
    "dataset = AccentRawWaveformDatasetAug(\"/Users/larsheijnen/DL/Train\")\n",
    "\n",
    "print(f\"Number of samples in dataset: {len(dataset)}\")\n",
    "\n",
    "# Get the first sample\n",
    "sample_waveform, sample_accent, sample_gender = dataset[0]\n",
    "\n",
    "print(\"Sample 0 waveform shape:\", sample_waveform.shape)\n",
    "print(\"Sample 0 accent label:\", sample_accent)\n",
    "print(\"Sample 0 gender label:\", sample_gender)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waveforms: torch.Size([4, 1, 208])\n",
      "Accents: tensor([0, 2, 2, 3])\n",
      "Gender: ['f', 'm', 'm', 'f']\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Use batch_size=4 for low RAM, pin_memory is False for macOS/MPS\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=pad_1d_collate, pin_memory=False)\n",
    "\n",
    "# Try again\n",
    "for batch in dataloader:\n",
    "    waveforms, accents, gender = batch\n",
    "    print(f\"Waveforms: {waveforms.shape}\")  # (B, 1, T)\n",
    "    print(f\"Accents: {accents}\")            # (B,)\n",
    "    print(f\"Gender: {gender}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Model 1 (baseline)\n",
    "class CNNBaseline(nn.Module):\n",
    "    def __init__(self, num_classes: int = 5):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 8, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(8, 16, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(16)  # Output: (B, 32, 256)\n",
    "        self.fc = nn.Linear(32 * 16, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, 1, T)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool(x)  # (B, 32, 256)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Model 2 (baseline + batch normalization)\n",
    "class CNNBaseline_BatchNorm(nn.Module):\n",
    "    def __init__(self, num_classes: int = 5):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 8, kernel_size=3, padding=1)\n",
    "        self.bn1   = nn.BatchNorm1d(8)\n",
    "        self.conv2 = nn.Conv1d(8, 16, kernel_size=3, padding=1)\n",
    "        self.bn2   = nn.BatchNorm1d(16)\n",
    "        self.conv3 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn3   = nn.BatchNorm1d(32)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(16)\n",
    "        self.fc = nn.Linear(32 * 16, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Model 3 (baseline + dropout 0.3)\n",
    "class CNNBaseline_Dropout3(nn.Module):\n",
    "    def __init__(self, num_classes: int = 5, dropout_p: float = 0.3):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 8, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(8, 16, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(16)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.fc = nn.Linear(32 * 16, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Model 4 (baseline + dropout 0.5)\n",
    "class CNNBaseline_Dropout5(nn.Module):\n",
    "    def __init__(self, num_classes: int = 5, dropout_p: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 8, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(8, 16, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(16)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.fc = nn.Linear(32 * 16, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Model 5 (baseline + batch normalization + dropout 0.3)\n",
    "class CNNBaseline_Dropout3_BatchNorm(nn.Module):\n",
    "    def __init__(self, num_classes: int = 5, dropout_p: float = 0.3):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 8, kernel_size=3, padding=1)\n",
    "        self.bn1   = nn.BatchNorm1d(8)\n",
    "        self.conv2 = nn.Conv1d(8, 16, kernel_size=3, padding=1)\n",
    "        self.bn2   = nn.BatchNorm1d(16)\n",
    "        self.conv3 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn3   = nn.BatchNorm1d(32)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(16)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.fc = nn.Linear(32 * 16, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Model 6 (baseline + batch normalization + dropout 0.5)\n",
    "class CNNBaseline_Dropout5_BatchNorm(nn.Module):\n",
    "    def __init__(self, num_classes: int = 5, dropout_p: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 8, kernel_size=3, padding=1)\n",
    "        self.bn1   = nn.BatchNorm1d(8)\n",
    "        self.conv2 = nn.Conv1d(8, 16, kernel_size=3, padding=1)\n",
    "        self.bn2   = nn.BatchNorm1d(16)\n",
    "        self.conv3 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn3   = nn.BatchNorm1d(32)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(16)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.fc = nn.Linear(32 * 16, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {\n",
    "    \"Model1\": CNNBaseline,\n",
    "    \"Model2\": CNNBaseline_BatchNorm, \n",
    "    \"Model3\": CNNBaseline_Dropout3,\n",
    "    \"Model4\": CNNBaseline_Dropout5,\n",
    "    \"Model5\": CNNBaseline_Dropout3_BatchNorm,\n",
    "    \"Model6\": CNNBaseline_Dropout5_BatchNorm,}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models using early stopping on Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training model: CNNBaseline (Early Stopping) ===\n",
      "Epoch   1/150 | Train Loss: 1012.445 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 0/20\n",
      "    → New best test accuracy: 23.659% (saved to /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_augmented_best_1d_earlystop.pth)\n",
      "Epoch   2/150 | Train Loss: 1011.369 | Train Acc: 24.01% | Train Prec: 10.35% | Train Recall: 20.14% | Train F1:  9.82% || Test Acc: 22.24% | Test Prec:  7.20% | Test Recall: 18.86% | Test F1:  8.43% | Patience: 0/20\n",
      "Epoch   3/150 | Train Loss: 1009.933 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 1/20\n",
      "Epoch   4/150 | Train Loss: 1009.755 | Train Acc: 23.97% | Train Prec: 29.47% | Train Recall: 20.17% | Train F1:  9.98% || Test Acc: 22.40% | Test Prec:  9.98% | Test Recall: 20.39% | Test F1: 10.14% | Patience: 2/20\n",
      "Epoch   5/150 | Train Loss: 1010.311 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 3/20\n",
      "Epoch   6/150 | Train Loss: 1009.800 | Train Acc: 24.17% | Train Prec:  9.23% | Train Recall: 20.33% | Train F1:  9.97% || Test Acc: 21.77% | Test Prec:  8.82% | Test Recall: 19.83% | Test F1:  9.74% | Patience: 4/20\n",
      "Epoch   7/150 | Train Loss: 1009.455 | Train Acc: 24.45% | Train Prec: 10.32% | Train Recall: 20.56% | Train F1: 10.32% || Test Acc: 22.87% | Test Prec:  9.75% | Test Recall: 20.83% | Test F1: 10.29% | Patience: 5/20\n",
      "Epoch   8/150 | Train Loss: 1009.508 | Train Acc: 23.74% | Train Prec:  9.20% | Train Recall: 19.96% | Train F1: 10.09% || Test Acc: 22.87% | Test Prec:  9.60% | Test Recall: 20.83% | Test F1: 10.28% | Patience: 6/20\n",
      "Epoch   9/150 | Train Loss: 1009.866 | Train Acc: 23.62% | Train Prec: 18.66% | Train Recall: 19.88% | Train F1:  9.51% || Test Acc: 21.45% | Test Prec:  8.11% | Test Recall: 19.63% | Test F1:  8.52% | Patience: 7/20\n",
      "Epoch  10/150 | Train Loss: 1009.503 | Train Acc: 23.38% | Train Prec:  8.93% | Train Recall: 19.66% | Train F1:  9.44% || Test Acc: 21.14% | Test Prec:  8.65% | Test Recall: 19.28% | Test F1:  9.15% | Patience: 8/20\n",
      "Epoch  11/150 | Train Loss: 1008.985 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 9/20\n",
      "Epoch  12/150 | Train Loss: 1009.740 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 10/20\n",
      "Epoch  13/150 | Train Loss: 1008.901 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 11/20\n",
      "Epoch  14/150 | Train Loss: 1008.962 | Train Acc: 24.05% | Train Prec:  9.41% | Train Recall: 20.23% | Train F1:  9.71% || Test Acc: 23.19% | Test Prec: 10.50% | Test Recall: 21.18% | Test F1:  9.75% | Patience: 12/20\n",
      "Epoch  15/150 | Train Loss: 1009.111 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 13/20\n",
      "Epoch  16/150 | Train Loss: 1009.019 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 14/20\n",
      "Epoch  17/150 | Train Loss: 1009.128 | Train Acc: 23.85% | Train Prec:  9.61% | Train Recall: 20.06% | Train F1:  9.90% || Test Acc: 21.77% | Test Prec:  9.12% | Test Recall: 19.86% | Test F1:  9.38% | Patience: 15/20\n",
      "Epoch  18/150 | Train Loss: 1008.622 | Train Acc: 24.72% | Train Prec: 10.48% | Train Recall: 20.79% | Train F1: 10.42% || Test Acc: 22.40% | Test Prec:  8.89% | Test Recall: 20.45% | Test F1:  9.46% | Patience: 16/20\n",
      "Epoch  19/150 | Train Loss: 1008.459 | Train Acc: 23.85% | Train Prec:  8.77% | Train Recall: 20.01% | Train F1:  7.78% || Test Acc: 23.82% | Test Prec: 14.75% | Test Recall: 20.17% | Test F1:  8.01% | Patience: 17/20\n",
      "Epoch  20/150 | Train Loss: 1009.431 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 18/20\n",
      "Epoch  21/150 | Train Loss: 1009.163 | Train Acc: 23.82% | Train Prec: 15.64% | Train Recall: 20.04% | Train F1:  8.02% || Test Acc: 21.61% | Test Prec:  4.34% | Test Recall: 19.86% | Test F1:  7.12% | Patience: 19/20\n",
      "\n",
      "Early stopping triggered for CNNBaseline after 21 epochs.\n",
      "Final training state for CNNBaseline saved to /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_augmented_latest_1d_earlystop.pth\n",
      "\n",
      "Training completed for CNNBaseline after 21 epochs.\n",
      "Best test accuracy achieved during training: 23.659%\n",
      "\n",
      "Loading best saved model for CNNBaseline from /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_augmented_best_1d_earlystop.pth for final evaluation...\n",
      "\n",
      "Classification Report for CNNBaseline (using best saved model):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       138\n",
      "           1      0.000     0.000     0.000       118\n",
      "           2      0.000     0.000     0.000       120\n",
      "           3      0.237     1.000     0.383       150\n",
      "           4      0.000     0.000     0.000       108\n",
      "\n",
      "    accuracy                          0.237       634\n",
      "   macro avg      0.047     0.200     0.077       634\n",
      "weighted avg      0.056     0.237     0.091       634\n",
      "\n",
      "\n",
      "Gender breakdown for CNNBaseline (using best saved model):\n",
      "Male: {'accuracy': 0.2515923566878981, 'precision': 0.05031847133757962, 'recall': 0.2, 'f1': 0.08040712468193384}\n",
      "Female: {'accuracy': 0.221875, 'precision': 0.044375, 'recall': 0.2, 'f1': 0.07263427109974424}\n",
      "\n",
      "--- Summary for CNNBaseline ---\n",
      "- Total epochs trained: 21\n",
      "- Best validation accuracy during training: 23.659%\n",
      "- Training accuracy of loaded (best saved) model: 23.85%\n",
      "- Best model saved to: /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_augmented_best_1d_earlystop.pth\n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "=== Training model: CNNBaseline_BatchNorm (Early Stopping) ===\n",
      "Epoch   1/150 | Train Loss: 1027.689 | Train Acc: 23.18% | Train Prec: 12.12% | Train Recall: 19.50% | Train F1:  9.70% || Test Acc: 23.66% | Test Prec:  8.73% | Test Recall: 20.13% | Test F1:  9.97% | Patience: 0/20\n",
      "    → New best test accuracy: 23.659% (saved to /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_BatchNorm_augmented_best_1d_earlystop.pth)\n",
      "Epoch   2/150 | Train Loss: 1015.829 | Train Acc: 23.42% | Train Prec:  8.28% | Train Recall: 20.09% | Train F1:  9.90% || Test Acc: 23.03% | Test Prec:  7.83% | Test Recall: 19.70% | Test F1:  9.22% | Patience: 0/20\n",
      "Epoch   3/150 | Train Loss: 1001.132 | Train Acc: 19.31% | Train Prec: 30.37% | Train Recall: 20.00% | Train F1: 12.12% || Test Acc: 21.14% | Test Prec: 11.77% | Test Recall: 20.81% | Test F1: 12.60% | Patience: 1/20\n",
      "Epoch   4/150 | Train Loss: 998.590 | Train Acc: 17.85% | Train Prec: 15.04% | Train Recall: 20.26% | Train F1:  8.32% || Test Acc: 18.30% | Test Prec:  7.77% | Test Recall: 19.29% | Test F1:  7.07% | Patience: 2/20\n",
      "Epoch   5/150 | Train Loss: 992.256 | Train Acc: 19.43% | Train Prec: 18.93% | Train Recall: 19.38% | Train F1:  8.56% || Test Acc: 19.72% | Test Prec: 18.38% | Test Recall: 20.89% | Test F1: 10.09% | Patience: 3/20\n",
      "Epoch   6/150 | Train Loss: 996.349 | Train Acc: 19.91% | Train Prec: 15.32% | Train Recall: 19.86% | Train F1:  8.59% || Test Acc: 19.40% | Test Prec: 15.29% | Test Recall: 20.61% | Test F1:  9.38% | Patience: 4/20\n",
      "Epoch   7/150 | Train Loss: 991.652 | Train Acc: 20.38% | Train Prec: 19.41% | Train Recall: 20.32% | Train F1:  9.96% || Test Acc: 17.98% | Test Prec: 12.61% | Test Recall: 19.24% | Test F1:  8.11% | Patience: 5/20\n",
      "Epoch   8/150 | Train Loss: 994.439 | Train Acc: 20.14% | Train Prec: 15.29% | Train Recall: 20.42% | Train F1: 12.10% || Test Acc: 19.24% | Test Prec: 15.29% | Test Recall: 20.50% | Test F1: 12.19% | Patience: 6/20\n",
      "Epoch   9/150 | Train Loss: 990.665 | Train Acc: 20.14% | Train Prec: 13.93% | Train Recall: 20.01% | Train F1: 10.01% || Test Acc: 18.93% | Test Prec: 12.99% | Test Recall: 20.10% | Test F1:  9.57% | Patience: 7/20\n",
      "Epoch  10/150 | Train Loss: 986.788 | Train Acc: 19.79% | Train Prec: 12.31% | Train Recall: 19.61% | Train F1:  7.71% || Test Acc: 18.14% | Test Prec:  9.44% | Test Recall: 19.42% | Test F1:  6.74% | Patience: 8/20\n",
      "Epoch  11/150 | Train Loss: 983.505 | Train Acc: 20.34% | Train Prec: 21.01% | Train Recall: 20.19% | Train F1: 10.22% || Test Acc: 18.45% | Test Prec: 24.97% | Test Recall: 19.59% | Test F1:  9.30% | Patience: 9/20\n",
      "Epoch  12/150 | Train Loss: 983.187 | Train Acc: 20.26% | Train Prec: 18.92% | Train Recall: 19.98% | Train F1:  9.86% || Test Acc: 19.72% | Test Prec: 16.16% | Test Recall: 20.67% | Test F1:  9.72% | Patience: 10/20\n",
      "Epoch  13/150 | Train Loss: 985.629 | Train Acc: 24.09% | Train Prec: 21.99% | Train Recall: 20.28% | Train F1: 10.55% || Test Acc: 23.50% | Test Prec: 11.41% | Test Recall: 20.02% | Test F1: 10.08% | Patience: 11/20\n",
      "Epoch  14/150 | Train Loss: 983.177 | Train Acc: 20.34% | Train Prec: 23.94% | Train Recall: 20.23% | Train F1:  9.15% || Test Acc: 18.61% | Test Prec: 15.14% | Test Recall: 19.69% | Test F1:  8.59% | Patience: 12/20\n",
      "Epoch  15/150 | Train Loss: 981.264 | Train Acc: 20.70% | Train Prec: 26.39% | Train Recall: 20.35% | Train F1:  9.85% || Test Acc: 18.77% | Test Prec: 20.37% | Test Recall: 19.81% | Test F1:  8.92% | Patience: 13/20\n",
      "Epoch  16/150 | Train Loss: 982.070 | Train Acc: 23.30% | Train Prec: 14.63% | Train Recall: 19.60% | Train F1:  9.94% || Test Acc: 23.34% | Test Prec: 12.97% | Test Recall: 19.89% | Test F1:  9.98% | Patience: 14/20\n",
      "Epoch  17/150 | Train Loss: 985.415 | Train Acc: 23.89% | Train Prec: 37.24% | Train Recall: 20.13% | Train F1: 10.11% || Test Acc: 22.87% | Test Prec:  7.11% | Test Recall: 19.39% | Test F1:  8.66% | Patience: 15/20\n",
      "Epoch  18/150 | Train Loss: 975.302 | Train Acc: 23.62% | Train Prec: 15.72% | Train Recall: 19.95% | Train F1:  9.71% || Test Acc: 24.45% | Test Prec: 24.29% | Test Recall: 21.04% | Test F1: 11.07% | Patience: 16/20\n",
      "    → New best test accuracy: 24.448% (saved to /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_BatchNorm_augmented_best_1d_earlystop.pth)\n",
      "Epoch  19/150 | Train Loss: 983.916 | Train Acc: 23.66% | Train Prec: 16.74% | Train Recall: 20.15% | Train F1:  9.49% || Test Acc: 23.97% | Test Prec: 18.18% | Test Recall: 20.46% | Test F1:  9.35% | Patience: 0/20\n",
      "Epoch  20/150 | Train Loss: 977.855 | Train Acc: 20.54% | Train Prec: 16.30% | Train Recall: 20.08% | Train F1:  9.95% || Test Acc: 18.93% | Test Prec: 13.07% | Test Recall: 19.93% | Test F1:  9.26% | Patience: 1/20\n",
      "Epoch  21/150 | Train Loss: 975.753 | Train Acc: 23.18% | Train Prec: 15.14% | Train Recall: 19.67% | Train F1:  9.04% || Test Acc: 22.71% | Test Prec:  5.92% | Test Recall: 19.24% | Test F1:  7.89% | Patience: 2/20\n",
      "Epoch  22/150 | Train Loss: 982.224 | Train Acc: 20.38% | Train Prec: 11.82% | Train Recall: 18.84% | Train F1: 11.55% || Test Acc: 19.56% | Test Prec: 11.90% | Test Recall: 17.85% | Test F1: 11.36% | Patience: 3/20\n",
      "Epoch  23/150 | Train Loss: 977.225 | Train Acc: 20.93% | Train Prec: 26.47% | Train Recall: 20.73% | Train F1: 11.81% || Test Acc: 19.40% | Test Prec: 26.85% | Test Recall: 20.54% | Test F1: 10.56% | Patience: 4/20\n",
      "Epoch  24/150 | Train Loss: 981.025 | Train Acc: 19.19% | Train Prec: 21.21% | Train Recall: 21.72% | Train F1: 13.64% || Test Acc: 19.72% | Test Prec: 18.18% | Test Recall: 21.86% | Test F1: 13.83% | Patience: 5/20\n",
      "Epoch  25/150 | Train Loss: 979.007 | Train Acc: 20.22% | Train Prec: 15.64% | Train Recall: 19.82% | Train F1:  9.69% || Test Acc: 19.40% | Test Prec: 10.50% | Test Recall: 20.20% | Test F1:  9.69% | Patience: 6/20\n",
      "Epoch  26/150 | Train Loss: 973.082 | Train Acc: 16.07% | Train Prec: 21.42% | Train Recall: 20.45% | Train F1:  9.08% || Test Acc: 17.03% | Test Prec: 23.86% | Test Recall: 19.36% | Test F1:  9.44% | Patience: 7/20\n",
      "Epoch  27/150 | Train Loss: 980.290 | Train Acc: 24.21% | Train Prec: 26.88% | Train Recall: 20.69% | Train F1: 10.50% || Test Acc: 23.66% | Test Prec: 24.26% | Test Recall: 20.36% | Test F1: 10.58% | Patience: 8/20\n",
      "Epoch  28/150 | Train Loss: 970.327 | Train Acc: 15.96% | Train Prec: 15.66% | Train Recall: 20.55% | Train F1:  8.62% || Test Acc: 17.51% | Test Prec: 17.94% | Test Recall: 19.86% | Test F1:  9.90% | Patience: 9/20\n",
      "Epoch  29/150 | Train Loss: 978.431 | Train Acc: 20.06% | Train Prec: 13.47% | Train Recall: 19.81% | Train F1:  8.41% || Test Acc: 18.14% | Test Prec:  7.70% | Test Recall: 19.38% | Test F1:  7.22% | Patience: 10/20\n",
      "Epoch  30/150 | Train Loss: 981.997 | Train Acc: 23.22% | Train Prec: 10.83% | Train Recall: 19.60% | Train F1:  9.16% || Test Acc: 23.82% | Test Prec: 27.58% | Test Recall: 20.44% | Test F1: 10.40% | Patience: 11/20\n",
      "Epoch  31/150 | Train Loss: 970.984 | Train Acc: 20.06% | Train Prec: 21.03% | Train Recall: 20.10% | Train F1: 10.25% || Test Acc: 19.87% | Test Prec: 11.90% | Test Recall: 21.22% | Test F1: 10.74% | Patience: 12/20\n",
      "Epoch  32/150 | Train Loss: 975.695 | Train Acc: 24.72% | Train Prec: 16.49% | Train Recall: 20.82% | Train F1: 12.58% || Test Acc: 23.66% | Test Prec: 13.82% | Test Recall: 20.32% | Test F1: 11.85% | Patience: 13/20\n",
      "Epoch  33/150 | Train Loss: 976.013 | Train Acc: 20.62% | Train Prec:  8.60% | Train Recall: 20.22% | Train F1:  9.22% || Test Acc: 18.45% | Test Prec:  7.30% | Test Recall: 19.51% | Test F1:  7.95% | Patience: 14/20\n",
      "Epoch  34/150 | Train Loss: 975.117 | Train Acc: 20.34% | Train Prec: 12.86% | Train Recall: 19.97% | Train F1:  9.09% || Test Acc: 19.24% | Test Prec: 13.91% | Test Recall: 20.33% | Test F1:  8.52% | Patience: 15/20\n",
      "Epoch  35/150 | Train Loss: 973.535 | Train Acc: 19.79% | Train Prec: 10.60% | Train Recall: 19.47% | Train F1:  8.69% || Test Acc: 18.61% | Test Prec:  8.65% | Test Recall: 19.60% | Test F1:  8.34% | Patience: 16/20\n",
      "Epoch  36/150 | Train Loss: 976.636 | Train Acc: 15.32% | Train Prec: 15.24% | Train Recall: 19.61% | Train F1:  8.63% || Test Acc: 18.14% | Test Prec: 25.09% | Test Recall: 20.79% | Test F1: 10.16% | Patience: 17/20\n",
      "Epoch  37/150 | Train Loss: 974.134 | Train Acc: 19.83% | Train Prec: 11.92% | Train Recall: 19.52% | Train F1:  8.66% || Test Acc: 18.93% | Test Prec: 12.93% | Test Recall: 20.00% | Test F1:  8.53% | Patience: 18/20\n",
      "Epoch  38/150 | Train Loss: 979.409 | Train Acc: 20.22% | Train Prec: 20.29% | Train Recall: 20.01% | Train F1:  9.34% || Test Acc: 18.14% | Test Prec: 28.96% | Test Recall: 19.27% | Test F1:  9.10% | Patience: 19/20\n",
      "\n",
      "Early stopping triggered for CNNBaseline_BatchNorm after 38 epochs.\n",
      "Final training state for CNNBaseline_BatchNorm saved to /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_BatchNorm_augmented_latest_1d_earlystop.pth\n",
      "\n",
      "Training completed for CNNBaseline_BatchNorm after 38 epochs.\n",
      "Best test accuracy achieved during training: 24.448%\n",
      "\n",
      "Loading best saved model for CNNBaseline_BatchNorm from /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_BatchNorm_augmented_best_1d_earlystop.pth for final evaluation...\n",
      "\n",
      "Classification Report for CNNBaseline_BatchNorm (using best saved model):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       138\n",
      "           1      0.214     0.051     0.082       118\n",
      "           2      0.000     0.000     0.000       120\n",
      "           3      0.231     0.913     0.369       150\n",
      "           4      0.286     0.019     0.035       108\n",
      "\n",
      "    accuracy                          0.229       634\n",
      "   macro avg      0.146     0.197     0.097       634\n",
      "weighted avg      0.143     0.229     0.109       634\n",
      "\n",
      "\n",
      "Gender breakdown for CNNBaseline_BatchNorm (using best saved model):\n",
      "Male: {'accuracy': 0.23885350318471338, 'precision': 0.1019298245614035, 'recall': 0.1911153570575591, 'f1': 0.08833622517833044}\n",
      "Female: {'accuracy': 0.225, 'precision': 0.22944307944307943, 'recall': 0.20610030814256164, 'f1': 0.10787703402751989}\n",
      "\n",
      "--- Summary for CNNBaseline_BatchNorm ---\n",
      "- Total epochs trained: 38\n",
      "- Best validation accuracy during training: 24.448%\n",
      "- Training accuracy of loaded (best saved) model: 23.46%\n",
      "- Best model saved to: /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_BatchNorm_augmented_best_1d_earlystop.pth\n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "=== Training model: CNNBaseline_Dropout3 (Early Stopping) ===\n",
      "Epoch   1/150 | Train Loss: 1012.555 | Train Acc: 23.85% | Train Prec:  9.39% | Train Recall: 20.04% | Train F1:  7.96% || Test Acc: 23.50% | Test Prec: 11.36% | Test Recall: 19.90% | Test F1:  7.91% | Patience: 0/20\n",
      "    → New best test accuracy: 23.502% (saved to /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout3_augmented_best_1d_earlystop.pth)\n",
      "Epoch   2/150 | Train Loss: 1011.026 | Train Acc: 23.89% | Train Prec:  9.34% | Train Recall: 20.10% | Train F1:  9.29% || Test Acc: 22.40% | Test Prec: 11.06% | Test Recall: 20.48% | Test F1:  9.18% | Patience: 0/20\n",
      "Epoch   3/150 | Train Loss: 1009.861 | Train Acc: 23.85% | Train Prec: 11.44% | Train Recall: 20.01% | Train F1:  7.79% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 1/20\n",
      "Epoch   4/150 | Train Loss: 1009.825 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.71% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 2/20\n",
      "Epoch   5/150 | Train Loss: 1009.979 | Train Acc: 24.17% | Train Prec:  9.42% | Train Recall: 20.33% | Train F1:  9.67% || Test Acc: 20.50% | Test Prec:  5.37% | Test Recall: 18.82% | Test F1:  7.39% | Patience: 3/20\n",
      "Epoch   6/150 | Train Loss: 1010.016 | Train Acc: 23.85% | Train Prec:  9.79% | Train Recall: 20.06% | Train F1:  9.64% || Test Acc: 21.77% | Test Prec:  8.08% | Test Recall: 19.92% | Test F1:  8.63% | Patience: 4/20\n",
      "Epoch   7/150 | Train Loss: 1009.683 | Train Acc: 23.58% | Train Prec:  8.72% | Train Recall: 19.83% | Train F1:  9.24% || Test Acc: 20.82% | Test Prec:  7.79% | Test Recall: 19.05% | Test F1:  8.30% | Patience: 5/20\n",
      "Epoch   8/150 | Train Loss: 1009.867 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 6/20\n",
      "Epoch   9/150 | Train Loss: 1009.176 | Train Acc: 24.41% | Train Prec: 19.82% | Train Recall: 20.54% | Train F1: 10.24% || Test Acc: 23.34% | Test Prec: 11.51% | Test Recall: 21.29% | Test F1: 10.27% | Patience: 7/20\n",
      "Epoch  10/150 | Train Loss: 1009.112 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 8/20\n",
      "Epoch  11/150 | Train Loss: 1009.499 | Train Acc: 24.53% | Train Prec: 10.40% | Train Recall: 20.63% | Train F1: 10.14% || Test Acc: 21.77% | Test Prec:  8.74% | Test Recall: 19.90% | Test F1:  8.94% | Patience: 9/20\n",
      "Epoch  12/150 | Train Loss: 1008.972 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 10/20\n",
      "Epoch  13/150 | Train Loss: 1009.725 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.71% || Test Acc: 23.82% | Test Prec: 14.75% | Test Recall: 20.14% | Test F1:  7.96% | Patience: 11/20\n",
      "Epoch  14/150 | Train Loss: 1009.239 | Train Acc: 24.45% | Train Prec: 10.26% | Train Recall: 20.56% | Train F1:  9.88% || Test Acc: 21.77% | Test Prec:  9.81% | Test Recall: 19.91% | Test F1:  8.79% | Patience: 12/20\n",
      "Epoch  15/150 | Train Loss: 1009.171 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 13/20\n",
      "Epoch  16/150 | Train Loss: 1009.116 | Train Acc: 24.33% | Train Prec: 10.20% | Train Recall: 20.46% | Train F1: 10.35% || Test Acc: 22.40% | Test Prec:  9.58% | Test Recall: 20.41% | Test F1: 10.00% | Patience: 14/20\n",
      "Epoch  17/150 | Train Loss: 1009.026 | Train Acc: 24.05% | Train Prec: 11.13% | Train Recall: 20.42% | Train F1:  9.31% || Test Acc: 22.87% | Test Prec:  8.13% | Test Recall: 19.43% | Test F1:  8.28% | Patience: 15/20\n",
      "Epoch  18/150 | Train Loss: 1009.671 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 16/20\n",
      "Epoch  19/150 | Train Loss: 1009.010 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 17/20\n",
      "Epoch  20/150 | Train Loss: 1008.652 | Train Acc: 23.34% | Train Prec:  8.24% | Train Recall: 19.63% | Train F1:  8.86% || Test Acc: 22.40% | Test Prec:  9.77% | Test Recall: 20.49% | Test F1:  9.00% | Patience: 18/20\n",
      "Epoch  21/150 | Train Loss: 1008.759 | Train Acc: 23.70% | Train Prec: 28.88% | Train Recall: 19.97% | Train F1:  9.89% || Test Acc: 21.77% | Test Prec:  7.77% | Test Recall: 19.91% | Test F1:  8.80% | Patience: 19/20\n",
      "\n",
      "Early stopping triggered for CNNBaseline_Dropout3 after 21 epochs.\n",
      "Final training state for CNNBaseline_Dropout3 saved to /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout3_augmented_latest_1d_earlystop.pth\n",
      "\n",
      "Training completed for CNNBaseline_Dropout3 after 21 epochs.\n",
      "Best test accuracy achieved during training: 23.502%\n",
      "\n",
      "Loading best saved model for CNNBaseline_Dropout3 from /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout3_augmented_best_1d_earlystop.pth for final evaluation...\n",
      "\n",
      "Classification Report for CNNBaseline_Dropout3 (using best saved model):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       138\n",
      "           1      0.000     0.000     0.000       118\n",
      "           2      0.333     0.008     0.016       120\n",
      "           3      0.236     0.993     0.382       150\n",
      "           4      0.000     0.000     0.000       108\n",
      "\n",
      "    accuracy                          0.237       634\n",
      "   macro avg      0.114     0.200     0.080       634\n",
      "weighted avg      0.119     0.237     0.093       634\n",
      "\n",
      "\n",
      "Gender breakdown for CNNBaseline_Dropout3 (using best saved model):\n",
      "Male: {'accuracy': 0.2515923566878981, 'precision': 0.05031847133757962, 'recall': 0.2, 'f1': 0.08040712468193384}\n",
      "Female: {'accuracy': 0.221875, 'precision': 0.044375, 'recall': 0.2, 'f1': 0.07263427109974424}\n",
      "\n",
      "--- Summary for CNNBaseline_Dropout3 ---\n",
      "- Total epochs trained: 21\n",
      "- Best validation accuracy during training: 23.502%\n",
      "- Training accuracy of loaded (best saved) model: 23.70%\n",
      "- Best model saved to: /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout3_augmented_best_1d_earlystop.pth\n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "=== Training model: CNNBaseline_Dropout5 (Early Stopping) ===\n",
      "Epoch   1/150 | Train Loss: 1012.036 | Train Acc: 23.78% | Train Prec: 14.75% | Train Recall: 20.00% | Train F1:  7.74% || Test Acc: 21.77% | Test Prec:  4.36% | Test Recall: 20.00% | Test F1:  7.16% | Patience: 0/20\n",
      "    → New best test accuracy: 21.767% (saved to /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout5_augmented_best_1d_earlystop.pth)\n",
      "Epoch   2/150 | Train Loss: 1010.998 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 0/20\n",
      "Epoch   3/150 | Train Loss: 1010.130 | Train Acc: 23.38% | Train Prec:  8.22% | Train Recall: 19.61% | Train F1:  9.05% || Test Acc: 22.71% | Test Prec:  7.89% | Test Recall: 19.28% | Test F1:  8.94% | Patience: 1/20\n",
      "    → New best test accuracy: 22.713% (saved to /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout5_augmented_best_1d_earlystop.pth)\n",
      "Epoch   4/150 | Train Loss: 1010.269 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 0/20\n",
      "Epoch   5/150 | Train Loss: 1010.031 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 1/20\n",
      "    → New best test accuracy: 23.659% (saved to /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout5_augmented_best_1d_earlystop.pth)\n",
      "Epoch   6/150 | Train Loss: 1009.649 | Train Acc: 23.89% | Train Prec: 14.77% | Train Recall: 20.03% | Train F1:  7.78% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 0/20\n",
      "Epoch   7/150 | Train Loss: 1010.430 | Train Acc: 23.89% | Train Prec: 13.10% | Train Recall: 20.10% | Train F1:  8.01% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 1/20\n",
      "Epoch   8/150 | Train Loss: 1008.927 | Train Acc: 23.66% | Train Prec: 12.12% | Train Recall: 19.84% | Train F1:  8.01% || Test Acc: 23.34% | Test Prec:  7.40% | Test Recall: 19.76% | Test F1:  8.14% | Patience: 2/20\n",
      "Epoch   9/150 | Train Loss: 1009.413 | Train Acc: 23.89% | Train Prec:  9.40% | Train Recall: 20.10% | Train F1:  8.09% || Test Acc: 22.24% | Test Prec:  8.74% | Test Recall: 20.40% | Test F1:  8.01% | Patience: 3/20\n",
      "Epoch  10/150 | Train Loss: 1009.344 | Train Acc: 24.05% | Train Prec: 18.10% | Train Recall: 20.23% | Train F1:  8.22% || Test Acc: 21.92% | Test Prec:  7.73% | Test Recall: 20.13% | Test F1:  7.46% | Patience: 4/20\n",
      "Epoch  11/150 | Train Loss: 1009.757 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.69% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 5/20\n",
      "Epoch  12/150 | Train Loss: 1009.310 | Train Acc: 23.66% | Train Prec:  7.88% | Train Recall: 19.90% | Train F1:  7.97% || Test Acc: 21.77% | Test Prec:  4.38% | Test Recall: 20.00% | Test F1:  7.19% | Patience: 6/20\n",
      "Epoch  13/150 | Train Loss: 1009.451 | Train Acc: 24.13% | Train Prec: 11.77% | Train Recall: 20.30% | Train F1:  8.64% || Test Acc: 22.56% | Test Prec: 12.77% | Test Recall: 20.67% | Test F1:  8.50% | Patience: 7/20\n",
      "Epoch  14/150 | Train Loss: 1009.592 | Train Acc: 24.01% | Train Prec: 10.03% | Train Recall: 20.20% | Train F1:  8.40% || Test Acc: 21.77% | Test Prec:  5.95% | Test Recall: 19.99% | Test F1:  7.47% | Patience: 8/20\n",
      "Epoch  15/150 | Train Loss: 1009.498 | Train Acc: 24.01% | Train Prec: 10.16% | Train Recall: 20.20% | Train F1:  8.40% || Test Acc: 21.45% | Test Prec:  5.62% | Test Recall: 19.70% | Test F1:  7.38% | Patience: 9/20\n",
      "Epoch  16/150 | Train Loss: 1008.836 | Train Acc: 23.85% | Train Prec:  9.90% | Train Recall: 20.06% | Train F1:  8.72% || Test Acc: 21.77% | Test Prec:  6.07% | Test Recall: 19.98% | Test F1:  7.74% | Patience: 10/20\n",
      "Epoch  17/150 | Train Loss: 1009.468 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 11/20\n",
      "Epoch  18/150 | Train Loss: 1009.124 | Train Acc: 23.85% | Train Prec:  8.29% | Train Recall: 20.07% | Train F1:  8.15% || Test Acc: 22.56% | Test Prec: 14.42% | Test Recall: 20.67% | Test F1:  8.49% | Patience: 12/20\n",
      "Epoch  19/150 | Train Loss: 1009.201 | Train Acc: 23.82% | Train Prec:  4.77% | Train Recall: 19.97% | Train F1:  7.70% || Test Acc: 23.50% | Test Prec:  4.71% | Test Recall: 19.87% | Test F1:  7.61% | Patience: 13/20\n",
      "Epoch  20/150 | Train Loss: 1008.568 | Train Acc: 23.70% | Train Prec:  6.51% | Train Recall: 19.87% | Train F1:  7.81% || Test Acc: 23.66% | Test Prec:  4.78% | Test Recall: 20.00% | Test F1:  7.72% | Patience: 14/20\n",
      "Epoch  21/150 | Train Loss: 1009.025 | Train Acc: 23.78% | Train Prec:  4.76% | Train Recall: 20.00% | Train F1:  7.68% || Test Acc: 21.77% | Test Prec:  4.35% | Test Recall: 20.00% | Test F1:  7.15% | Patience: 15/20\n",
      "Epoch  22/150 | Train Loss: 1009.200 | Train Acc: 23.58% | Train Prec:  7.89% | Train Recall: 19.83% | Train F1:  7.82% || Test Acc: 21.92% | Test Prec:  9.38% | Test Recall: 20.13% | Test F1:  7.45% | Patience: 16/20\n",
      "Epoch  23/150 | Train Loss: 1008.970 | Train Acc: 23.82% | Train Prec:  9.05% | Train Recall: 20.03% | Train F1: 10.17% || Test Acc: 23.66% | Test Prec: 10.53% | Test Recall: 21.47% | Test F1: 11.36% | Patience: 17/20\n",
      "Epoch  24/150 | Train Loss: 1009.240 | Train Acc: 23.93% | Train Prec:  9.04% | Train Recall: 20.13% | Train F1:  8.55% || Test Acc: 22.40% | Test Prec: 10.74% | Test Recall: 20.51% | Test F1:  8.64% | Patience: 18/20\n",
      "Epoch  25/150 | Train Loss: 1008.982 | Train Acc: 23.97% | Train Prec: 11.04% | Train Recall: 20.10% | Train F1:  8.04% || Test Acc: 23.34% | Test Prec:  4.71% | Test Recall: 19.73% | Test F1:  7.60% | Patience: 19/20\n",
      "\n",
      "Early stopping triggered for CNNBaseline_Dropout5 after 25 epochs.\n",
      "Final training state for CNNBaseline_Dropout5 saved to /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout5_augmented_latest_1d_earlystop.pth\n",
      "\n",
      "Training completed for CNNBaseline_Dropout5 after 25 epochs.\n",
      "Best test accuracy achieved during training: 23.659%\n",
      "\n",
      "Loading best saved model for CNNBaseline_Dropout5 from /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout5_augmented_best_1d_earlystop.pth for final evaluation...\n",
      "\n",
      "Classification Report for CNNBaseline_Dropout5 (using best saved model):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/larsheijnen/DL/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       138\n",
      "           1      0.000     0.000     0.000       118\n",
      "           2      0.000     0.000     0.000       120\n",
      "           3      0.237     1.000     0.383       150\n",
      "           4      0.000     0.000     0.000       108\n",
      "\n",
      "    accuracy                          0.237       634\n",
      "   macro avg      0.047     0.200     0.077       634\n",
      "weighted avg      0.056     0.237     0.091       634\n",
      "\n",
      "\n",
      "Gender breakdown for CNNBaseline_Dropout5 (using best saved model):\n",
      "Male: {'accuracy': 0.2515923566878981, 'precision': 0.05031847133757962, 'recall': 0.2, 'f1': 0.08040712468193384}\n",
      "Female: {'accuracy': 0.221875, 'precision': 0.044375, 'recall': 0.2, 'f1': 0.07263427109974424}\n",
      "\n",
      "--- Summary for CNNBaseline_Dropout5 ---\n",
      "- Total epochs trained: 25\n",
      "- Best validation accuracy during training: 23.659%\n",
      "- Training accuracy of loaded (best saved) model: 23.85%\n",
      "- Best model saved to: /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout5_augmented_best_1d_earlystop.pth\n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "=== Training model: CNNBaseline_Dropout3_BatchNorm (Early Stopping) ===\n",
      "Epoch   1/150 | Train Loss: 1027.220 | Train Acc: 21.96% | Train Prec: 26.02% | Train Recall: 20.65% | Train F1: 12.88% || Test Acc: 21.14% | Test Prec: 30.17% | Test Recall: 20.59% | Test F1: 12.58% | Patience: 0/20\n",
      "    → New best test accuracy: 21.136% (saved to /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout3_BatchNorm_augmented_best_1d_earlystop.pth)\n",
      "Epoch   2/150 | Train Loss: 1006.793 | Train Acc: 23.54% | Train Prec: 13.44% | Train Recall: 19.79% | Train F1:  9.81% || Test Acc: 23.66% | Test Prec: 15.97% | Test Recall: 20.21% | Test F1: 10.49% | Patience: 0/20\n",
      "    → New best test accuracy: 23.659% (saved to /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout3_BatchNorm_augmented_best_1d_earlystop.pth)\n",
      "Epoch   3/150 | Train Loss: 1003.414 | Train Acc: 23.62% | Train Prec:  9.22% | Train Recall: 19.81% | Train F1:  7.95% || Test Acc: 22.87% | Test Prec:  6.86% | Test Recall: 19.34% | Test F1:  7.74% | Patience: 0/20\n",
      "Epoch   4/150 | Train Loss: 999.096 | Train Acc: 23.66% | Train Prec: 12.55% | Train Recall: 19.86% | Train F1:  9.22% || Test Acc: 23.50% | Test Prec: 14.40% | Test Recall: 20.01% | Test F1:  9.90% | Patience: 1/20\n",
      "Epoch   5/150 | Train Loss: 991.792 | Train Acc: 14.81% | Train Prec: 19.57% | Train Recall: 19.05% | Train F1:  7.97% || Test Acc: 17.98% | Test Prec: 23.52% | Test Recall: 20.44% | Test F1:  9.67% | Patience: 2/20\n",
      "Epoch   6/150 | Train Loss: 992.740 | Train Acc: 14.93% | Train Prec: 25.78% | Train Recall: 19.18% | Train F1:  8.22% || Test Acc: 18.14% | Test Prec: 17.53% | Test Recall: 20.49% | Test F1: 10.21% | Patience: 3/20\n",
      "Epoch   7/150 | Train Loss: 989.793 | Train Acc: 20.42% | Train Prec: 13.69% | Train Recall: 20.15% | Train F1:  8.58% || Test Acc: 19.72% | Test Prec: 15.05% | Test Recall: 20.78% | Test F1:  9.09% | Patience: 4/20\n",
      "Epoch   8/150 | Train Loss: 987.372 | Train Acc: 24.13% | Train Prec: 20.51% | Train Recall: 20.44% | Train F1:  9.27% || Test Acc: 24.13% | Test Prec: 21.65% | Test Recall: 20.74% | Test F1: 10.38% | Patience: 5/20\n",
      "Epoch   9/150 | Train Loss: 985.660 | Train Acc: 20.42% | Train Prec: 26.79% | Train Recall: 20.07% | Train F1:  9.38% || Test Acc: 17.98% | Test Prec: 11.23% | Test Recall: 18.96% | Test F1:  8.22% | Patience: 6/20\n",
      "Epoch  10/150 | Train Loss: 983.169 | Train Acc: 23.58% | Train Prec: 12.54% | Train Recall: 19.90% | Train F1:  8.67% || Test Acc: 24.13% | Test Prec: 18.36% | Test Recall: 20.54% | Test F1:  8.99% | Patience: 7/20\n",
      "Epoch  11/150 | Train Loss: 993.312 | Train Acc: 22.55% | Train Prec:  8.37% | Train Recall: 19.18% | Train F1:  9.00% || Test Acc: 23.50% | Test Prec: 12.28% | Test Recall: 20.20% | Test F1:  9.99% | Patience: 8/20\n",
      "Epoch  12/150 | Train Loss: 983.929 | Train Acc: 23.78% | Train Prec: 18.18% | Train Recall: 20.47% | Train F1: 10.20% || Test Acc: 23.50% | Test Prec: 21.36% | Test Recall: 20.25% | Test F1:  9.94% | Patience: 9/20\n",
      "Epoch  13/150 | Train Loss: 984.844 | Train Acc: 23.54% | Train Prec: 18.84% | Train Recall: 20.13% | Train F1:  9.95% || Test Acc: 23.34% | Test Prec: 27.53% | Test Recall: 19.92% | Test F1:  9.07% | Patience: 10/20\n",
      "Epoch  14/150 | Train Loss: 984.377 | Train Acc: 23.50% | Train Prec: 22.27% | Train Recall: 19.79% | Train F1:  8.23% || Test Acc: 23.34% | Test Prec: 13.69% | Test Recall: 19.87% | Test F1:  8.57% | Patience: 11/20\n",
      "Epoch  15/150 | Train Loss: 986.399 | Train Acc: 23.74% | Train Prec: 16.87% | Train Recall: 20.29% | Train F1:  9.48% || Test Acc: 22.71% | Test Prec: 10.27% | Test Recall: 19.34% | Test F1:  8.48% | Patience: 12/20\n",
      "Epoch  16/150 | Train Loss: 981.770 | Train Acc: 23.66% | Train Prec: 20.05% | Train Recall: 20.40% | Train F1: 10.67% || Test Acc: 22.87% | Test Prec: 10.40% | Test Recall: 19.52% | Test F1:  8.93% | Patience: 13/20\n",
      "Epoch  17/150 | Train Loss: 978.076 | Train Acc: 24.01% | Train Prec: 17.21% | Train Recall: 20.25% | Train F1:  8.77% || Test Acc: 24.13% | Test Prec: 29.03% | Test Recall: 20.60% | Test F1:  9.28% | Patience: 14/20\n",
      "Epoch  18/150 | Train Loss: 980.478 | Train Acc: 23.74% | Train Prec:  9.14% | Train Recall: 19.95% | Train F1:  7.99% || Test Acc: 23.19% | Test Prec:  9.13% | Test Recall: 19.70% | Test F1:  8.23% | Patience: 15/20\n",
      "Epoch  19/150 | Train Loss: 980.714 | Train Acc: 23.54% | Train Prec: 15.29% | Train Recall: 19.80% | Train F1:  8.07% || Test Acc: 23.50% | Test Prec: 17.57% | Test Recall: 19.95% | Test F1:  8.28% | Patience: 16/20\n",
      "Epoch  20/150 | Train Loss: 989.670 | Train Acc: 23.97% | Train Prec: 18.03% | Train Recall: 20.32% | Train F1:  9.79% || Test Acc: 24.45% | Test Prec: 11.10% | Test Recall: 21.03% | Test F1: 10.42% | Patience: 17/20\n",
      "    → New best test accuracy: 24.448% (saved to /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout3_BatchNorm_augmented_best_1d_earlystop.pth)\n",
      "Epoch  21/150 | Train Loss: 988.557 | Train Acc: 23.70% | Train Prec: 31.81% | Train Recall: 20.05% | Train F1:  9.25% || Test Acc: 23.50% | Test Prec: 13.00% | Test Recall: 20.10% | Test F1:  9.34% | Patience: 0/20\n",
      "Epoch  22/150 | Train Loss: 985.450 | Train Acc: 23.06% | Train Prec: 18.26% | Train Recall: 19.46% | Train F1:  8.78% || Test Acc: 23.34% | Test Prec:  6.61% | Test Recall: 19.74% | Test F1:  7.97% | Patience: 1/20\n",
      "Epoch  23/150 | Train Loss: 985.006 | Train Acc: 23.74% | Train Prec:  8.58% | Train Recall: 19.95% | Train F1:  8.26% || Test Acc: 23.19% | Test Prec:  8.30% | Test Recall: 19.67% | Test F1:  8.13% | Patience: 2/20\n",
      "Epoch  24/150 | Train Loss: 982.481 | Train Acc: 23.18% | Train Prec: 13.52% | Train Recall: 19.66% | Train F1:  9.58% || Test Acc: 22.08% | Test Prec: 12.28% | Test Recall: 18.84% | Test F1:  8.73% | Patience: 3/20\n",
      "Epoch  25/150 | Train Loss: 980.406 | Train Acc: 23.70% | Train Prec: 18.87% | Train Recall: 20.20% | Train F1: 10.35% || Test Acc: 23.97% | Test Prec: 18.66% | Test Recall: 20.57% | Test F1: 10.30% | Patience: 4/20\n",
      "Epoch  26/150 | Train Loss: 980.595 | Train Acc: 23.74% | Train Prec: 20.63% | Train Recall: 20.08% | Train F1:  9.18% || Test Acc: 23.03% | Test Prec: 17.97% | Test Recall: 19.63% | Test F1:  8.70% | Patience: 5/20\n",
      "Epoch  27/150 | Train Loss: 984.137 | Train Acc: 22.39% | Train Prec: 12.32% | Train Recall: 19.24% | Train F1:  9.42% || Test Acc: 22.40% | Test Prec: 12.37% | Test Recall: 19.38% | Test F1:  9.72% | Patience: 6/20\n",
      "Epoch  28/150 | Train Loss: 981.435 | Train Acc: 23.38% | Train Prec:  7.44% | Train Recall: 19.63% | Train F1:  7.78% || Test Acc: 23.34% | Test Prec:  7.21% | Test Recall: 19.77% | Test F1:  7.91% | Patience: 7/20\n",
      "Epoch  29/150 | Train Loss: 977.195 | Train Acc: 23.89% | Train Prec:  9.67% | Train Recall: 20.07% | Train F1:  8.08% || Test Acc: 23.34% | Test Prec:  4.71% | Test Recall: 19.73% | Test F1:  7.61% | Patience: 8/20\n",
      "Epoch  30/150 | Train Loss: 980.257 | Train Acc: 23.62% | Train Prec: 13.47% | Train Recall: 20.12% | Train F1:  9.84% || Test Acc: 22.87% | Test Prec: 13.33% | Test Recall: 19.71% | Test F1:  9.97% | Patience: 9/20\n",
      "Epoch  31/150 | Train Loss: 981.693 | Train Acc: 23.46% | Train Prec: 11.15% | Train Recall: 19.80% | Train F1:  8.71% || Test Acc: 22.71% | Test Prec: 10.33% | Test Recall: 19.37% | Test F1:  8.87% | Patience: 10/20\n",
      "Epoch  32/150 | Train Loss: 979.442 | Train Acc: 23.34% | Train Prec: 21.74% | Train Recall: 19.88% | Train F1:  9.97% || Test Acc: 22.87% | Test Prec:  9.20% | Test Recall: 19.46% | Test F1:  8.54% | Patience: 11/20\n",
      "Epoch  33/150 | Train Loss: 980.784 | Train Acc: 23.93% | Train Prec: 27.91% | Train Recall: 20.20% | Train F1:  9.20% || Test Acc: 22.87% | Test Prec: 12.01% | Test Recall: 19.46% | Test F1:  8.65% | Patience: 12/20\n",
      "Epoch  34/150 | Train Loss: 978.477 | Train Acc: 23.34% | Train Prec: 17.19% | Train Recall: 19.82% | Train F1:  8.98% || Test Acc: 23.03% | Test Prec:  9.14% | Test Recall: 19.55% | Test F1:  8.26% | Patience: 13/20\n",
      "Epoch  35/150 | Train Loss: 980.686 | Train Acc: 23.70% | Train Prec: 17.49% | Train Recall: 19.91% | Train F1:  8.49% || Test Acc: 23.19% | Test Prec:  7.34% | Test Recall: 19.63% | Test F1:  8.33% | Patience: 14/20\n",
      "Epoch  36/150 | Train Loss: 978.209 | Train Acc: 23.74% | Train Prec:  8.31% | Train Recall: 19.96% | Train F1:  8.01% || Test Acc: 23.34% | Test Prec: 11.35% | Test Recall: 19.77% | Test F1:  7.89% | Patience: 15/20\n",
      "Epoch  37/150 | Train Loss: 978.409 | Train Acc: 23.70% | Train Prec: 20.55% | Train Recall: 20.03% | Train F1:  8.70% || Test Acc: 22.71% | Test Prec:  4.67% | Test Recall: 19.20% | Test F1:  7.51% | Patience: 16/20\n",
      "Epoch  38/150 | Train Loss: 973.274 | Train Acc: 22.95% | Train Prec: 11.44% | Train Recall: 19.41% | Train F1:  8.53% || Test Acc: 23.50% | Test Prec: 14.94% | Test Recall: 20.21% | Test F1:  9.72% | Patience: 17/20\n",
      "Epoch  39/150 | Train Loss: 979.085 | Train Acc: 23.66% | Train Prec: 19.95% | Train Recall: 19.88% | Train F1:  8.63% || Test Acc: 23.82% | Test Prec: 29.71% | Test Recall: 20.30% | Test F1:  9.61% | Patience: 18/20\n",
      "Epoch  40/150 | Train Loss: 979.611 | Train Acc: 23.78% | Train Prec: 11.39% | Train Recall: 19.95% | Train F1:  7.98% || Test Acc: 23.66% | Test Prec: 29.16% | Test Recall: 20.06% | Test F1:  8.47% | Patience: 19/20\n",
      "\n",
      "Early stopping triggered for CNNBaseline_Dropout3_BatchNorm after 40 epochs.\n",
      "Final training state for CNNBaseline_Dropout3_BatchNorm saved to /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout3_BatchNorm_augmented_latest_1d_earlystop.pth\n",
      "\n",
      "Training completed for CNNBaseline_Dropout3_BatchNorm after 40 epochs.\n",
      "Best test accuracy achieved during training: 24.448%\n",
      "\n",
      "Loading best saved model for CNNBaseline_Dropout3_BatchNorm from /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout3_BatchNorm_augmented_best_1d_earlystop.pth for final evaluation...\n",
      "\n",
      "Classification Report for CNNBaseline_Dropout3_BatchNorm (using best saved model):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       138\n",
      "           1      0.258     0.068     0.107       118\n",
      "           2      0.000     0.000     0.000       120\n",
      "           3      0.234     0.933     0.374       150\n",
      "           4      0.000     0.000     0.000       108\n",
      "\n",
      "    accuracy                          0.233       634\n",
      "   macro avg      0.098     0.200     0.096       634\n",
      "weighted avg      0.103     0.233     0.108       634\n",
      "\n",
      "\n",
      "Gender breakdown for CNNBaseline_Dropout3_BatchNorm (using best saved model):\n",
      "Male: {'accuracy': 0.2484076433121019, 'precision': 0.2631756756756757, 'recall': 0.1985786762279264, 'f1': 0.09579487179487181}\n",
      "Female: {'accuracy': 0.228125, 'precision': 0.10753311258278146, 'recall': 0.20940643863179073, 'f1': 0.10070002978850164}\n",
      "\n",
      "--- Summary for CNNBaseline_Dropout3_BatchNorm ---\n",
      "- Total epochs trained: 40\n",
      "- Best validation accuracy during training: 24.448%\n",
      "- Training accuracy of loaded (best saved) model: 23.54%\n",
      "- Best model saved to: /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout3_BatchNorm_augmented_best_1d_earlystop.pth\n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "=== Training model: CNNBaseline_Dropout5_BatchNorm (Early Stopping) ===\n",
      "Epoch   1/150 | Train Loss: 1027.313 | Train Acc: 23.54% | Train Prec: 11.78% | Train Recall: 19.80% | Train F1:  9.66% || Test Acc: 22.40% | Test Prec:  7.79% | Test Recall: 19.01% | Test F1:  8.88% | Patience: 0/20\n",
      "    → New best test accuracy: 22.397% (saved to /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout5_BatchNorm_augmented_best_1d_earlystop.pth)\n",
      "Epoch   2/150 | Train Loss: 1011.801 | Train Acc: 22.43% | Train Prec:  7.89% | Train Recall: 18.81% | Train F1:  8.74% || Test Acc: 23.66% | Test Prec: 23.90% | Test Recall: 20.29% | Test F1: 10.80% | Patience: 0/20\n",
      "    → New best test accuracy: 23.659% (saved to /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout5_BatchNorm_augmented_best_1d_earlystop.pth)\n",
      "Epoch   3/150 | Train Loss: 1010.023 | Train Acc: 20.10% | Train Prec: 14.13% | Train Recall: 19.96% | Train F1:  7.78% || Test Acc: 18.30% | Test Prec: 14.18% | Test Recall: 19.50% | Test F1:  7.72% | Patience: 0/20\n",
      "Epoch   4/150 | Train Loss: 996.109 | Train Acc: 23.10% | Train Prec: 14.87% | Train Recall: 19.62% | Train F1:  9.51% || Test Acc: 23.19% | Test Prec: 15.40% | Test Recall: 19.96% | Test F1: 10.05% | Patience: 1/20\n",
      "Epoch   5/150 | Train Loss: 997.835 | Train Acc: 20.10% | Train Prec: 18.22% | Train Recall: 19.90% | Train F1:  9.02% || Test Acc: 19.09% | Test Prec: 23.90% | Test Recall: 20.30% | Test F1:  8.75% | Patience: 2/20\n",
      "Epoch   6/150 | Train Loss: 993.556 | Train Acc: 15.44% | Train Prec: 18.05% | Train Recall: 19.67% | Train F1:  8.30% || Test Acc: 16.88% | Test Prec: 10.82% | Test Recall: 19.29% | Test F1:  8.56% | Patience: 3/20\n",
      "Epoch   7/150 | Train Loss: 995.914 | Train Acc: 23.82% | Train Prec: 29.32% | Train Recall: 20.19% | Train F1:  9.79% || Test Acc: 23.97% | Test Prec: 14.56% | Test Recall: 20.62% | Test F1: 10.42% | Patience: 4/20\n",
      "Epoch   8/150 | Train Loss: 992.229 | Train Acc: 23.74% | Train Prec: 42.16% | Train Recall: 20.00% | Train F1:  8.89% || Test Acc: 23.34% | Test Prec: 12.70% | Test Recall: 19.79% | Test F1:  8.43% | Patience: 5/20\n",
      "Epoch   9/150 | Train Loss: 992.768 | Train Acc: 15.92% | Train Prec: 19.83% | Train Recall: 20.22% | Train F1:  8.99% || Test Acc: 17.67% | Test Prec: 17.98% | Test Recall: 19.87% | Test F1:  9.68% | Patience: 6/20\n",
      "Epoch  10/150 | Train Loss: 994.120 | Train Acc: 20.38% | Train Prec: 20.71% | Train Recall: 20.04% | Train F1:  9.81% || Test Acc: 18.61% | Test Prec: 21.04% | Test Recall: 19.52% | Test F1:  9.22% | Patience: 7/20\n",
      "Epoch  11/150 | Train Loss: 990.065 | Train Acc: 22.75% | Train Prec: 14.05% | Train Recall: 19.11% | Train F1:  9.45% || Test Acc: 23.19% | Test Prec:  8.72% | Test Recall: 19.69% | Test F1:  9.32% | Patience: 8/20\n",
      "Epoch  12/150 | Train Loss: 981.576 | Train Acc: 23.22% | Train Prec: 11.66% | Train Recall: 19.77% | Train F1:  9.43% || Test Acc: 22.87% | Test Prec:  9.57% | Test Recall: 19.63% | Test F1:  9.61% | Patience: 9/20\n",
      "Epoch  13/150 | Train Loss: 987.198 | Train Acc: 23.54% | Train Prec: 21.18% | Train Recall: 19.79% | Train F1:  9.48% || Test Acc: 22.56% | Test Prec:  7.33% | Test Recall: 19.14% | Test F1:  8.75% | Patience: 10/20\n",
      "Epoch  14/150 | Train Loss: 990.783 | Train Acc: 23.70% | Train Prec: 15.32% | Train Recall: 19.88% | Train F1:  8.63% || Test Acc: 24.13% | Test Prec:  9.84% | Test Recall: 20.47% | Test F1:  9.25% | Patience: 11/20\n",
      "Epoch  15/150 | Train Loss: 991.020 | Train Acc: 23.78% | Train Prec:  9.37% | Train Recall: 19.94% | Train F1:  8.55% || Test Acc: 23.03% | Test Prec:  7.16% | Test Recall: 19.49% | Test F1:  8.02% | Patience: 12/20\n",
      "Epoch  16/150 | Train Loss: 992.920 | Train Acc: 23.46% | Train Prec:  7.76% | Train Recall: 19.67% | Train F1:  8.48% || Test Acc: 23.19% | Test Prec:  9.21% | Test Recall: 19.69% | Test F1:  9.27% | Patience: 13/20\n",
      "Epoch  17/150 | Train Loss: 990.415 | Train Acc: 23.85% | Train Prec:  4.77% | Train Recall: 20.00% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.73% | Test Recall: 20.00% | Test F1:  7.65% | Patience: 14/20\n",
      "Epoch  18/150 | Train Loss: 988.053 | Train Acc: 23.70% | Train Prec:  7.16% | Train Recall: 19.89% | Train F1:  7.90% || Test Acc: 23.66% | Test Prec: 14.72% | Test Recall: 20.04% | Test F1:  7.96% | Patience: 15/20\n",
      "Epoch  19/150 | Train Loss: 991.933 | Train Acc: 23.82% | Train Prec:  4.77% | Train Recall: 19.97% | Train F1:  7.70% || Test Acc: 23.66% | Test Prec:  4.74% | Test Recall: 20.00% | Test F1:  7.66% | Patience: 16/20\n",
      "Epoch  20/150 | Train Loss: 991.144 | Train Acc: 23.85% | Train Prec: 18.10% | Train Recall: 20.00% | Train F1:  7.83% || Test Acc: 24.13% | Test Prec: 23.12% | Test Recall: 20.46% | Test F1:  8.62% | Patience: 17/20\n",
      "Epoch  21/150 | Train Loss: 987.829 | Train Acc: 23.85% | Train Prec: 14.23% | Train Recall: 20.03% | Train F1:  8.02% || Test Acc: 23.50% | Test Prec:  4.72% | Test Recall: 19.87% | Test F1:  7.62% | Patience: 18/20\n",
      "Epoch  22/150 | Train Loss: 987.122 | Train Acc: 23.42% | Train Prec: 21.95% | Train Recall: 19.92% | Train F1:  9.29% || Test Acc: 23.66% | Test Prec: 19.01% | Test Recall: 20.25% | Test F1:  9.54% | Patience: 19/20\n",
      "\n",
      "Early stopping triggered for CNNBaseline_Dropout5_BatchNorm after 22 epochs.\n",
      "Final training state for CNNBaseline_Dropout5_BatchNorm saved to /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout5_BatchNorm_augmented_latest_1d_earlystop.pth\n",
      "\n",
      "Training completed for CNNBaseline_Dropout5_BatchNorm after 22 epochs.\n",
      "Best test accuracy achieved during training: 23.659%\n",
      "\n",
      "Loading best saved model for CNNBaseline_Dropout5_BatchNorm from /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout5_BatchNorm_augmented_best_1d_earlystop.pth for final evaluation...\n",
      "\n",
      "Classification Report for CNNBaseline_Dropout5_BatchNorm (using best saved model):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.211     0.058     0.091       138\n",
      "           1      0.000     0.000     0.000       118\n",
      "           2      0.000     0.000     0.000       120\n",
      "           3      0.235     0.920     0.375       150\n",
      "           4      0.167     0.009     0.018       108\n",
      "\n",
      "    accuracy                          0.232       634\n",
      "   macro avg      0.123     0.197     0.097       634\n",
      "weighted avg      0.130     0.232     0.111       634\n",
      "\n",
      "\n",
      "Gender breakdown for CNNBaseline_Dropout5_BatchNorm (using best saved model):\n",
      "Male: {'accuracy': 0.24522292993630573, 'precision': 0.2863636363636364, 'recall': 0.19859213647716834, 'f1': 0.09813184218701461}\n",
      "Female: {'accuracy': 0.221875, 'precision': 0.0994093761535622, 'recall': 0.19690450394675746, 'f1': 0.08931636578869488}\n",
      "\n",
      "--- Summary for CNNBaseline_Dropout5_BatchNorm ---\n",
      "- Total epochs trained: 22\n",
      "- Best validation accuracy during training: 23.659%\n",
      "- Training accuracy of loaded (best saved) model: 23.74%\n",
      "- Best model saved to: /Users/larsheijnen/DL/saved_models/A/augmented_earlystop/CNNBaseline_Dropout5_BatchNorm_augmented_best_1d_earlystop.pth\n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "All model configurations have been trained and evaluated.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Prepare dataset & split\n",
    "# For 1D data, ensure AccentSpectrogramDataset returns tensors of shape (batch, channels=1, length)\n",
    "dataset = AccentRawWaveformDatasetAug(\n",
    "    '/Users/larsheijnen/DL/Train',\n",
    "    target_sr=16000,\n",
    "    standardize=True\n",
    ")\n",
    "\n",
    "train_len = int(0.8 * len(dataset))\n",
    "test_len  = len(dataset) - train_len\n",
    "train_ds, test_ds = random_split(dataset, [train_len, test_len], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "# For 1D data, pad_collate should pad along the last dimension (length)\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True,  collate_fn=pad_1d_collate)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=4, shuffle=False, collate_fn=pad_1d_collate)\n",
    "\n",
    "device    = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# General (not by gender) evaluation helper\n",
    "def evaluate(loader, model, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for specs, labels, _ in loader:\n",
    "            # For 1D data, specs should be (batch, 1, length)\n",
    "            specs, labels = specs.to(device), labels.to(device)\n",
    "            outputs = model(specs)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_labels.extend(labels.cpu().tolist())\n",
    "    acc    = accuracy_score(all_labels, all_preds)\n",
    "    prec   = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='macro')\n",
    "    f1     = f1_score(all_labels, all_preds, average='macro')\n",
    "    return acc, prec, recall, f1\n",
    "\n",
    "# Gender-based evaluation helper\n",
    "def evaluate_by_gender(loader, model, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels, all_genders = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for specs, labels, genders in loader:\n",
    "            specs, labels = specs.to(device), labels.to(device)\n",
    "            outputs = model(specs)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_labels.extend(labels.cpu().tolist())\n",
    "            all_genders.extend(genders)\n",
    "    results = {}\n",
    "    for gender in ['m', 'f']:\n",
    "        idxs = [i for i, g in enumerate(all_genders) if g == gender]\n",
    "        gender_preds = [all_preds[i] for i in idxs]\n",
    "        gender_labels = [all_labels[i] for i in idxs]\n",
    "        acc = accuracy_score(gender_labels, gender_preds)\n",
    "        prec = precision_score(gender_labels, gender_preds, average='macro', zero_division=0)\n",
    "        recall = recall_score(gender_labels, gender_preds, average='macro')\n",
    "        f1 = f1_score(gender_labels, gender_preds, average='macro')\n",
    "        results[gender] = {'accuracy': acc, 'precision': prec, 'recall': recall, 'f1': f1}\n",
    "    return results\n",
    "\n",
    "def classification_report_for_model(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for specs, labels, _ in loader:\n",
    "            specs, labels = specs.to(device), labels.to(device)\n",
    "            outputs = model(specs)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_labels.extend(labels.cpu().tolist())\n",
    "    print(classification_report(all_labels, all_preds, digits=3))\n",
    "\n",
    "import os\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 20\n",
    "max_epochs = 150\n",
    "min_improvement = 0.005\n",
    "\n",
    "save_dir_base = \"/Users/larsheijnen/DL/saved_models/A/augmented_earlystop\"\n",
    "os.makedirs(save_dir_base, exist_ok=True)\n",
    "\n",
    "for model_name, model_class in models_dict.items():\n",
    "    model = model_class().to(device)\n",
    "    print(f\"\\n=== Training model: {type(model).__name__} (Early Stopping) ===\")\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "    best_test_acc = 0.0\n",
    "    patience_counter = 0\n",
    "\n",
    "    best_model_path = os.path.join(save_dir_base, f\"{type(model).__name__}_augmented_best_1d_earlystop.pth\")\n",
    "    final_model_path = os.path.join(save_dir_base, f\"{type(model).__name__}_augmented_latest_1d_earlystop.pth\")\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for specs, labels, genders in train_loader:\n",
    "            specs, labels = specs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(specs), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Compute and print general metrics for this epoch (not by gender)\n",
    "        train_acc, train_prec, train_recall, train_f1 = evaluate(train_loader, model, device)\n",
    "        test_acc, test_prec, test_recall, test_f1 = evaluate(test_loader, model, device)\n",
    "        print(\n",
    "            f\"Epoch {epoch+1:3d}/{max_epochs} | \"\n",
    "            f\"Train Loss: {running_loss:.3f} | \"\n",
    "            f\"Train Acc: {train_acc*100:5.2f}% | \"\n",
    "            f\"Train Prec: {train_prec*100:5.2f}% | \"\n",
    "            f\"Train Recall: {train_recall*100:5.2f}% | \"\n",
    "            f\"Train F1: {train_f1*100:5.2f}% || \"\n",
    "            f\"Test Acc: {test_acc*100:5.2f}% | \"\n",
    "            f\"Test Prec: {test_prec*100:5.2f}% | \"\n",
    "            f\"Test Recall: {test_recall*100:5.2f}% | \"\n",
    "            f\"Test F1: {test_f1*100:5.2f}% | \"\n",
    "            f\"Patience: {patience_counter}/{patience}\"\n",
    "        )\n",
    "\n",
    "        if test_acc > best_test_acc + min_improvement:\n",
    "            best_test_acc = test_acc\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"    → New best test accuracy: {best_test_acc*100:.3f}% (saved to {best_model_path})\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\nEarly stopping triggered for {type(model).__name__} after {epoch+1} epochs.\")\n",
    "            break\n",
    "\n",
    "    torch.save(model.state_dict(), final_model_path)\n",
    "    print(f\"Final training state for {type(model).__name__} saved to {final_model_path}\")\n",
    "    print(f\"\\nTraining completed for {type(model).__name__} after {epoch+1} epochs.\")\n",
    "    print(f\"Best test accuracy achieved during training: {best_test_acc*100:.3f}%\")\n",
    "\n",
    "    # Load the best model for final evaluation\n",
    "    if os.path.exists(best_model_path):\n",
    "        print(f\"\\nLoading best saved model for {type(model).__name__} from {best_model_path} for final evaluation...\")\n",
    "        model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "        eval_model_description = \"best saved\"\n",
    "    else:\n",
    "        print(f\"\\nNo best model was saved for {type(model).__name__}. Using final model state for evaluation.\")\n",
    "        eval_model_description = \"final\"\n",
    "\n",
    "    print(f\"\\nClassification Report for {type(model).__name__} (using {eval_model_description} model):\")\n",
    "    classification_report_for_model(model, test_loader, device)\n",
    "\n",
    "    print(f\"\\nGender breakdown for {type(model).__name__} (using {eval_model_description} model):\")\n",
    "    gender_results = evaluate_by_gender(test_loader, model, device)\n",
    "    for gender in gender_results:\n",
    "        label = \"Male\" if gender == \"m\" else \"Female\"\n",
    "        print(f\"{label}: {gender_results[gender]}\")\n",
    "\n",
    "    final_train_acc, _, _, _ = evaluate(train_loader, model, device)\n",
    "    print(f\"\\n--- Summary for {type(model).__name__} ---\")\n",
    "    print(f\"- Total epochs trained: {epoch+1}\")\n",
    "    print(f\"- Best validation accuracy during training: {best_test_acc*100:.3f}%\")\n",
    "    print(f\"- Training accuracy of loaded ({eval_model_description}) model: {final_train_acc*100:.2f}%\")\n",
    "    if os.path.exists(best_model_path):\n",
    "        print(f\"- Best model saved to: {best_model_path}\")\n",
    "    else:\n",
    "        print(f\"- Best model not saved (or final model is the best achieved). Final model at: {final_model_path}\")\n",
    "    print(f\"---------------------------------------\\n\")\n",
    "\n",
    "print(\"\\nAll model configurations have been trained and evaluated.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
